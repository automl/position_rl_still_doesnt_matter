index,filename,code_available,hyperparameters_detailed,env_version_specified,year,conference,conf_id,seeds,keyword_0,keyword_1,keyword_2,keyword_3,keyword_4,keyword_5,keyword_6,algorithm_0,algorithm_1,algorithm_2,algorithm_3,algorithm_4,algorithm_5,algorithm_6
0,Learning Robust Rewards with Adverserial Inverse Reinforcement Learning.pdf,False,True,False,2018,iclr,iclr_2018,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,,,,,
1,Divide-and-Conquer Reinforcement Learning.pdf,False,False,False,2018,iclr,iclr_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,,,,
2,MaskGAN Better Text Generation via Filling in the _______.pdf,True,True,False,2018,iclr,iclr_2018,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,pets,ppo,,,,,
3,Towards Synthesizing Complex Programs From Input-Output Examples.pdf,False,True,False,2018,iclr,iclr_2018,0,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
4,META LEARNING SHARED HIERARCHIES.pdf,False,False,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,trpo,a3c,ppo,dqn,,,
5,Deep Bayesian Bandits Showdown  An Empirical Comparison of Bayesian Deep Networks for Thompson Sampl.pdf,True,True,False,2018,iclr,iclr_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,sac,,,,,
6,A Hierarchical Model for Device Placement.pdf,False,False,False,2018,iclr,iclr_2018,6-10,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,ppo,,,,,,
7,Eigenoption Discovery through the Deep Successor Representation.pdf,False,False,False,2018,iclr,iclr_2018,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
8,Noisy Networks For Exploration.pdf,False,True,False,2018,iclr,iclr_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,a3c,dqn,a2c,,,,
9,Certifying Some Distributional Robustness with Principled Adversarial Training.pdf,False,False,False,2018,iclr,iclr_2018,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,dqn,,,,,
10,Policy Optimization by Genetic Distillation.pdf,True,True,False,2018,iclr,iclr_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,dqn,a2c,sac,ppo,,
11,Universal Agent for Disentangling Environments and Tasks.pdf,False,False,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,a3c,,,,,,
12,DCN Mixed Objective And Deep Residual Coattention for Question Answering.pdf,False,False,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
13,SCAN Learning Hierarchical Compositional Visual Concepts.pdf,True,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
14,Flipout Efficient Pseudo-Independent Weight Perturbations on Mini-Batches.pdf,False,True,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,,,,,,
15,Routing Networks Adaptive Selection of Non-Linear Functions for Multi-Task Learning.pdf,False,False,False,2018,iclr,iclr_2018,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,sac,,,,
16,Memory Augmented Control Networks.pdf,False,False,False,2018,iclr,iclr_2018,0,(?:discount|reward)\s+function,,,,,,,a3c,ppo,dqn,,,,
17,Divide and Conquer Networks.pdf,True,True,False,2018,iclr,iclr_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
18,Towards better understanding of gradient-based attribution methods for Deep Neural Networks.pdf,True,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
19,Zero-Shot Visual Imitation.pdf,True,True,False,2018,iclr,iclr_2018,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
20,TD or not TD Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning.pdf,True,False,False,2018,iclr,iclr_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,trpo,a3c,dqn,a2c,sac,ppo,
21,NerveNet Learning Structured Policy with Graph Neural Networks.pdf,False,True,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,ppo,sac,,,,
22,Stochastic Activation Pruning for Robust Adversarial Defense.pdf,True,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
23,Learning to Teach.pdf,True,False,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,sac,,,,,,
24,Ask the Right Questions Active Question Reformulation with Reinforcement Learning.pdf,True,False,False,2018,iclr,iclr_2018,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,pets,ppo,,,,,
25,Learning to Multi-Task by Active Sampling.pdf,False,True,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,a3c,dqn,a2c,ppo,,
26,Leave no Trace Learning to Reset for Safe and Autonomous Reinforcement Learning.pdf,False,False,False,2018,iclr,iclr_2018,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,,,,
27,Hyperparameter optimization a spectral approach.pdf,True,True,False,2018,iclr,iclr_2018,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
28,A Deep Reinforced Model for Abstractive Summarization.pdf,False,False,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
29,Semi-parametric topological memory for navigation.pdf,True,False,False,2018,iclr,iclr_2018,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,ppo,sac,,,,,
30,Active Neural Localization.pdf,True,False,False,2018,iclr,iclr_2018,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,a3c,ppo,sac,a2c,,,
31,Learning how to explain neural networks PatternNet and PatternAttribution.pdf,False,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
32,Interactive Grounded Language Acquisition and Generalization in a 2D World.pdf,True,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
33,Consequentialist conditional cooperation in social dilemmas with imperfect information.pdf,True,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,a3c,ppo,,,,,
34,Can Neural Networks Understand Logical Entailment.pdf,False,True,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
35,Emergence of Linguistic Communication from  Referential Games with Symbolic and Pixel Input.pdf,False,False,False,2018,iclr,iclr_2018,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
36,Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning.pdf,False,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a2c,,,,,,
37,Hierarchical Subtask Discovery with Non-Negative Matrix Factorization.pdf,False,False,False,2018,iclr,iclr_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
38,Modular Continual Learning in a Unified Visual Environment.pdf,False,True,False,2018,iclr,iclr_2018,0,state-action\s+pairs,,,,,,,ppo,,,,,,
39,Emergence of grid-like representations by training recurrent neural networks to perform spatial loca.pdf,False,False,False,2018,iclr,iclr_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
40,Learning Parametric Closed-Loop Policies for Markov Potential Games.pdf,False,False,False,2018,iclr,iclr_2018,0,(?:discount|reward)\s+function,,,,,,,trpo,a3c,sac,ddpg,ppo,,
41,Distributed Prioritized Experience Replay.pdf,False,True,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,a3c,dqn,ddpg,a2c,sac,ppo,
42,Trust-PCL An Off-Policy Trust Region Method for Continuous Control.pdf,True,True,False,2018,iclr,iclr_2018,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ddpg,,,,,
43,Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play.pdf,False,False,False,2018,iclr,iclr_2018,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
44,Go for a Walk and Arrive at the Answer Reasoning Over Paths in Knowledge Bases using Reinforcement L.pdf,True,False,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,ppo,sac,,,,,
45,Learning an Embedding Space for Transferable Robot Skills.pdf,False,False,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,pets,dqn,,,,,
46,Guide Actor-Critic for Continuous Control.pdf,True,False,False,2018,iclr,iclr_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,trpo,ppo,dqn,,,,
47,An Online Learning Approach to Generative Adversarial Networks.pdf,False,False,False,2018,iclr,iclr_2018,6-10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
48,Learning a Generative Model for Validity in Complex Discrete Structures.pdf,False,False,False,2018,iclr,iclr_2018,0,we\s+train\s+(?:a\s+|an\s+)(?:deep\s+|model-based\s+|model-free\s+)?(?:reinforcement\s+learning|RL),,,,,,,ppo,,,,,,
49,Emergent Communication through Negotiation.pdf,False,True,False,2018,iclr,iclr_2018,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
50,TRUNCATED HORIZON POLICY SEARCH COMBINING REINFORCEMENT LEARNING  IMITATION LEARNING.pdf,False,False,False,2018,iclr,iclr_2018,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,trpo,ppo,,,,,
51,Learning Deep Mean Field Games for Modeling Large Population Behavior.pdf,False,False,False,2018,iclr,iclr_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,ddpg,,,,,
52,Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments.pdf,False,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
53,Memory Architectures in Recurrent Neural Network Language Models.pdf,False,True,False,2018,iclr,iclr_2018,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
54,DORA The Explorer Directed Outreaching Reinforcement Action-Selection.pdf,True,False,False,2018,iclr,iclr_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
55,Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis.pdf,False,False,False,2018,iclr,iclr_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
56,Model-Ensemble Trust-Region Policy Optimization.pdf,True,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,sac,ddpg,,,
57,Emergent Complexity via Multi-Agent Competition.pdf,True,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,trpo,ppo,sac,,,,
58,Memory-based Parameter Adaptation.pdf,False,True,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
59,Boosting the Actor with Dual Critic.pdf,True,False,False,2018,iclr,iclr_2018,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,trpo,ppo,,,,,
60,Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines.pdf,False,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,other,,,,,,
61,Parameter Space Noise for Exploration.pdf,True,False,False,2018,iclr,iclr_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,,,,
62,Interpretable Counting for Visual Question Answering.pdf,False,True,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
63,The Reactor A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning.pdf,False,False,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,trpo,a3c,dqn,a2c,ppo,,
64,Imitation Learning from Visual Data with Multiple Intentions.pdf,False,False,False,2018,iclr,iclr_2018,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
65,Parametrized Hierarchical Procedures for Neural Programming.pdf,False,False,False,2018,iclr,iclr_2018,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
66,TreeQN and ATreeC Differentiable Tree-Structured Models for Deep Reinforcement Learning.pdf,True,True,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,a3c,dqn,a2c,sac,,,
67,Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control.pdf,False,False,False,2018,iclr,iclr_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
68,Reinforcement Learning on Web Interfaces using Workflow-Guided Exploration.pdf,True,False,False,2018,iclr,iclr_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a2c,,,,,,
69,Temporal Difference Models Model-Free Deep RL for Model-Based Control.pdf,False,True,False,2018,iclr,iclr_2018,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,,,,
70,Latent Constraints Learning to Generate Conditionally from Unconditional Generative Models.pdf,False,False,False,2018,iclr,iclr_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
71,Maximum a Posteriori Policy Optimisation.pdf,False,True,False,2018,iclr,iclr_2018,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,trpo,dqn,ddpg,sac,ppo,,
72,RESIDUAL LOSS PREDICTION REINFORCEMENT LEARNING WITH NO INCREMENTAL FEEDBACK.pdf,True,True,False,2018,iclr,iclr_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,a2c,,,,
73,Action-dependent Control Variates for Policy Optimization via Stein Identity.pdf,False,False,False,2018,iclr,iclr_2018,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,dqn,ddpg,a2c,ppo,,
74,MGAN Training Generative Adversarial Nets with Multiple Generators.pdf,True,False,False,2018,iclr,iclr_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
75,N2N learning Network to Network Compression via Policy Gradient Reinforcement Learning.pdf,False,True,False,2018,iclr,iclr_2018,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
76,A Simple Neural Attentive Meta-Learner.pdf,False,True,False,2018,iclr,iclr_2018,1-5,(?:discount|reward)\s+function,,,,,,,trpo,sac,,,,,
0,Episodic Curiosity through Reachability.pdf,True,True,False,2019,iclr,iclr_2019,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
1,Policy Transfer with Strategy Optimization.pdf,True,False,False,2019,iclr,iclr_2019,1-5,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
2,Supervised Policy Update for Deep Reinforcement Learning.pdf,True,True,False,2019,iclr,iclr_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
3,Environment Probing Interaction Policies.pdf,True,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,sac,,,,,
4,DHER Hindsight Experience Replay for Dynamic Goals.pdf,True,False,False,2019,iclr,iclr_2019,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,trpo,ppo,dqn,ddpg,,,
5,Two-Timescale Networks for Nonlinear Value Function Approximation.pdf,False,True,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
6,From Language to Goals Inverse Reinforcement Learning for Vision-Based Instruction Following.pdf,False,False,False,2019,iclr,iclr_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
7,Attention Learn to Solve Routing Problems.pdf,True,False,False,2019,iclr,iclr_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
8,Deep Online Learning Via Meta-Learning Continual Adaptation for Model-Based RL.pdf,False,False,False,2019,iclr,iclr_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
9,ProMP Proximal Meta-Policy Search.pdf,False,False,False,2019,iclr,iclr_2019,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
10,Learning To Solve Circuit-SAT An Unsupervised Differentiable Approach.pdf,False,False,False,2019,iclr,iclr_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
11,Neural Logic Machines.pdf,False,False,False,2019,iclr,iclr_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
12,Neural Speed Reading with Structural-Jump-LSTM.pdf,True,False,False,2019,iclr,iclr_2019,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,a2c,,,,,
13,Reward Constrained Policy Optimization.pdf,True,True,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,a3c,sac,a2c,ppo,,
14,Learning to Schedule Communication in Multi-agent Reinforcement Learning.pdf,True,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,ppo,dqn,ddpg,sac,,,
15,Neural network gradient-based learning of black-box function interfaces.pdf,False,False,False,2019,iclr,iclr_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,a3c,ppo,sac,,,,
16,Probabilistic Planning with Sequential Monte Carlo methods.pdf,True,True,False,2019,iclr,iclr_2019,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
17,Hierarchical Visuomotor Control of Humanoids.pdf,False,False,False,2019,iclr,iclr_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
18,Emergent Coordination Through Competition.pdf,False,False,False,2019,iclr,iclr_2019,1-5,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,ppo,,,,,,
19,Robustness May Be at Odds with Accuracy.pdf,True,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
20,Analysing Mathematical Reasoning Abilities of Neural Models.pdf,True,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
21,A new dog learns old tricks  RL finds classic optimization algorithms.pdf,False,False,False,2019,iclr,iclr_2019,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
22,Information-Directed Exploration for Deep Reinforcement Learning.pdf,True,False,False,2019,iclr,iclr_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
23,Hyperbolic Attention Networks.pdf,True,False,False,2019,iclr,iclr_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
24,On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks.pdf,False,False,False,2019,iclr,iclr_2019,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,,,,,,,ppo,,,,,,
25,Near-Optimal Representation Learning for Hierarchical Reinforcement Learning.pdf,True,False,False,2019,iclr,iclr_2019,6-10,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
26,Stochastic GradientMirror Descent Minimax Optimality and Implicit Regularization.pdf,False,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
27,Learning a Meta-Solver for Syntax-Guided Program Synthesis.pdf,True,False,False,2019,iclr,iclr_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,a2c,,,,,
28,Knowledge Flow Improve Upon Your Teachers.pdf,True,True,False,2019,iclr,iclr_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a3c,dqn,a2c,sac,ppo,,
29,Learning Actionable Representations with Goal Conditioned Policies.pdf,False,True,False,2019,iclr,iclr_2019,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
30,Learning when to Communicate at Scale in Multiagent Cooperative and Competitive Tasks.pdf,True,False,False,2019,iclr,iclr_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
31,Hierarchical RL Using an Ensemble of Proprioceptive Periodic Policies.pdf,True,False,False,2019,iclr,iclr_2019,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,sac,,,
32,Probabilistic Recursive Reasoning for Multi-Agent Reinforcement Learning.pdf,False,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
33,Neural Graph Evolution Automatic Robot Design.pdf,False,True,False,2019,iclr,iclr_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
34,Hierarchical Reinforcement Learning via Advantage-Weighted Information Maximization.pdf,True,False,False,2019,iclr,iclr_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,sac,,,,
35,The Neuro-Symbolic Concept Learner Interpreting Scenes Words and Sentences From Natural Supervision.pdf,False,True,False,2019,iclr,iclr_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
36,Optimal Completion Distillation for Sequence Learning.pdf,False,True,False,2019,iclr,iclr_2019,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
37,AD-VAT An Asymmetric Dueling mechanism for learning Visual Active Tracking.pdf,True,True,False,2019,iclr,iclr_2019,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,a3c,ppo,sac,,,,
38,Multi-step Retriever-Reader Interaction for Scalable Open-domain Question Answering.pdf,True,False,False,2019,iclr,iclr_2019,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,pets,,,,,,
39,Marginal Policy Gradients A Unified Family of Estimators for Bounded Action Spaces with Applications.pdf,True,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,trpo,a3c,ppo,a2c,,,
40,Opportunistic Learning Budgeted Cost-Sensitive Learning from Data Streams.pdf,True,True,False,2019,iclr,iclr_2019,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
41,Learning Multi-Level Hierarchies with Hindsight.pdf,True,False,False,2019,iclr,iclr_2019,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
42,AutoLoss Learning Discrete Schedule for Alternate Optimization.pdf,False,True,False,2019,iclr,iclr_2019,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
43,Variance Reduction for Reinforcement Learning in Input-Driven Environments.pdf,True,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,,,,,,
44,DOM-Q-NET  Grounded RL on Structured Language.pdf,True,True,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,sac,,,,,
45,Modeling the Long Term Future in Model-Based Reinforcement Learning.pdf,True,False,False,2019,iclr,iclr_2019,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,trpo,ppo,sac,,,,
46,Function Space Particle Optimization for Bayesian Neural Networks.pdf,True,False,False,2019,iclr,iclr_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
47,Visual Semantic Navigation using Scene Priors.pdf,False,False,False,2019,iclr,iclr_2019,0,(?:discount|reward)\s+function,,,,,,,a3c,ppo,a2c,,,,
48,M3RL Mind-aware Multi-agent Management Reinforcement Learning.pdf,True,False,False,2019,iclr,iclr_2019,6-10,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,(?:discount|reward)\s+function,,,,,,other,,,,,,
49,Value Propagation Networks.pdf,False,False,False,2019,iclr,iclr_2019,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,trpo,ppo,,,,,
50,Unsupervised Control Through Non-Parametric Discriminative Rewards.pdf,False,True,False,2019,iclr,iclr_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
51,Structured Neural Summarization.pdf,True,False,False,2019,iclr,iclr_2019,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,,,,,,,sac,,,,,,
52,The Laplacian in RL Learning Representations with Efficient Approximations.pdf,False,False,False,2019,iclr,iclr_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
53,Discriminator-Actor-Critic Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation L.pdf,True,False,False,2019,iclr,iclr_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,sac,ddpg,td3,ppo,,
54,Bayesian Policy Optimization for Model Uncertainty.pdf,False,False,False,2019,iclr,iclr_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
55,Diversity is All You Need Learning Skills without a Reward Function.pdf,True,False,False,2019,iclr,iclr_2019,1-5,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
56,An analytic theory of generalization dynamics and transfer learning in deep linear networks.pdf,False,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
57,Neural Probabilistic Motor Primitives for Humanoid Control.pdf,False,False,False,2019,iclr,iclr_2019,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,pets,,,
58,Deep reinforcement learning with relational inductive biases.pdf,False,True,False,2019,iclr,iclr_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,a2c,,,,,
59,Optimal Control Via Neural Networks A Convex Approach.pdf,False,False,False,2019,iclr,iclr_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
60,RelGAN Relational Generative Adversarial Networks for Text Generation.pdf,True,True,False,2019,iclr,iclr_2019,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
61,NADPEx An on-policy temporally consistent exploration method for deep reinforcement learning.pdf,True,False,False,2019,iclr,iclr_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,,,,
62,Generative predecessor models for sample-efficient imitation learning.pdf,True,False,False,2019,iclr,iclr_2019,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,,,,,,
63,Universal Successor Features Approximators.pdf,False,False,False,2019,iclr,iclr_2019,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
64,Learning Self-Imitating Diverse Policies.pdf,True,False,False,2019,iclr,iclr_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,trpo,td3,ppo,dqn,,,
65,Learning what you can do before doing anything.pdf,False,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
66,Solving the Rubiks Cube with Approximate Policy Iteration.pdf,True,False,False,2019,iclr,iclr_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,value\s+function\s+approximation,,,,,,ppo,,,,,,
67,Information asymmetry in KL-regularized RL.pdf,False,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,trpo,ppo,dqn,sac,,,
68,Amortized Bayesian Meta-Learning.pdf,False,False,False,2019,iclr,iclr_2019,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
69,Quasi-hyperbolic momentum and Adam for deep learning.pdf,True,True,False,2019,iclr,iclr_2019,over 10,(?:discount|reward)\s+function,,,,,,,td3,ppo,ddpg,,,,
70,Guiding Policies with Language via Meta-Learning.pdf,True,False,False,2019,iclr,iclr_2019,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
71,Learning To Simulate.pdf,False,True,False,2019,iclr,iclr_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,other,,,,,,
72,Learning Exploration Policies for Navigation.pdf,False,False,False,2019,iclr,iclr_2019,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
73,Hindsight policy gradients.pdf,True,True,False,2019,iclr,iclr_2019,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
74,Large-Scale Answerer in Questioners Mind for Visual Dialog Question Generation.pdf,True,False,False,2019,iclr,iclr_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
75,Understanding Straight-Through Estimator in Training Activation Quantized Neural Nets.pdf,False,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
76,Visceral Machines Risk-Aversion in  Reinforcement Learning with Intrinsic Physiological Rewards.pdf,False,False,False,2019,iclr,iclr_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,dqn,,,,,,
77,InfoBot Transfer and Exploration via the Information Bottleneck.pdf,True,False,False,2019,iclr,iclr_2019,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,a2c,,,
78,A Direct Approach to Robust Deep Learning Using Adversarial Networks.pdf,True,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
79,Learning Programmatically Structured Representations with Perceptor Gradients.pdf,False,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
80,Dynamically Unfolding Recurrent Restorer A Moving Endpoint Control Method for Image Restoration.pdf,False,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
81,Learning to Understand Goal Specifications by Modelling Reward.pdf,True,False,False,2019,iclr,iclr_2019,0,(?:discount|reward)\s+function,,,,,,,a3c,ppo,sac,,,,
82,Learning to Adapt in Dynamic Real-World Environments through Meta-Reinforcement Learning.pdf,False,True,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,dqn,sac,,,,
83,Execution-Guided Neural Program Synthesis.pdf,False,False,False,2019,iclr,iclr_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
84,Soft Q-Learning with Mutual-Information Regularization.pdf,False,False,False,2019,iclr,iclr_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,dqn,sac,,,,,
85,Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference.pdf,True,True,False,2019,iclr,iclr_2019,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,ppo,dqn,,,,,
86,Contingency-Aware Exploration in Reinforcement Learning.pdf,True,False,False,2019,iclr,iclr_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,a3c,dqn,a2c,ppo,,
87,Recurrent Experience Replay in Distributed Reinforcement Learning.pdf,False,True,False,2019,iclr,iclr_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,ppo,dqn,,,,
88,Learnable Embedding Space for Efficient Neural Architecture Compression.pdf,False,True,False,2019,iclr,iclr_2019,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
89,Learning Multimodal Graph-to-Graph Translation for Molecule Optimization.pdf,True,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
90,Learning to Navigate the Web.pdf,False,False,False,2019,iclr,iclr_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,dqn,,,,,,
91,Variance Networks When Expectation Does Not Meet Your Expectations.pdf,True,False,False,2019,iclr,iclr_2019,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
92,Composing Complex Skills by Learning Transition Policies.pdf,True,False,False,2019,iclr,iclr_2019,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
93,BabyAI A Platform to Study the Sample Efficiency of Grounded Language Learning.pdf,True,False,False,2019,iclr,iclr_2019,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
94,Variational Discriminator Bottleneck Improving Imitation Learning Inverse RL and GANs by Constrainin.pdf,True,False,False,2019,iclr,iclr_2019,1-5,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
95,Minimum Divergence vs Maximum Margin an Empirical Comparison on Seq2Seq Models.pdf,False,False,False,2019,iclr,iclr_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
96,Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic.pdf,True,False,False,2019,iclr,iclr_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,,,,,,
97,Competitive experience replay.pdf,False,False,False,2019,iclr,iclr_2019,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,trpo,ppo,dqn,ddpg,,,
98,Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees.pdf,True,True,False,2019,iclr,iclr_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
99,Preferences Implicit in the State of the World.pdf,True,False,False,2019,iclr,iclr_2019,0,(?:discount|reward)\s+function,,,,,,,pets,,,,,,
100,Sample Efficient Imitation Learning for Continuous Control.pdf,True,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
101,Plan Online Learn Offline Efficient Learning and Exploration via Model-Based Control.pdf,False,False,False,2019,iclr,iclr_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
102,Learning to Design RNA.pdf,True,False,False,2019,iclr,iclr_2019,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,,,,,,
103,Rigorous Agent Evaluation An Adversarial Approach to Uncover Catastrophic Failures.pdf,False,False,False,2019,iclr,iclr_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,a2c,,,,
104,Deep learning generalizes because the parameter-function map is biased towards simple functions.pdf,True,False,False,2019,iclr,iclr_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,sac,,,,,,
105,Large-Scale Study of Curiosity-Driven Learning.pdf,False,True,False,2019,iclr,iclr_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
106,Directed-Info GAIL Learning Hierarchical Policies from Unsegmented Demonstrations using Directed Inf.pdf,False,False,False,2019,iclr,iclr_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
107,Adversarial Imitation via Variational Inverse Reinforcement Learning.pdf,False,False,False,2019,iclr,iclr_2019,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,trpo,ppo,dqn,,,,
108,SNAS stochastic neural architecture search.pdf,False,True,False,2019,iclr,iclr_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
109,Exploration by random network distillation.pdf,False,False,False,2019,iclr,iclr_2019,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
0,Rapid Task-Solving in Novel Environments.pdf,False,True,False,2021,iclr,iclr_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
1,Regularized Inverse Reinforcement Learning.pdf,False,False,False,2021,iclr,iclr_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
2,Reinforcement Learning with Random Delays.pdf,False,True,False,2021,iclr,iclr_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
3,Parameter-Based Value Functions.pdf,True,True,False,2021,iclr,iclr_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,ddpg,,,,,
4,Blending MPC  Value Function Approximation for Efficient Reinforcement Learning.pdf,True,True,False,2021,iclr,iclr_2021,1-5,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
5,Greedy-GQ with Variance Reduction Finite-time Analysis and Improved Complexity.pdf,False,False,False,2021,iclr,iclr_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
6,Simple Augmentation Goes a Long Way ADRL for DNN Quantization.pdf,False,False,False,2021,iclr,iclr_2021,0,(?:discount|reward)\s+function,,,,,,,dqn,ddpg,sac,,,,
7,Deep symbolic regression Recovering mathematical expressions from data via risk-seeking policy gradi.pdf,True,True,False,2021,iclr,iclr_2021,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,ppo,sac,,,,,
8,Data-Efficient Reinforcement Learning with Self-Predictive Representations.pdf,True,False,False,2021,iclr,iclr_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
9,Autoregressive Dynamics Models for Offline Policy Evaluation and Optimization.pdf,False,False,False,2021,iclr,iclr_2021,0,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
10,Benchmarks for Deep Off-Policy Evaluation.pdf,True,False,False,2021,iclr,iclr_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
11,Variational Intrinsic Control Revisited.pdf,False,False,False,2021,iclr,iclr_2021,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
12,Temporally-Extended Îµ-Greedy Exploration.pdf,False,True,False,2021,iclr,iclr_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
13,Differentiable Trust Region Layers for Deep Reinforcement Learning.pdf,True,False,False,2021,iclr,iclr_2021,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,value\s+function\s+approximation,,,,,,trpo,ppo,,,,,
14,Optimizing Memory Placement using Evolutionary Graph Reinforcement Learning.pdf,False,False,False,2021,iclr,iclr_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,dqn,sac,,,,,
15,Balancing Constraints and Rewards with Meta-Gradient D4PG.pdf,True,False,False,2021,iclr,iclr_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ddpg,,,,,,
16,Contrastive Explanations for Reinforcement Learning via Embedded Self Predictions.pdf,False,True,False,2021,iclr,iclr_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
17,My Body is a Cage the Role of Morphology in Graph-Based Incompatible Control.pdf,True,False,False,2021,iclr,iclr_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,ddpg,,,
18,Drop-Bottleneck Learning Discrete Compressed Representation for Noise-Robust Exploration.pdf,True,False,False,2021,iclr,iclr_2021,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,sac,,,,,
19,Discovering Diverse Multi-Agent Strategic Behavior via Reward Randomization.pdf,True,False,False,2021,iclr,iclr_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
20,Learning Safe Multi-agent Control with Decentralized Neural Barrier Certificates.pdf,False,False,False,2021,iclr,iclr_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,ddpg,,,,
21,Control-Aware Representations for Model-based Reinforcement Learning.pdf,False,False,False,2021,iclr,iclr_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,dreamer,sac,,,,,
22,Model-Based Offline Planning.pdf,False,False,False,2021,iclr,iclr_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
23,Monte-Carlo Planning and Learning with Language Action Value Estimates.pdf,True,False,False,2021,iclr,iclr_2021,over 10,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,sac,,,
24,Risk-Averse Offline Reinforcement Learning.pdf,True,True,False,2021,iclr,iclr_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
25,Meta-Learning of Structured Task Distributions in Humans and Machines.pdf,False,False,False,2021,iclr,iclr_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
26,Randomized Ensembled Double Q-Learning Learning Fast Without a Model.pdf,True,True,False,2021,iclr,iclr_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,,,,,ppo,dqn,ddpg,sac,,,
27,Planning from Pixels using Inverse Dynamics Models.pdf,True,True,False,2021,iclr,iclr_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
28,Self-supervised Visual Reinforcement Learning with Object-centric Representations.pdf,True,False,False,2021,iclr,iclr_2021,1-5,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
29,C-Learning Learning to Achieve Goals via Recursive Classification.pdf,False,False,False,2021,iclr,iclr_2021,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,dqn,sac,,,,
30,UPDeT Universal Multi-agent RL via Policy Decoupling with Transformers.pdf,True,False,False,2021,iclr,iclr_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
31,Image Augmentation Is All You Need Regularizing Deep Reinforcement Learning from Pixels.pdf,True,True,False,2021,iclr,iclr_2021,6-10,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,dqn,sac,,,
32,Batch Reinforcement Learning Through Continuation Method.pdf,False,False,False,2021,iclr,iclr_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,ppo,dqn,sac,,,,
33,What are the Statistical Limits of Offline RL with Linear Function Approximation.pdf,False,False,False,2021,iclr,iclr_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,,,,,ppo,,,,,,
34,Solving Compositional Reinforcement Learning Problems via Task Reduction.pdf,True,True,False,2021,iclr,iclr_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
35,CausalWorld A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning.pdf,True,False,False,2021,iclr,iclr_2021,0,(?:discount|reward)\s+function,,,,,,,td3,ppo,sac,,,,
36,X2T Training an X-to-Text Typing Interface with Online Learning from User Feedback.pdf,False,False,False,2021,iclr,iclr_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
37,Policy-Driven Attack Learning to Query for Hard-label Black-box Adversarial Examples.pdf,True,False,False,2021,iclr,iclr_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,td3,,,,,,
38,Mastering Atari with Discrete World Models.pdf,True,True,False,2021,iclr,iclr_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dreamer,ppo,dqn,,,,
39,Fuzzy Tiling Activations A Simple Approach to Learning Sparse Representations Online.pdf,True,True,False,2021,iclr,iclr_2021,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,ppo,dqn,ddpg,,,,
40,Hierarchical Reinforcement Learning by Discovering Intrinsic Options.pdf,True,False,False,2021,iclr,iclr_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
41,Adapting to Reward Progressivity via Spectral Reinforcement Learning.pdf,True,False,False,2021,iclr,iclr_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,ppo,dqn,,,,,
42,Off-Dynamics Reinforcement Learning Training for Transfer with Domain Classifiers.pdf,True,True,False,2021,iclr,iclr_2021,1-5,(?:discount|reward)\s+function,,,,,,,pets,ppo,sac,,,,
43,RODE Learning Roles to Decompose Multi-Agent Tasks.pdf,False,False,False,2021,iclr,iclr_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,dqn,ddpg,sac,,,
44,Parrot Data-Driven Behavioral Priors for Reinforcement Learning.pdf,False,True,False,2021,iclr,iclr_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,pets,ppo,dqn,sac,,,
45,Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks.pdf,True,False,False,2021,iclr,iclr_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,ddpg,,,,,
46,Transient Non-stationarity and Generalisation in Deep Reinforcement Learning.pdf,True,True,False,2021,iclr,iclr_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
47,Human-Level Performance in No-Press Diplomacy via Equilibrium Search.pdf,False,False,False,2021,iclr,iclr_2021,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,a2c,,,,
48,Grounding Language to Autonomously-Acquired Skills via Goal Generation.pdf,False,True,False,2021,iclr,iclr_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
49,Reset-Free Lifelong Learning with Skill-Space Planning.pdf,True,False,False,2021,iclr,iclr_2021,1-5,(?:discount|reward)\s+function,,,,,,,pets,ppo,dqn,sac,,,
50,C-Learning Horizon-Aware Cumulative Accessibility Estimation.pdf,True,True,False,2021,iclr,iclr_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td3,ppo,,
51,Ask Your Humans Using Human Instructions to Improve Generalization in Reinforcement Learning.pdf,True,False,False,2021,iclr,iclr_2021,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
52,Primal Wasserstein Imitation Learning.pdf,False,True,False,2021,iclr,iclr_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,td3,ppo,
53,Discovering Non-monotonic Autoregressive Orderings with Variational Inference.pdf,False,False,False,2021,iclr,iclr_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
54,Provable Rich Observation Reinforcement Learning with Combinatorial Latent States.pdf,True,False,False,2021,iclr,iclr_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
55,The Importance of Pessimism in Fixed-Dataset Policy Optimization.pdf,True,True,False,2021,iclr,iclr_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
56,QPLEX Duplex Dueling Multi-Agent Q-Learning.pdf,False,False,False,2021,iclr,iclr_2021,6-10,action-value\s+function,,,,,,,ppo,dqn,sac,,,,
57,Latent Skill Planning for Exploration and Transfer.pdf,False,True,False,2021,iclr,iclr_2021,1-5,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
58,Mutual Information State Intrinsic Control.pdf,True,True,False,2021,iclr,iclr_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,ddpg,,,,
59,Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning.pdf,False,True,False,2021,iclr,iclr_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
60,Return-Based Contrastive Representation Learning for Reinforcement  Learning.pdf,True,False,False,2021,iclr,iclr_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
61,Efficient Reinforcement Learning in Factored MDPs with Application to Constrained RL.pdf,False,False,False,2021,iclr,iclr_2021,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
62,Adaptive Procedural Task Generation for Hard-Exploration Problems.pdf,True,True,False,2021,iclr,iclr_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
63,Efficient Wasserstein Natural Gradients for Reinforcement Learning.pdf,True,True,False,2021,iclr,iclr_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,,,,,
64,Robust Reinforcement Learning on State Observations with Learned Optimal Adversary.pdf,True,True,False,2021,iclr,iclr_2021,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,trpo,dqn,ddpg,sac,ppo,,
65,Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation.pdf,False,False,False,2021,iclr,iclr_2021,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
66,DOP Off-Policy Multi-Agent Decomposed Policy Gradients.pdf,False,True,False,2021,iclr,iclr_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
67,Acting in Delayed Environments with Non-Stationary Markov Policies.pdf,True,False,False,2021,iclr,iclr_2021,1-5,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
68,DeepAveragers Offline Reinforcement Learning By Solving Derived Non-Parametric MDPs.pdf,False,True,False,2021,iclr,iclr_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
69,Representation Balancing Offline Model-based Reinforcement Learning.pdf,True,False,False,2021,iclr,iclr_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,sac,,,
70,Genetic Soft Updates for Policy Evolution in Deep Reinforcement Learning.pdf,False,True,False,2021,iclr,iclr_2021,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,ddpg,,,
71,Learning with AMIGo Adversarially Motivated Intrinsic Goals.pdf,True,True,False,2021,iclr,iclr_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
72,Conservative Safety Critics for Exploration.pdf,False,False,False,2021,iclr,iclr_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
73,Learning Robust State Abstractions for Hidden-Parameter Block MDPs.pdf,False,False,False,2021,iclr,iclr_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,sac,,,,,,
74,Enforcing robust control guarantees within neural network policies.pdf,True,False,False,2021,iclr,iclr_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
75,Optimism in Reinforcement Learning with Generalized Linear Function Approximation.pdf,False,False,False,2021,iclr,iclr_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
76,Communication in Multi-Agent Reinforcement Learning Intention Sharing.pdf,False,False,False,2021,iclr,iclr_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,,,,
77,Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization.pdf,True,False,False,2021,iclr,iclr_2021,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
78,Regularization Matters in Policy Optimization - An Empirical Study on Continuous Control.pdf,True,True,False,2021,iclr,iclr_2021,6-10,state-action\s+pairs,,,,,,,trpo,sac,ddpg,a2c,ppo,,
79,Scalable Bayesian Inverse Reinforcement Learning.pdf,True,False,False,2021,iclr,iclr_2021,0,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
80,Correcting experience replay for multi-agent communication.pdf,True,True,False,2021,iclr,iclr_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
81,Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning.pdf,False,True,False,2021,iclr,iclr_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
82,OPAL Offline Primitive Discovery for Accelerating Offline Reinforcement Learning.pdf,True,False,False,2021,iclr,iclr_2021,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
83,Winning the L2RPN Challenge Power Grid Management via Semi-Markov Afterstate Actor-Critic.pdf,True,True,False,2021,iclr,iclr_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,a3c,dqn,a2c,sac,ppo,,
84,Sample-Efficient Automated Deep Reinforcement Learning.pdf,True,True,False,2021,iclr,iclr_2021,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,ppo,dqn,ddpg,,,
85,Evolving Reinforcement Learning Algorithms.pdf,True,True,False,2021,iclr,iclr_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,sac,,,,
86,Self-Supervised Policy Adaptation during Deployment.pdf,True,False,False,2021,iclr,iclr_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,a2c,,,,
87,Molecule Optimization by Explainable Evolution.pdf,True,False,False,2021,iclr,iclr_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
88,Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown Dynamics.pdf,True,False,False,2021,iclr,iclr_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,,,,
89,Extracting Strong Policies for Robotics Tasks from Zero-Order Trajectory Optimizers.pdf,True,True,False,2021,iclr,iclr_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
90,Modelling Hierarchical Structure between Dialogue Policy and Natural Language Generator with Option .pdf,True,True,False,2021,iclr,iclr_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,sac,,,,,,
91,Learning Generalizable Visual Representations via Interactive Gameplay.pdf,False,False,False,2021,iclr,iclr_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a3c,ppo,a2c,,,,
92,Learning Invariant Representations for Reinforcement Learning without Reconstruction.pdf,True,True,False,2021,iclr,iclr_2021,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,pets,ppo,dqn,sac,,,
93,Learning Deep Features in Instrumental Variable Regression.pdf,True,True,False,2021,iclr,iclr_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
94,SMiRL Surprise Minimizing Reinforcement Learning in Unstable Environments.pdf,True,False,False,2021,iclr,iclr_2021,over 10,(?:discount|reward)\s+function,,,,,,,trpo,ppo,dqn,sac,,,
95,Symmetry-Aware Actor-Critic for 3D Molecular Design.pdf,True,False,False,2021,iclr,iclr_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
96,FOCAL Efficient Fully-Offline Meta-Reinforcement Learning via Distance Metric Learning and Behavior .pdf,True,False,False,2021,iclr,iclr_2021,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
97,Learning to Represent Action Values as a Hypergraph on the Action Vertices.pdf,True,False,False,2021,iclr,iclr_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,sac,,,
98,Learning to Sample with Local and Global Contexts  in Experience Replay Buffer.pdf,True,False,False,2021,iclr,iclr_2021,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,dqn,ddpg,sac,td3,ppo,,
99,Behavioral Cloning from Noisy Demonstrations.pdf,True,False,False,2021,iclr,iclr_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
100,Learning What To Do by Simulating the Past.pdf,True,True,False,2021,iclr,iclr_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
101,Non-asymptotic Confidence Intervals of Off-policy Evaluation  Primal and Dual Bounds.pdf,True,False,False,2021,iclr,iclr_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
102,Model-Based Visual Planning with Self-Supervised Functional Distances.pdf,True,True,False,2021,iclr,iclr_2021,6-10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,dqn,sac,td3,ppo,dreamer,,
103,Rank the Episodes A Simple Approach for Exploration in Procedurally-Generated Environments.pdf,True,False,False,2021,iclr,iclr_2021,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
104,Learning to Reach Goals via Iterated Supervised Learning.pdf,True,True,False,2021,iclr,iclr_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,td3,ppo,dqn,,,
105,Domain-Robust Visual Imitation Learning with Mutual Information Constraints.pdf,True,False,False,2021,iclr,iclr_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
106,Learning Subgoal Representations with Slow Dynamics.pdf,True,True,False,2021,iclr,iclr_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
0,Hinge Policy Optimization Rethinking Policy Improvement and Reinterpreting PPO.pdf,True,False,False,2022,iclr,iclr_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
1,Human-Level Control without Server-Grade Hardware.pdf,True,False,False,2022,iclr,iclr_2022,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,dqn,sac,,,,
2,Know Your Action Set Learning Action Relations for Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,,,,
3,Information Prioritization through Empowerment in Visual Model-based RL.pdf,False,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
4,On Multi-objective Policy Optimization as a Tool for Reinforcement Learning Case Studies in Offline .pdf,False,False,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
5,Hindsight Foresight Relabeling for Meta-Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
6,HyperDQN A Randomized Exploration Method for Deep Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,,,,,ppo,dqn,a2c,sac,,,
7,Evolution Strategies as an Alternate Learning method for Hierarchical Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
8,CROP Certifying Robust Policies for Reinforcement Learning through Functional Smoothing.pdf,True,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
9,Safe Deep RL in 3D Environments using Human Feedback.pdf,False,True,False,2022,iclr,iclr_2022,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
10,Modeling Bounded Rationality in Multi-Agent Simulations Using Rationally Inattentive Reinforcement L.pdf,False,False,False,2022,iclr,iclr_2022,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
11,A General Theory of Relativity in Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,ppo,,,,,
12,Bayesian Exploration for Lifelong Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,pets,ppo,sac,,,,
13,Transfer RL across Observation Feature Spaces via Model-Based Regularization.pdf,True,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
14,Model-Invariant State Abstractions for Model-Based Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,pets,,,
15,Benchmarking Sample Selection Strategies for Batch Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,dqn,sac,,,,
16,ScheduleNet Learn to solve multi-agent scheduling problems with reinforcement learning.pdf,False,True,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
17,Soft Actor-Critic with Inhibitory Networks for Faster Retraining.pdf,False,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,dqn,ddpg,sac,td3,ppo,,
18,Closed-Loop Control of Additive Manufacturing via Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
19,Learning Altruistic Behaviours in Reinforcement Learning without External Rewards.pdf,True,True,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
20,Understanding the Generalization Gap in Visual Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,,,,
21,Pareto Policy Pool for Model-based Offline Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,,,,
22,Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL.pdf,True,True,False,2022,iclr,iclr_2022,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
23,Learning a subspace of policies for online adaptation in Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,td3,ppo,sac,a2c,,,
24,Stability and Generalisation in Batch Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,,,,,,
25,On the Convergence of the Monte Carlo Exploring Starts Algorithm for Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
26,Learning transferable motor skills with hierarchical latent mixture policies.pdf,False,False,False,2022,iclr,iclr_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
27,Analytically Tractable Bayesian Deep Q-Learning.pdf,True,True,False,2022,iclr,iclr_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,dqn,,,,,,
28,Learning Value Functions from Undirected State-only Experience.pdf,False,False,False,2022,iclr,iclr_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,,,,
29,Policy Smoothing for Provably Robust Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
30,Imitation Learning from Observations under Transition Model Disparity.pdf,False,True,False,2022,iclr,iclr_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
31,The Boltzmann Policy Distribution Accounting for Systematic Suboptimality in Human Models.pdf,True,True,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
32,Near-Optimal Algorithms for Autonomous Exploration and Multi-Goal Stochastic Shortest Path.pdf,False,False,False,2022,iclr,iclr_2022,0,state-action\s+pairs,,,,,,,ppo,dqn,sac,,,,
33,Text Generation with Efficient Soft Q-Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
34,EAT-C Environment-Adversarial sub-Task Curriculum for Efficient Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,sac,,,,,,
35,Meta Attention For Off-Policy Actor-Critic.pdf,False,False,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,dqn,ddpg,sac,td3,ppo,,
36,IA-MARL Imputation Assisted Multi-Agent Reinforcement Learning for Missing Training Data.pdf,False,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,,,,,ppo,dqn,ddpg,,,,
37,Offline Meta-Reinforcement Learning with Online Self-Supervision.pdf,True,True,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
38,LIGS Learnable Intrinsic-Reward Generation Selection for Multi-Agent Learning.pdf,False,False,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
39,Retrieval-Augmented Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,dqn,,,,,,
40,Deep Learning of Intrinsically Motivated Options in the Arcade Learning Environment.pdf,True,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
41,Self-Organized Polynomial-time Coordination Graphs.pdf,False,False,False,2022,iclr,iclr_2022,1-5,action-value\s+function,,,,,,,ppo,dqn,sac,,,,
42,Fully Decentralized Model-based Policy Optimization with Networked Agents.pdf,False,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
43,Deep Reinforcement Learning for Equal Risk Option Pricing and Hedging under Dynamic Expectile Risk M.pdf,False,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,sac,,,
44,Bi-linear Value Networks for Multi-goal Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,dqn,ddpg,sac,td3,ppo,,
45,CoBERL Contrastive BERT for Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,dreamer,ppo,dqn,sac,,,
46,Multi-Stage Episodic Control for Strategic Exploration in Text Games.pdf,True,False,False,2022,iclr,iclr_2022,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
47,Understanding and Preventing Capacity Loss in Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
48,The Role of Pretrained Representations for the OOD Generalization of RL Agents.pdf,True,False,False,2022,iclr,iclr_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,td3,ppo,sac,,,
49,Hypothesis Driven Coordinate Ascent for Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,over 10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
50,Reinforcement Learning in Presence of Discrete Markovian Context Evolution.pdf,True,False,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,a2c,sac,,,
51,Decentralized Cross-Entropy Method for Model-Based Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,pets,ppo,sac,,,,
52,Model-Based Offline Meta-Reinforcement Learning with Regularization.pdf,False,False,False,2022,iclr,iclr_2022,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
53,Active Hierarchical Exploration with Stable Subgoal Representation Learning.pdf,True,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
54,DESTA A Framework for Safe Reinforcement Learning with Markov Games of Intervention.pdf,False,False,False,2022,iclr,iclr_2022,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,sac,,,,
55,Weakly-Supervised Learning of Disentangled and Interpretable Skills for Hierarchical Reinforcement L.pdf,False,False,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
56,Actor-critic is implicitly biased towards high entropy optimal policies.pdf,False,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,trpo,ppo,dqn,,,,
57,Offline Pre-trained Multi-Agent Decision Transformer.pdf,False,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
58,Better state exploration using action sequence equivalence.pdf,True,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
59,A First-Occupancy Representation for Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
60,Multi-batch Reinforcement Learning via Sample Transfer and Imitation Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
61,Learning Two-Step Hybrid Policy for Graph-Based Interpretable Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,ppo,dqn,sac,,,,
62,The guide and the explorer smart agents for resource-limited iterated batch reinforcement learning.pdf,True,False,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,pets,dqn,sac,ppo,,
63,Sequoia A Software Framework to Unify Continual Learning Research.pdf,True,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,sac,,,,
64,Reward Uncertainty for Exploration in Preference-based Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,a3c,dqn,sac,ppo,,
65,SAFER Data-Efficient and Safe Reinforcement Learning Through Skill Acquisition.pdf,True,True,False,2022,iclr,iclr_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,sac,,,,,,
66,The Remarkable Effectiveness of Combining Policy and Value Networks in A-based Deep RL for AI Planni.pdf,False,False,False,2022,iclr,iclr_2022,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,,,,,,,ppo,,,,,,
67,Learning Pseudometric-based Action Representations for Offline Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
68,Disentangling Sources of Risk for Distributional Multi-Agent Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
69,A Risk-Sensitive Policy Gradient Method.pdf,False,False,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
70,GPT-Critic Offline Reinforcement Learning for End-to-End Task-Oriented Dialogue Systems.pdf,False,False,False,2022,iclr,iclr_2022,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
71,Help Me Explore Minimal Social Interventions for Graph-Based Autotelic Agents.pdf,True,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
72,Flow-based Recurrent Belief State Learning for POMDPs.pdf,True,True,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,a3c,dreamer,ppo,sac,,,
73,Self-Supervised Structured Representations for Deep Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,dqn,sac,,,
74,On Covariate Shift of Latent Confounders in Imitation and Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
75,Context-Aware Sparse Deep Coordination Graphs.pdf,True,True,False,2022,iclr,iclr_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
76,Adaptive Behavior Cloning Regularization for Stable Offline-to-Online Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,pets,dqn,sac,,,
77,Can Reinforcement Learning Efficiently Find Stackelberg-Nash Equilibria in General-Sum Markov Games.pdf,False,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,dqn,sac,,,,,
78,Offline Decentralized Multi-Agent Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,trpo,dqn,ddpg,,,,
79,Superior Performance with Diversified Strategic Control in FPS Games Using General Reinforcement Lea.pdf,False,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,ppo,sac,ddpg,,,
80,Generalizing Successor Features to continuous domains for Multi-task Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
81,Self Reward Design with Fine-grained Interpretability.pdf,True,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
82,Continual Backprop Stochastic Gradient Descent with Persistent Randomness.pdf,False,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
83,Koopman Q-learning Offline Reinforcement Learning via Symmetries of Dynamics.pdf,False,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
84,WaveCorr Deep Reinforcement Learning with Permutation Invariant Policy Networks for Portfolio Manage.pdf,False,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
85,Targeted Environment Design from Offline Data.pdf,True,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
86,Model-Based Opponent Modeling.pdf,False,True,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
87,Online Tuning for Offline Decentralized Multi-Agent Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,dqn,,,,,,
88,A Simple Reward-free Approach to Constrained Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
89,Xi-learning Successor Feature Transfer Learning for General Reward Functions.pdf,False,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
90,It Takes Four to Tango Multiagent Self Play for Automatic Curriculum Generation.pdf,True,True,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,sac,,,
91,Provably Improved Context-Based Offline Meta-RL with Attention and Contrastive Learning.pdf,False,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
92,Near-optimal Offline Reinforcement Learning with Linear Representation Leveraging Variance Informati.pdf,False,False,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
93,Neural Simulated Annealing.pdf,False,True,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
94,One After Another Learning Incremental Skills for a Changing World.pdf,True,True,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
95,Provable Hierarchy-Based Meta-Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
96,Maximizing Ensemble Diversity in Deep Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,td3,ppo,dqn,sac,,,
97,DRIBO Robust Deep Reinforcement Learning via Multi-View Information Bottleneck.pdf,False,False,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dreamer,ppo,dqn,sac,,,
98,AdaRL What Where and How to Adapt in Transfer Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,,,,
99,Distributional Perturbation for Efficient Exploration in Distributional Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,6-10,action-value\s+function,,,,,,,ppo,dqn,sac,,,,
100,Learning Graphon Mean Field Games and Approximate Nash Equilibria.pdf,False,False,False,2022,iclr,iclr_2022,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
101,Data Sharing without Rewards in Multi-Task Offline Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
102,Orchestrated Value Mapping for Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,,,,,,
103,Who Is the Strongest Enemy Towards Optimal and Efficient Evasion Attacks in Deep RL.pdf,True,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,dqn,a2c,sac,ppo,,
104,TempoRL Temporal Priors for Exploration in Off-Policy Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
105,Nested Policy Reinforcement Learning for Clinical Decision Support.pdf,True,False,False,2022,iclr,iclr_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
106,Adversarial Style Transfer for Robust Policy Optimization in Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,pets,ppo,sac,,,,
107,MixRL Data Mixing Augmentation for Regression using Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,a3c,ppo,,,,,
108,RL-DARTS Differentiable Architecture Search for Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,sac,,,,
109,Temporal abstractions-augmented temporally contrastive learning an alternative to the Laplacian in R.pdf,False,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,ddpg,a2c,,,
110,Learning Controllable Elements Oriented Representations for Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
111,Metrics Matter A Closer Look on Self-Paced Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
112,Reinforcement Learning under a Multi-agent Predictive State Representation Model Method and Theory.pdf,False,False,False,2022,iclr,iclr_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
113,Learning Diverse Options via InfoMax Termination Critic.pdf,True,True,False,2022,iclr,iclr_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,trpo,ppo,a2c,,,,
114,When should agents explore.pdf,True,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
115,Learning Generalizable Representations for Reinforcement Learning via Adaptive Meta-learner of Behav.pdf,True,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
116,Beyond Prioritized Replay Sampling States in Model-Based Reinforcement Learning via Simulated Priori.pdf,True,False,False,2022,iclr,iclr_2022,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,dqn,ddpg,,,,,
117,Lipschitz-constrained Unsupervised Skill Discovery.pdf,True,False,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
118,Divergent representations of ethological visual inputs emerge from supervised unsupervised and reinf.pdf,True,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,ppo,,,,,,
119,Delayed Geometric Discounts An alternative criterion for Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
120,Training Transition Policies via Distribution Matching for Complex Tasks.pdf,True,True,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,dqn,sac,,,
121,Revisiting Design Choices in Offline Model Based Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
122,The Effects of Reward Misspecification Mapping and Mitigating Misaligned Models.pdf,True,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
123,Maximum Entropy Population Based Training for Zero-Shot Human-AI Coordination.pdf,False,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
124,Off-Policy Reinforcement Learning with Delayed Rewards.pdf,True,False,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dqn,ddpg,sac,td3,ppo,,
125,PRIMA Planner-Reasoner Inside a Multi-task Reasoning Agent.pdf,True,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
126,Edge Rewiring Goes Neural Boosting Network Resilience via Policy Gradient.pdf,False,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
127,Near-Optimal Reward-Free Exploration for Linear Mixture MDPs with Plug-in Solver.pdf,False,False,False,2022,iclr,iclr_2022,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
128,Value Gradient weighted Model-Based Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
129,Disentangling Generalization in Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
130,Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games.pdf,False,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
131,Is High Variance Unavoidable in RL A Case Study in Continuous Control.pdf,True,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,dqn,ddpg,sac,,,,
132,Boosting Search Engines with Interactive Agents.pdf,True,True,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,pets,ppo,dqn,sac,,,
133,Direct then Diffuse Incremental Unsupervised Skill Discovery for State Covering and Goal Reaching.pdf,False,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,sac,,,,
134,Multi-Agent Reinforcement Learning with Shared Resource in Inventory Management.pdf,False,True,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,ddpg,a2c,sac,ppo,,
135,Vision-Based Manipulators Need to Also See from Their Hands.pdf,False,True,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
136,Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation.pdf,True,True,False,2022,iclr,iclr_2022,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,sac,,,,
137,Mismatched No More Joint Model-Policy Optimization for Model-Based RL.pdf,False,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,td3,dqn,sac,,,,
138,A Relational Intervention Approach for Unsupervised Dynamics Generalization in Model-Based Reinforce.pdf,True,False,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,pets,ppo,,,,,
139,Dealing with Non-Stationarity in MARL via Trust-Region Decomposition.pdf,True,False,False,2022,iclr,iclr_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,ddpg,,,
140,Why so pessimistic Estimating uncertainties for offline RL through ensembles and why their independe.pdf,False,True,False,2022,iclr,iclr_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
141,Reachability Traces for Curriculum Design in Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,ddpg,,,,,
142,SPLID Self-Imitation Policy Learning through Iterative Distillation.pdf,False,False,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
143,Semi-supervised Offline Reinforcement Learning with Pre-trained Decision Transformers.pdf,False,True,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
144,Detecting Worst-case Corruptions via Loss Landscape Curvature in Deep Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,other,,,,,,
145,Learning When and What to Ask a Hierarchical Reinforcement Learning Framework.pdf,False,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,,,,
146,GrASP Gradient-Based Affordance Selection for Planning.pdf,False,True,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,td3,dreamer,,,,,
147,MetaMorph Learning Universal Controllers with Transformers.pdf,True,False,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
148,Value Function Spaces Skill-Centric State Abstractions for Long-Horizon Reasoning.pdf,True,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,,,,,,
149,Multi-Agent MDP Homomorphic Networks.pdf,True,False,False,2022,iclr,iclr_2022,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
150,Deep Q-Network with Proximal Iteration.pdf,True,True,False,2022,iclr,iclr_2022,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,trpo,dqn,sac,td3,ppo,,
151,SPP-RL State Planning Policy Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,trpo,dqn,ddpg,sac,td3,ppo,
152,Containerized Distributed Value-Based Multi-Agent Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,a3c,ppo,dqn,sac,,,
153,Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage.pdf,False,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
154,An Experimental Design Perspective on Model-Based Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,pets,dqn,sac,td3,ppo,,
155,DARA Dynamics-Aware Reward Augmentation in Offline Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
156,Learning Representations for Pixel-based Control What Matters and Why.pdf,True,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,dqn,sac,,,,
157,Divide and Explore Multi-Agent Separate Exploration with Shared Intrinsic Motivations.pdf,True,True,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
158,Rethinking Goal-Conditioned Supervised Learning and Its Connection to Offline RL.pdf,True,True,False,2022,iclr,iclr_2022,6-10,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,ddpg,,,
159,Influence-Based Reinforcement Learning for Intrinsically-Motivated Agents.pdf,True,True,False,2022,iclr,iclr_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,td3,ppo,
160,Learning to Solve Multi-Robot Task Allocation with a Covariant-Attention based Neural Architecture.pdf,True,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
161,Lagrangian Method for Episodic Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,dqn,sac,,,
162,COptiDICE Offline Constrained Reinforcement Learning via Stationary Distribution Correction Estimati.pdf,False,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,other,,,,,,
163,DR3 Value-Based Deep Reinforcement Learning Requires Explicit Regularization.pdf,False,False,False,2022,iclr,iclr_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
164,OVD-Explorer A General Information-theoretic Exploration Approach for Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,td3,ppo,dqn,sac,,,
165,Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates.pdf,True,False,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
166,Mastering Visual Continuous Control Improved Data-Augmented Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dreamer,dqn,ddpg,sac,,,
167,Offline Reinforcement Learning with Resource Constrained Online Deployment.pdf,True,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,dqn,sac,td3,ppo,,
168,PDQN - A Deep Reinforcement Learning Method for Planning with Long Delays Optimization of Manufactur.pdf,False,True,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
169,DAIR Disentangled Attention Intrinsic Regularization for Safe and Efficient Bimanual Manipulation.pdf,False,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
170,Monotonic Improvement Guarantees under Non-stationarity for Decentralized PPO.pdf,False,False,False,2022,iclr,iclr_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
171,Finding General Equilibria in Many-Agent Economic Simulations using Deep Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,,,,
172,Divergence-Regularized Multi-Agent Actor-Critic.pdf,True,True,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,dqn,sac,,,,
173,Deep Inverse Reinforcement Learning via Adversarial One-Class Classification.pdf,True,False,False,2022,iclr,iclr_2022,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,sac,,,,
174,Adaptive Q-learning for Interaction-Limited Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,trpo,dqn,sac,td3,ppo,,
175,Topological Experience Replay.pdf,True,False,False,2022,iclr,iclr_2022,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
176,Dynamics-Aware Comparison of Learned Reward Functions.pdf,False,False,False,2022,iclr,iclr_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
177,RvS What is Essential for Offline RL via Supervised Learning.pdf,True,True,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
178,Should I Run Offline Reinforcement Learning or Behavioral Cloning.pdf,False,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
179,Learning to Solve Combinatorial Problems via Efficient Exploration.pdf,True,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,a3c,ppo,dqn,sac,,,
180,Reinforcement Learning for Adaptive Mesh Refinement.pdf,False,True,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,ppo,sac,,,,,
181,Robust Losses for Learning Value Functions.pdf,False,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
182,Greedy-based Value Representation for Efficient Coordination in Multi-agent Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
183,rQdia Regularizing Q-Value Distributions With Image Augmentation.pdf,True,False,False,2022,iclr,iclr_2022,over 10,state-action\s+pairs,,,,,,,pets,dqn,ddpg,sac,dreamer,,
184,Goal-Directed Planning via Hindsight Experience Replay.pdf,True,False,False,2022,iclr,iclr_2022,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
185,EVaDE  Event-Based Variational Thompson Sampling for Model-Based Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
186,Reinforcement Learning with Ex-Post Max-Min Fairness.pdf,False,False,False,2022,iclr,iclr_2022,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
187,Learning Synthetic Environments and Reward Networks for Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
188,A Generalised Inverse Reinforcement Learning Framework.pdf,False,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
189,Learning Dynamics Models for Model Predictive Agents.pdf,False,True,False,2022,iclr,iclr_2022,1-5,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,pets,ppo,sac,,,,
190,How memory architecture affects learning in a simple POMDP the two-hypothesis testing problem.pdf,True,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
191,Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,ppo,,
192,Emergent Communication at Scale.pdf,True,True,False,2022,iclr,iclr_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,,,,,
193,Continuous Control With Ensemble Deep Deterministic Policy Gradients.pdf,True,False,False,2022,iclr,iclr_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td3,ppo,,
194,Do Androids Dream of Electric Fences Safety-Aware Reinforcement Learning with Latent Shielding.pdf,False,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
195,mathrmSO2-Equivariant Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
196,Exploiting Minimum-Variance Policy Evaluation for Policy Optimization.pdf,True,False,False,2022,iclr,iclr_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
197,Auto-Encoding Inverse Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
198,Boosted Curriculum Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
199,Robust Imitation via Mirror Descent Inverse Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
200,Continuous Deep Q-Learning in Optimal Control Problems Normalized Advantage Functions Analysis.pdf,False,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,,,,
201,Offline-Online Reinforcement Learning Extending Batch and Online RL.pdf,True,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
202,Gradient Information Matters in Policy Optimization by Back-propagating through Model.pdf,True,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
203,Gradient Importance Learning for Incomplete Observations.pdf,True,True,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
204,The Information Geometry of Unsupervised Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
205,Structure-Aware Transformer Policy for Inhomogeneous Multi-Task Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,ppo,sac,,,,
206,Local Patch AutoAugment with Multi-Agent Collaboration.pdf,False,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,a2c,,,,
207,Recurrent Model-Free RL is a Strong Baseline for Many POMDPs.pdf,True,True,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,sac,a2c,,,
208,Overcoming The Spectral Bias of Neural Value Approximation.pdf,True,False,False,2022,iclr,iclr_2022,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,sac,,,
209,On Lottery Tickets and Minimal Task Representations in Deep Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,ppo,dqn,,,,,
210,Generalized Decision Transformer for Offline Hindsight Information Matching.pdf,True,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
211,Imitation Learning by Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
212,Rewardless Open-Ended Learning ROEL.pdf,True,True,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,pets,ppo,sac,,,,
213,Bootstrapped Meta-Learning.pdf,True,True,False,2022,iclr,iclr_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,,,,,trpo,ppo,dqn,sac,,,
214,State-Action Joint Regularized Implicit Policy for Offline Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,trpo,ppo,dqn,sac,,,
215,Learning Object-Oriented Dynamics for Planning from Text.pdf,True,False,False,2022,iclr,iclr_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,,,,
216,Learning Efficient Online 3D Bin Packing on Packing Configuration Trees.pdf,True,True,False,2022,iclr,iclr_2022,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
217,Distributional Reinforcement Learning with Monotonic Splines.pdf,True,False,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,ddpg,sac,,,
218,Revealing the Incentive to Cause Distributional Shift.pdf,False,False,False,2022,iclr,iclr_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
219,BioLCNet Reward-modulated Locally Connected Spiking Neural Networks.pdf,False,True,False,2022,iclr,iclr_2022,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
220,Improving Hyperparameter Optimization by Planning Ahead.pdf,False,True,False,2022,iclr,iclr_2022,over 10,(?:discount|reward)\s+function,,,,,,,pets,dqn,sac,,,,
221,Batch size-invariance for policy optimization.pdf,False,True,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,sac,,,,
222,Multi-Critic Actor Learning Teaching RL Policies to Act with Style.pdf,True,False,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
223,Closed-loop Control for Online Continual Learning.pdf,False,True,False,2022,iclr,iclr_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
224,On-Policy Model Errors in Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
225,Assisted Learning for Organizations with Limited Imbalanced Data.pdf,False,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
226,In a Nutshell the Human Asked for This Latent Goals for Following Temporal Specifications.pdf,True,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,a3c,ppo,sac,a2c,,,
227,Learning Temporally-Consistent Representations for Data-Efficient Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,sac,,,,,,
228,A Boosting Approach to Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
229,Accelerated Policy Learning with Parallel Differentiable Simulation.pdf,True,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
230,Unifying Top-down and Bottom-up for Recurrent Visual Attention.pdf,False,True,False,2022,iclr,iclr_2022,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
231,Particle Based Stochastic Policy Optimization.pdf,True,True,False,2022,iclr,iclr_2022,1-5,state-action\s+pairs,,,,,,,td3,ppo,dqn,sac,,,
232,Fragment-Based Sequential Translation for Molecular Optimization.pdf,False,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
233,Generalisation in Lifelong Reinforcement Learning through Logical Composition.pdf,True,False,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
234,CIC Contrastive Intrinsic Control for Unsupervised Skill Discovery.pdf,False,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,ddpg,,,,,
235,Communicating via Markov Decision Processes.pdf,True,False,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,a2c,sac,,,
236,ED2 An Environment Dynamics Decomposition Framework for World Model Construction.pdf,True,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,,,,,,
237,Avoiding Overfitting to the Importance Weights in Offline Policy Optimization.pdf,False,False,False,2022,iclr,iclr_2022,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
238,Pareto Policy Adaptation.pdf,True,False,False,2022,iclr,iclr_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
239,PER-ETD A Polynomially Efficient Emphatic Temporal Difference Learning Method.pdf,False,False,False,2022,iclr,iclr_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
240,A Free Lunch from the Noise Provable and Practical Exploration for Representation Learning.pdf,True,True,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
241,Feudal Reinforcement Learning by Reading Manuals.pdf,False,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,other,,,,,,
242,Wish you were here Hindsight Goal Selection for long-horizon dexterous manipulation.pdf,False,False,False,2022,iclr,iclr_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td3,ppo,,
243,C-Planning An Automatic Curriculum for Learning Goal-Reaching Tasks.pdf,True,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
244,Towards Learning to Speak and Hear Through Multi-Agent Communication over a Continuous Acoustic Chan.pdf,False,False,False,2022,iclr,iclr_2022,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,dqn,sac,,,,
245,Model-based Reinforcement Learning with a Hamiltonian Canonical ODE Network.pdf,True,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,dreamer,ppo,sac,,,
246,Anti-Concentrated Confidence Bonuses For Scalable Exploration.pdf,False,True,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,,,,ppo,dqn,sac,,,,
247,Efficient Learning of Safe Driving Policy via Human-AI Copilot Optimization.pdf,False,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
248,Online Ad Hoc Teamwork under Partial Observability.pdf,False,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
249,Gradient play in stochastic games stationary points convergence and sample complexity.pdf,False,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
250,That Escalated Quickly Compounding Complexity by Editing Levels at the Frontier of Agent Capabilitie.pdf,True,True,False,2022,iclr,iclr_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
251,EqR Equivariant Representations for Data-Efficient Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,,,,,,
252,Modular Lifelong Reinforcement Learning via Neural Composition.pdf,True,True,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
253,Q-learning for real time control of heterogeneous microagent collectives.pdf,False,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
254,DATA-DRIVEN EVALUATION  OF TRAINING ACTION SPACE FOR REINFORCEMENT LEARNING.pdf,True,False,False,2022,iclr,iclr_2022,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,sac,,,,,,
255,Learning State Representations via Retracing in Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,over 10,(?:discount|reward)\s+function,,,,,,,a3c,dqn,sac,ppo,dreamer,,
256,Offline Reinforcement Learning with Implicit Q-Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,,,,
257,Local Feature Swapping for Generalization in Reinforcement Learning.pdf,True,True,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,sac,,,,
258,Maximum Entropy RL Provably Solves Some Robust RL Problems.pdf,True,False,False,2022,iclr,iclr_2022,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
259,COPA Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks.pdf,True,False,False,2022,iclr,iclr_2022,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
260,Reinforcement Learning with Efficient Active Feature Acquisition.pdf,False,False,False,2022,iclr,iclr_2022,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,a3c,ppo,sac,,,,
261,Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization.pdf,True,True,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,dqn,sac,td3,ppo,,
262,Benchmarking the Spectrum of Agent Capabilities.pdf,True,False,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dreamer,,,,,
263,Experience Replay More When Its a Key Transition in Deep Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,dqn,ddpg,sac,td3,ppo,,
264,Procedural generalization by planning with self-supervised world models.pdf,False,True,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
265,Finite-Time Convergence and Sample Complexity of Multi-Agent Actor-Critic Reinforcement Learning wit.pdf,False,False,False,2022,iclr,iclr_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
266,Explore and Control with Adversarial Surprise.pdf,True,True,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
267,Learning Long-Term Reward Redistribution via Randomized Return Decomposition.pdf,True,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,ddpg,sac,td3,ppo,,
268,CoMPS Continual Meta Policy Search.pdf,False,True,False,2022,iclr,iclr_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
269,Online Target Q-learning with Reverse Experience Replay Efficiently finding the Optimal Policy for L.pdf,False,False,False,2022,iclr,iclr_2022,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
270,Iterated Reasoning with Mutual Information in Cooperative and Byzantine Decentralized Teaming.pdf,True,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,a2c,,,,
271,When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently.pdf,False,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
272,Improving zero-shot generalization in offline reinforcement learning using generalized similarity fu.pdf,True,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
273,SURF Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based .pdf,True,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
274,Selective Token Generation for Few-shot Language Modeling.pdf,True,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
275,Neural Combinatorial Optimization with Reinforcement Learning  Solving theVehicle Routing Problem wi.pdf,True,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
276,Offline Reinforcement Learning with Value-based Episodic Memory.pdf,True,False,False,2022,iclr,iclr_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
277,Exploring the Robustness of Distributional Reinforcement Learning against Noisy State Observations.pdf,True,False,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
278,On the benefits of deep RL in accelerated MRI sampling.pdf,False,True,False,2022,iclr,iclr_2022,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,ppo,dqn,sac,,,
279,Towards Deployment-Efficient Reinforcement Learning Lower Bound and Optimality.pdf,False,False,False,2022,iclr,iclr_2022,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
280,Transformers are Meta-Reinforcement Learners.pdf,False,True,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,trpo,ppo,dqn,sac,,,
281,CausalDyna Improving Generalization of Dyna-style Reinforcement Learning via Counterfactual-Based Da.pdf,False,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,trpo,sac,,,,,
282,On Reward Maximization and Distribution Matching for Fine-Tuning Language Models.pdf,True,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,,,,,
283,Variance Reduced Domain Randomization for Policy Gradient.pdf,False,False,False,2022,iclr,iclr_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
284,Model-augmented Prioritized Experience Replay.pdf,True,True,False,2022,iclr,iclr_2022,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,dqn,ddpg,sac,td3,ppo,,
285,Role Diversity Matters A Study of Cooperative Training Strategies for Multi-Agent RL.pdf,False,False,False,2022,iclr,iclr_2022,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,trpo,dqn,ddpg,sac,a2c,ppo,
286,Learning Vision-Guided Quadrupedal Locomotion End-to-End with Cross-Modal Transformers.pdf,False,True,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
287,Bootstrapped Hindsight Experience replay with Counterintuitive Prioritization.pdf,False,False,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,dqn,ddpg,sac,ppo,,
288,Polyphonic Music Composition An Adversarial Inverse Reinforcement Learning Approach.pdf,True,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,dqn,,,,
289,Knowledge Infused Decoding.pdf,True,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,pets,dqn,sac,ppo,,
290,Reinforcement Learning with Sparse Rewards using Guidance from Offline Demonstration.pdf,True,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
291,Communication-Efficient Actor-Critic Methods for Homogeneous Markov Games.pdf,False,False,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
292,Robust Robotic Control from Pixels using Contrastive Recurrent State-Space Models.pdf,False,False,False,2022,iclr,iclr_2022,6-10,(?:discount|reward)\s+function,,,,,,,dreamer,sac,,,,,
293,Provably Filtering Exogenous Distractors using Multistep Inverse Dynamics.pdf,True,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
294,Task-Induced Representation Learning.pdf,False,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
295,Surprise Minimizing Multi-Agent Learning with Energy-based Models.pdf,False,False,False,2022,iclr,iclr_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
296,Robust Imitation Learning from Corrupted Demonstrations.pdf,True,False,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
297,Interpreting Reinforcement Policies through Local Behaviors.pdf,False,True,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
298,A Reduction-Based Framework for Conservative Bandits and Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
299,Mean-Variance Efficient Reinforcement Learning by Expected Quadratic Utility Maximization.pdf,True,False,False,2022,iclr,iclr_2022,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
300,Fast Deterministic Stackelberg Actor-Critic.pdf,True,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td3,ppo,,
301,Pessimistic Model Selection for Offline Deep Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
302,Autonomous Reinforcement Learning Formalism and Benchmarking.pdf,True,False,False,2022,iclr,iclr_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,,,,,,
303,Action-Sufficient State Representation Learning for Control with Structural Constraints.pdf,False,True,False,2022,iclr,iclr_2022,0,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,dqn,ddpg,,,
304,Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learnin.pdf,False,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
305,Escaping Stochastic Traps with Aleatoric Mapping Agents.pdf,True,True,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,,,,
306,Representation Learning for Online and Offline RL in Low-rank MDPs.pdf,False,False,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
307,Decentralized Cooperative Multi-Agent Reinforcement Learning with Exploration.pdf,False,True,False,2022,iclr,iclr_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
308,Faster Reinforcement Learning with Value Target Lower Bounding.pdf,False,True,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,dqn,ddpg,sac,td3,ppo,,
309,AlphaZero-based Proof Cost Network to Aid Game Solving.pdf,True,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
310,Learning Minimal Representations with Model Invariance.pdf,False,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
311,Reward Shifting for Optimistic Exploration and Conservative Exploitation.pdf,True,True,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,trpo,dqn,sac,td3,ppo,,
312,Conditional Expectation based Value Decomposition for Scalable On-Demand Ride Pooling.pdf,False,False,False,2022,iclr,iclr_2022,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,sac,,,,,,
313,Transform2Act Learning a Transform-and-Control Policy for Efficient Agent Design.pdf,True,False,False,2022,iclr,iclr_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
314,A Principled Permutation Invariant Approach to Mean-Field Multi-Agent Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
315,Spending Thinking Time Wisely Accelerating MCTS with Virtual Expansions.pdf,True,False,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
316,Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery.pdf,True,False,False,2022,iclr,iclr_2022,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,trpo,dqn,a2c,sac,ppo,,
317,Learning Homophilic Incentives in Sequential Social Dilemmas.pdf,True,False,False,2022,iclr,iclr_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
318,Align-RUDDER Learning From Few Demonstrations by Reward Redistribution.pdf,True,True,False,2022,iclr,iclr_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
319,Why Should I Trust You Bellman Evaluating the Bellman Objective with Off-Policy Data.pdf,True,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,dqn,sac,td3,ppo,,
320,Convergent and Efficient Deep Q Learning Algorithm.pdf,False,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,sac,,,,
321,Learning to Shape Rewards using a Game of Two Partners.pdf,True,False,False,2022,iclr,iclr_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
322,Generative Planning for Temporally Coordinated Exploration in Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,ppo,sac,,,,
323,Evaluating Robustness of Cooperative MARL.pdf,False,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,a3c,dqn,ddpg,sac,ppo,
324,Resmax An Alternative Soft-Greedy Operator for Reinforcement Learning.pdf,False,True,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,,,,,ppo,dqn,,,,,
325,Constrained Policy Optimization via Bayesian World Models.pdf,True,True,False,2022,iclr,iclr_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
326,Variational oracle guiding for reinforcement learning.pdf,True,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
327,Plan Better Amid Conservatism Offline Multi-Agent Reinforcement Learning with Actor Rectification.pdf,True,True,False,2022,iclr,iclr_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,ddpg,,,
328,sbfdelta2-exploration for Reinforcement Learning.pdf,False,False,False,2022,iclr,iclr_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,dqn,,,,,,
329,Occupy  Specify Investigations into a Maximum Credit Assignment Occupancy Objective for Data-efficie.pdf,True,False,False,2022,iclr,iclr_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,sac,,,,
330,Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning.pdf,True,False,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,dqn,sac,,,
331,Continuous Control with Action Quantization from Demonstrations.pdf,True,True,False,2022,iclr,iclr_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,ppo,,
332,Towards Understanding Distributional Reinforcement Learning Regularization Optimization Acceleration.pdf,False,False,False,2022,iclr,iclr_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
333,Zeroth-Order Actor-Critic.pdf,False,True,False,2022,iclr,iclr_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
334,Grounding Aleatoric Uncertainty in Unsupervised Environment Design.pdf,False,True,False,2022,iclr,iclr_2022,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
0,Optimal Conservative Offline RL with General Function Approximation via Augmented Lagrangian.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,ppo,,,,,,
1,MACTA A Multi-agent Reinforcement Learning Approach for Cache Timing Attacks and Detection.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
2,Deep Reinforcement Learning based Insight Selection Policy.pdf,False,False,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,dqn,ddpg,sac,ppo,,
3,Revisiting Higher-Order Gradient Methods for Multi-Agent Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
4,Graph Backup Data Efficient Backup Exploiting Markovian Transitions.pdf,True,False,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,,,,,,,ppo,dqn,,,,,
5,Automatic Curriculum Generation for Reinforcement Learning in Zero-Sum Games.pdf,False,False,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
6,Curriculum Reinforcement Learning via Morphology-Environment Co-Evolution.pdf,False,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
7,Evaluation of Active Feature Acquisition Methods under Missing Data.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,sac,,,,,
8,A sampling framework for value-based reinforcement learning.pdf,True,False,False,2023,iclr,iclr_2023,0,action-value\s+function,,,,,,,ppo,dqn,,,,,
9,Building a Subspace of Policies for Scalable Continual Learning.pdf,False,False,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
10,Learning Zero-Shot Cooperation with Humans Assuming Humans Are Biased.pdf,False,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,ddpg,,,,
11,Q-learning Decision Transformer Leveraging Dynamic Programming for Conditional Sequence Modelling in.pdf,True,False,False,2023,iclr,iclr_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
12,Multi-Agent Sequential Decision-Making via Communication.pdf,True,False,False,2023,iclr,iclr_2023,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
13,Offline Reinforcement Learning with Differentiable Function Approximation is Provably Efficient.pdf,False,False,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
14,When Data Geometry Meets Deep Function Generalizing Offline Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
15,Making Better Decision by Directly Planning in Continuous Control.pdf,True,True,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,dreamer,ppo,sac,,,,
16,ESCHER Eschewing Importance Sampling in Games by Computing a History Value Function to Estimate Regr.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
17,Priors Hierarchy and Information Asymmetry for Skill Transfer in Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
18,Systematic Rectification of Language Models via Dead-end Analysis.pdf,True,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
19,Understanding and Adopting Rational Behavior by Bellman Score Estimation.pdf,True,False,False,2023,iclr,iclr_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
20,Dichotomy of Control Separating What You Can Control from What You Cannot.pdf,True,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
21,Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation Single-Agen.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
22,A General Framework for Sample-Efficient Function Approximation in Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
23,Explicitly Maintaining Diverse Playing Styles in Self-Play.pdf,True,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
24,Best Possible Q-Learning.pdf,False,True,False,2023,iclr,iclr_2023,6-10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
25,Cheap Talk Discovery and Utilization in Multi-Agent Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,dqn,a2c,,,,,
26,Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning.pdf,True,True,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
27,Model-free Reinforcement Learning that Transfers Using Random Reward Features.pdf,False,False,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,dqn,sac,,,
28,LEARNING CONTEXT-AWARE ADAPTIVE SOLVERS TO ACCELERATE QUADRATIC PROGRAMMING.pdf,False,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
29,Emergent collective intelligence from massive-agent cooperation and competition.pdf,True,False,False,2023,iclr,iclr_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,,,,,,
30,Jump-Start Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
31,Performance Bounds for Model and Policy Transfer in Hidden-parameter MDPs.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
32,An Adaptive Entropy-Regularization Framework for Multi-Agent Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,,,,,ppo,dqn,sac,,,,
33,Emergence of Exploration in Policy Gradient Reinforcement Learning via Resetting.pdf,False,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,sac,a2c,,,,
34,Go-Explore with a guide Speeding up search in sparse reward settings with goal-directed intrinsic re.pdf,False,True,False,2023,iclr,iclr_2023,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
35,Understanding Hindsight Goal Relabeling Requires Rethinking Divergence Minimization.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
36,Parallel Q-Learning Scaling Off-policy Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,a3c,dqn,ddpg,a2c,sac,ppo,
37,Adversarial Cheap Talk.pdf,True,False,False,2023,iclr,iclr_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
38,Benchmarking Constraint Inference in Inverse Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,ppo,,,,,,
39,Co-Evolution As More Than a Scalable Alternative for Multi-Agent Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,dqn,,,,
40,Model-based Value Exploration in Actor-critic Deep Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,td3,ppo,
41,Entropy-Regularized Model-Based Offline Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
42,Learning to Communicate using Contrastive Learning.pdf,True,True,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
43,Predicting Drug Repurposing Candidates and Their Mechanisms from A Biomedical Knowledge Graph.pdf,True,True,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
44,Momentum Boosted Episodic Memory for Improving Learning in Long-Tailed RL Environments.pdf,False,False,False,2023,iclr,iclr_2023,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
45,Become a Proficient Player with Limited Data through Watching Pure Videos.pdf,True,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,ppo,dqn,,,,
46,Deep Learning of Intrinsically Motivated Options in the Arcade Learning Environment.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
47,Learning Soft Constraints From Constrained Expert Demonstrations.pdf,True,True,False,2023,iclr,iclr_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
48,Feasible Adversarial Robust Reinforcement Learning for Underspecified Environments.pdf,False,True,False,2023,iclr,iclr_2023,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
49,Cyclophobic Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,,,,,ppo,a2c,,,,,
50,Impossibly Good Experts and How to Follow Them.pdf,True,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,sac,,,,
51,Reinforcement Learning-Based Estimation for Partial Differential Equations.pdf,True,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
52,Joint-Predictive Representations for Multi-Agent Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,1-5,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
53,Learning Representations for Reinforcement Learning with Hierarchical Forward Models.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,dreamer,sac,,,,,
54,Safe Reinforcement Learning with Contrastive Risk Prediction.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,pets,ppo,dqn,sac,,,
55,Goal-Space Planning with Subgoal Models.pdf,True,True,False,2023,iclr,iclr_2023,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
56,Efficient Reward Poisoning Attacks on Online Deep Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,a2c,td3,ppo,
57,TEMPERA Test-Time Prompt Editing via Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
58,Beyond Reward Offline Preference-guided Policy Optimization.pdf,True,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
59,On the Importance of the Policy Structure in Offline Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,dqn,,,,
60,Learning Simultaneous Navigation and Construction in Grid Worlds.pdf,True,True,False,2023,iclr,iclr_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
61,Speeding up Policy Optimization with Vanishing Hypothesis and Variable Mini-Batch Size.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
62,Value Memory Graph A Graph-Structured World Model for Offline Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
63,Offline RL of the Underlying MDP from Heterogeneous Data Sources.pdf,False,False,False,2023,iclr,iclr_2023,0,state-action\s+pairs,,,,,,,ppo,,,,,,
64,Accelerating Inverse Reinforcement Learning with Expert Bootstrapping.pdf,True,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
65,DEP-RL Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems.pdf,True,True,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
66,A Connection between One-Step Regularization and Critic Regularization in Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
67,Policy-Based Self-Competition for Planning Problems.pdf,True,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,,,,,,
68,Neural Episodic Control with State Abstraction.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,ddpg,sac,td3,ppo,,
69,Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
70,Minimal Value-Equivalent Partial Models for Scalable and Robust Planning in Lifelong Reinforcement L.pdf,True,True,False,2023,iclr,iclr_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
71,Effective Offline Reinforcement Learning via Conservative State Value Estimation.pdf,True,False,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,,,,
72,Replay Buffer with Local Forgetting for Adaptive Deep Model-Based Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
73,Memory-Efficient Reinforcement Learning with Priority based on Surprise and On-policyness.pdf,False,True,False,2023,iclr,iclr_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,trpo,ppo,dqn,sac,,,
74,Simplifying Model-based RL Learning Representations Latent-space Models and Policies with One Object.pdf,False,True,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td3,ppo,dreamer,
75,Hybrid RL Using both offline and online data can make RL efficient.pdf,True,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
76,UTS When Monotonic Value Factorisation Meets Non-monotonic and Stochastic Targets.pdf,False,False,False,2023,iclr,iclr_2023,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
77,The guide and the explorer smart agents for resource-limited iterated batch reinforcement learning.pdf,True,True,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,ppo,dqn,sac,,,
78,When and Why Is Pretraining Object-Centric Representations Good for Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
79,Minimum Description Length Control.pdf,False,False,False,2023,iclr,iclr_2023,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,sac,,,,,,
80,Improving Deep Policy Gradients with Value Function Search.pdf,False,True,False,2023,iclr,iclr_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,,,,td3,ppo,sac,ddpg,,,
81,LEARNING DYNAMIC ABSTRACT REPRESENTATIONS FOR SAMPLE-EFFICIENT REINFORCEMENT LEARNING.pdf,False,False,False,2023,iclr,iclr_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
82,Learning Control by Iterative Inversion.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,a2c,,,,
83,Let Offline RL Flow Training Conservative Agents in the Latent Space of Normalizing Flow.pdf,False,True,False,2023,iclr,iclr_2023,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
84,Contextual Subspace Approximation with Neural Householder Transforms.pdf,True,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,ddpg,,,,,
85,A Reinforcement Learning Approach to Estimating Long-term Treatment Effects.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
86,Variational Reparametrized Policy Learning with Differentiable Physics.pdf,False,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
87,On the Geometry of Reinforcement Learning in Continuous State and Action Spaces.pdf,True,True,False,2023,iclr,iclr_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,ddpg,,,,
88,OT-1 Convergence of Optimistic-Follow-the-Regularized-Leader in Two-Player Zero-Sum Markov Games.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
89,How to Enable Uncertainty Estimation in Proximal Policy Optimization.pdf,False,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,a2c,,,
90,Variance Double-Down The Small Batch Size Anomaly in Multistep Deep Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,dqn,sac,,,,
91,User-Interactive Offline Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,td3,ppo,sac,,,,
92,Provably efficient multi-task Reinforcement Learning in large state spaces.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,other,,,,,,
93,Consciousness-Aware Multi-Agent Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,,,,
94,Provably Efficient Risk-Sensitive Reinforcement Learning Iterated CVaR and Worst Path.pdf,False,False,False,2023,iclr,iclr_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
95,Return Augmentation gives Supervised RL Temporal Compositionality.pdf,True,False,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
96,Example-based Planning via Dual Gradient Fields.pdf,False,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
97,ConserWeightive Behavioral Cloning for Reliable Offline Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,dqn,,,,
98,Offline Policy Comparison with Confidence Benchmarks and Baselines.pdf,True,False,False,2023,iclr,iclr_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
99,Energy-based Predictive Representation for Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dreamer,ppo,dqn,sac,,,
100,Hierarchies of Reward Machines.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
101,Bi-Level Dynamic Parameter Sharing among Individuals and Teams for Promoting Collaborations in Multi.pdf,False,False,False,2023,iclr,iclr_2023,1-5,action-value\s+function,,,,,,,ppo,dqn,,,,,
102,Partially Observable RL with B-Stability Unified Structural Condition and Sharp Sample-Efficient Alg.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
103,Behavior Proximal Policy Optimization.pdf,True,True,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,dqn,sac,td3,ppo,,
104,Imitating Graph-Based Planning with Goal-Conditioned Policies.pdf,True,True,False,2023,iclr,iclr_2023,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
105,The Role of Coverage in Online Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
106,On the Sensitivity of Reward Inference to Misspecified Human Models.pdf,False,False,False,2023,iclr,iclr_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
107,Multi-Agent Multi-Game Entity Transformer.pdf,False,True,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
108,Fantastic Rewards and How to Tame Them A Case Study on Reward Learning for Task-oriented Dialogue Sy.pdf,True,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
109,In-context Reinforcement Learning with Algorithm Distillation.pdf,False,True,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a3c,ppo,dqn,a2c,,,
110,Towards Global Optimality in Cooperative MARL with Sequential Transformation.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,trpo,ppo,dqn,ddpg,,,
111,Efficient Exploration via Fragmentation and Recall.pdf,True,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
112,Deep Transformer Q-Networks for Partially Observable Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
113,Incorporating Explicit Uncertainty Estimates into Deep Offline Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
114,High-dimensional Continuum Armed and High-dimensional Contextual Bandit with Applications to Assortm.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
115,Latent State Marginalization as a Low-cost Approach for Improving Exploration.pdf,True,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,td3,dreamer,dqn,sac,,,
116,Iteratively Learning Novel Strategies with Diversity Measured in State Distances.pdf,True,True,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
117,Uncertainty-Driven Exploration for Generalization in Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,dreamer,ppo,dqn,sac,,,
118,Raisin Residual Algorithms for Versatile Offline Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,td3,dqn,sac,,,,
119,Memory Gym Partially Observable Challenges to Memory-Based Agents.pdf,True,True,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,ppo,sac,a2c,,,
120,Robust Policy Optimization in Deep Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
121,Guiding Safe Exploration with Weakest Preconditions.pdf,True,True,False,2023,iclr,iclr_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
122,DISCO-DANCE Learning to Discover Skills with Guidance.pdf,False,False,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,sac,,,,,,
123,Reward Design with Language Models.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
124,Learning a Data-Driven Policy Network for Pre-Training Automated Feature Engineering.pdf,True,True,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
125,Designing and Using Goal-Conditioned Tools.pdf,True,True,False,2023,iclr,iclr_2023,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
126,Mutual Information Regularized Offline Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,td3,dqn,sac,,,
127,Skill-Based Reinforcement Learning with Intrinsic Reward Matching.pdf,False,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,td3,,,,,,
128,Auto-Encoding Adversarial Imitation Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
129,The Challenges of Exploration for Offline Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,other,,,,,,
130,Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery.pdf,True,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,sac,,,,
131,System Identification as a Reinforcement Learning Problem.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
132,VIPeR Provably Efficient Algorithm for Offline RL with Neural Function Approximation.pdf,True,True,False,2023,iclr,iclr_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
133,Skill Machines Temporal Logic Composition in Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,td3,dqn,ddpg,,,,
134,Advantage Constrained Proximal Policy Optimization in Multi-Agent Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
135,On the Fast Convergence of Unstable Reinforcement Learning Problems.pdf,False,False,False,2023,iclr,iclr_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,,,,,,
136,On the Power of Pre-training for Generalization in RL Provable Benefits and Hardness.pdf,False,False,False,2023,iclr,iclr_2023,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
137,A System for Morphology-Task Generalization via Unified Representation and Behavior Distillation.pdf,True,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
138,Reward Learning with Trees Methods and Evaluation.pdf,False,True,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,pets,ppo,dqn,sac,,,
139,Behavior Prior Representation learning for Offline Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,6-10,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,dqn,,,,,
140,Pessimism in the Face of Confounders Provably Efficient Offline Reinforcement Learning in Partially .pdf,False,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
141,Partial Advantage Estimator for Proximal Policy Optimization.pdf,True,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
142,VIP Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training.pdf,True,True,False,2023,iclr,iclr_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,pets,ppo,dqn,,,,
143,Understanding the Complexity Gains of Contextual Multi-task RL with Curricula.pdf,True,True,False,2023,iclr,iclr_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,ddpg,,,,
144,Deep autoregressive density nets vs neural ensembles for model-based offline reinforcement learning.pdf,False,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
145,Investigating Multi-task Pretraining and Generalization in Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
146,Convergence Rate of Primal-Dual Approach to Constrained Reinforcement Learning with Softmax Policy.pdf,False,False,False,2023,iclr,iclr_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
147,ERL-Re2 Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individua.pdf,True,True,False,2023,iclr,iclr_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,,,,,td3,sac,ddpg,,,,
148,Parameterized projected Bellman operator.pdf,False,False,False,2023,iclr,iclr_2023,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
149,Provably Efficient Lifelong Reinforcement Learning with Linear Representation.pdf,False,False,False,2023,iclr,iclr_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
150,How Does Value Distribution in Distributional Reinforcement Learning Help Optimization.pdf,False,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,ppo,dqn,sac,,,,
151,GoBigger A Scalable Platform for Cooperative-Competitive Multi-Agent Interactive Simulation.pdf,True,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
152,Learning Rewards and Skills to Follow Commands with a Data Efficient Visual-Audio Representation.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
153,Representation Interference Suppression via Non-linear Value Factorization for Indecomposable Markov.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
154,Pretraining the Vision Transformer using self-supervised methods for vision based Deep Reinforcement.pdf,True,True,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
155,Decentralized Optimistic Hyperpolicy Mirror Descent Provably No-Regret Learning in Markov Games.pdf,False,False,False,2023,iclr,iclr_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
156,EUCLID Towards Efficient Unsupervised Reinforcement Learning with Multi-choice Dynamics Model.pdf,True,False,False,2023,iclr,iclr_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,ddpg,,,,
157,Stein Variational Goal Generation for adaptive Exploration in Multi-Goal Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,ddpg,,,,,
158,Population-Based Reinforcement Learning for Combinatorial Optimization Problems.pdf,True,False,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
159,Q-learning with regularization converges with non-linear non-stationary features.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
160,Improved Sample Complexity for Reward-free Reinforcement Learning under Low-rank MDPs.pdf,False,False,False,2023,iclr,iclr_2023,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
161,Can Wikipedia Help Offline Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
162,Human-AI Coordination via Human-Regularized Search and Learning.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
163,Very Large Scale Multi-Agent Reinforcement Learning with Graph Attention Mean Field.pdf,True,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,ddpg,sac,,,
164,Efficient Offline Policy Optimization with a Learned Model.pdf,True,False,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,dqn,sac,ppo,dreamer,,
165,Evolving Populations of Diverse RL Agents with MAP-Elites.pdf,True,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,sac,,,,
166,Deep reinforced active learning for multi-class image classification.pdf,True,False,False,2023,iclr,iclr_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,ppo,dqn,,,,,
167,Offline Reinforcement Learning via High-Fidelity Generative Behavior Modeling.pdf,True,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,ppo,dqn,,,,,
168,On the Data-Efficiency with Contrastive Image Transformation in Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
169,Demystifying Approximate RL with epsilon-greedy Exploration A Differential Inclusion View.pdf,False,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
170,Is Conditional Generative Modeling all you need for Decision Making.pdf,True,False,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
171,Adversarial Diversity in Hanabi.pdf,True,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
172,Distributional Reinforcement Learning via Sinkhorn Iterations.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
173,Guided Safe Shooting model based reinforcement learning with safety constraints.pdf,True,True,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,trpo,pets,,,,,
174,Constrained Reinforcement Learning for Safety-Critical Tasks via Scenario-Based Programming.pdf,True,False,False,2023,iclr,iclr_2023,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
175,DPMAC Differentially Private Communication for Cooperative Multi-Agent Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
176,Distributional Meta-Gradient Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,dqn,,,,,,
177,In-sample Actor Critic for Offline Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,,,,
178,BC-IRL Learning Generalizable Reward Functions from Demonstrations.pdf,False,True,False,2023,iclr,iclr_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
179,Efficiently Computing Nash Equilibria in Adversarial Team Markov Games.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
180,Guarded Policy Optimization with Imperfect Online Demonstrations.pdf,True,True,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,dqn,sac,,,
181,Robust Multi-Agent Reinforcement Learning against Adversaries on Observation.pdf,False,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,sac,ddpg,,,,
182,Stationary Deep Reinforcement Learning with Quantum K-spin Hamiltonian Equation.pdf,False,False,False,2023,iclr,iclr_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,ddpg,,,,,
183,Policy Expansion for Bridging Offline-to-Online Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,td3,ppo,dqn,sac,,,
184,ROCO A General Framework for Evaluating Robustness of Combinatorial Optimization Solvers on Graphs.pdf,True,True,False,2023,iclr,iclr_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
185,Does Zero-Shot Reinforcement Learning Exist.pdf,True,True,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,td3,pets,,,,,
186,Light-weight probing of unsupervised representations for Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dreamer,ppo,dqn,,,,
187,Unified Algorithms for RL with Decision-Estimation Coefficients No-Regret PAC and Reward-Free Learni.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,,,,,,
188,CAMA A New Framework for Safe Multi-Agent Reinforcement Learning  Using Constraint Augmentation.pdf,False,False,False,2023,iclr,iclr_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
189,Look Back When Surprised Stabilizing Reverse Experience Replay for Neural Approximation.pdf,True,True,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,dqn,ddpg,sac,td3,ppo,,
190,Oracles and Followers Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
191,Simple Emergent Action Representations from Multi-Task Policy Training.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
192,Pink Noise Is All You Need Colored Noise Exploration in Deep Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,sac,ddpg,td3,ppo,,
193,Risk-Aware Reinforcement Learning with Coherent Risk Measures and Non-linear Function Approximation.pdf,True,False,False,2023,iclr,iclr_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,,,,,,
194,Learning Cut Selection for Mixed-Integer Linear Programming via Hierarchical Sequence Model.pdf,True,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,a3c,sac,a2c,ppo,,
195,Training Equilibria in Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
196,The Provable Benefit of Unsupervised Data Sharing for Offline Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
197,The Reward Hypothesis is False.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
198,Discrete State-Action Abstraction via the Successor Representation.pdf,False,True,False,2023,iclr,iclr_2023,6-10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
199,On the Robustness of Safe Reinforcement Learning under Observational Perturbations.pdf,True,False,False,2023,iclr,iclr_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
200,Multi-Agent Policy Transfer via Task Relationship Modeling.pdf,False,False,False,2023,iclr,iclr_2023,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
201,Hedge Your Actions Flexible Reinforcement Learning for Complex Action Spaces.pdf,True,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,ppo,,
202,Offline Q-learning on Diverse Multi-Task Data Both Scales And Generalizes.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
203,Confidence-Conditioned Value Functions for Offline Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
204,Near-Optimal Deployment Efficiency in Reward-Free Reinforcement Learning with Linear Function Approx.pdf,False,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
205,Scaling Laws for a Multi-Agent Reinforcement Learning Model.pdf,True,True,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
206,Uncovering Directions of Instability via Quadratic Approximation of Deep Neural Loss in Reinforcemen.pdf,False,True,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
207,More Centralized Training Still Decentralized Execution Multi-Agent Conditional Policy Factorization.pdf,True,True,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,ppo,,
208,Diminishing Return of Value Expansion Methods in Model-Based Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,trpo,sac,ddpg,ppo,dreamer,,
209,Asymptotic Instance-Optimal Algorithms for Interactive Decision Making.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
210,Powderworld A Platform for Understanding Generalization via Rich Task Distributions.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
211,Learning Portable Skills by Identifying Generalizing Features with an Attention-Based Ensemble.pdf,False,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
212,Illusory Adversarial Attacks on Sequential Decision-Makers and Countermeasures.pdf,True,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
213,General Policy Evaluation and Improvement by Learning to Identify Few But Crucial States.pdf,False,True,False,2023,iclr,iclr_2023,over 10,action-value\s+function,state-action\s+pairs,,,,,,ppo,sac,ddpg,,,,
214,Policy-Induced Self-Supervision Improves Representation Finetuning in Visual RL.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
215,Adversarial Counterfactual Environment Model Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
216,DITTO Offline Imitation Learning with World Models.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dreamer,,,,,,
217,Online Reinforcement Learning via Posterior Sampling of Policy.pdf,False,False,False,2023,iclr,iclr_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
218,PALM Preference-based Adversarial Manipulation against Deep Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
219,Multi-User Reinforcement Learning with Low Rank Rewards.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
220,Offline Reinforcement Learning from Heteroskedastic Data Via Support Constraints.pdf,True,False,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
221,ACQL An Adaptive Conservative Q-Learning Framework for Offline Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
222,How Predictors Affect Search Strategies in Neural Architecture Search.pdf,False,True,False,2023,iclr,iclr_2023,over 10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
223,Towards biologically plausible Dreaming and Planning.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
224,Optimal Transport for Offline Imitation Learning.pdf,True,True,False,2023,iclr,iclr_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
225,Quality-Similar Diversity via Population Based Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,dqn,sac,,,
226,LS-IQ Implicit Reward Regularization for Inverse Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,6-10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
227,Backstepping Temporal Difference Learning.pdf,False,False,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
228,MARLlib Extending RLlib for Multi-agent Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,trpo,ppo,ddpg,a2c,,,
229,Gray-Box Gaussian Processes for Automated Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,sac,ddpg,a2c,td3,ppo,
230,Towards Interpretable Deep Reinforcement Learning with Human-Friendly Prototypes.pdf,True,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,a3c,dqn,sac,td3,ppo,,
231,Human-level Atari 200x faster.pdf,False,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,trpo,ppo,dqn,,,,
232,Sample Complexity of Nonparametric Off-Policy Evaluation on Low-Dimensional Manifolds using Deep Net.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
233,Context and History Aware Other-Shaping.pdf,True,True,False,2023,iclr,iclr_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
234,Learning Adversarial Linear Mixture Markov Decision Processes with Bandit Feedback and Unknown Trans.pdf,False,False,False,2023,iclr,iclr_2023,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,,,,,ppo,,,,,,
235,Towards Skilled Population Curriculum for MARL.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
236,MaxMin-Novelty Maximizing Novelty via Minimizing the State-Action Values in Deep Reinforcement Learn.pdf,True,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
237,Understanding Curriculum Learning in Policy Optimization for Online Combinatorial Optimization.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
238,Enforcing Hard Constraints with Soft Barriers Safe Reinforcement Learning in Unknown Stochastic Envi.pdf,False,False,False,2023,iclr,iclr_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,sac,,,,,
239,Achieving Communication-Efficient Policy Evaluation for Multi-Agent Reinforcement Learning Local TD-.pdf,False,False,False,2023,iclr,iclr_2023,6-10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
240,Never Revisit Continuous Exploration in Multi-Agent Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
241,Memory of Unimaginable Outcomes in Experience Replay.pdf,False,True,False,2023,iclr,iclr_2023,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
242,Offline Reinforcement Learning with Closed-Form Policy Improvement Operators.pdf,True,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,trpo,dqn,sac,td3,ppo,,
243,Offline Reinforcement Learning with Differential Privacy.pdf,False,False,False,2023,iclr,iclr_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
244,Skill Decision Transformer.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
245,Towards Understanding How Machines Can Learn Causal Overhypotheses.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,,,,
246,Thresholded Lexicographic Ordered Multi-Objective Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
247,Optimistic Exploration in Reinforcement Learning Using Symbolic Model Estimates.pdf,True,False,False,2023,iclr,iclr_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
248,Augmentation Curriculum Learning For Generalization in RL.pdf,False,False,False,2023,iclr,iclr_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
249,Evaluating Robustness of Cooperative MARL A Model-based Approach.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,a3c,ppo,sac,ddpg,,,
250,Solving Partial Label Learning Problem with Multi-Agent Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,other,,,,,,
251,HloEnv A Graph Rewrite Environment for Deep Learning Compiler Optimization Research.pdf,True,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
252,SpeedyZero Mastering Atari with Limited Data and Time.pdf,False,True,False,2023,iclr,iclr_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
253,HiT-MDP Learning the SMDP option framework on MDPs with Hidden Temporal Embeddings.pdf,True,False,False,2023,iclr,iclr_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
254,Latent Variable Representation for Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,trpo,pets,sac,ppo,dreamer,,
255,Offline RL for Natural Language Generation with Implicit Language Q Learning.pdf,True,True,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
256,SkillS Adaptive Skill Sequencing for Efficient Temporally-Extended Exploration.pdf,False,True,False,2023,iclr,iclr_2023,over 10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
257,A Unified Approach to Reinforcement Learning Quantal Response Equilibria and Two-Player Zero-Sum Gam.pdf,True,True,False,2023,iclr,iclr_2023,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
258, Robust Constrained Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,ppo,sac,,,,,
259,Curiosity-Driven Unsupervised Data Collection for Offline Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,dqn,ddpg,sac,,,
260,Abstract-to-Executable Trajectory Translation for One-Shot Task Generalization.pdf,True,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
261,Solving Continuous Control via Q-learning.pdf,True,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,trpo,dqn,ddpg,sac,ppo,dreamer,
262,A CMDP-within-online framework for Meta-Safe Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,sac,,,,,
263,Reinforcement learning for instance segmentation with high-level priors.pdf,False,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
264,Hyperbolic Deep Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,a2c,,,,
265,SPRINT Scalable Semantic Policy Pre-training via Language Instruction Relabeling.pdf,True,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
266,Planning Immediate Landmarks of Targets for Model-Free Skill Transfer across Agents.pdf,True,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
267,Correcting Data Distribution Mismatch in Offline Meta-Reinforcement Learning with Few-Shot Online Ad.pdf,False,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
268,Evaluating Long-Term Memory in 3D Mazes.pdf,True,True,False,2023,iclr,iclr_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,dreamer,,,,,,
269,ManiSkill2 A Unified Benchmark for Generalizable Manipulation Skills.pdf,True,True,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
270,MoDem Accelerating Visual Model-Based Reinforcement Learning with Demonstrations.pdf,True,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td-mpc,ppo,sac,ddpg,,,
271,MCTransformer Combining Transformers And Monte-Carlo Tree Search For Offline Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
272,Neural Discrete Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,td3,dqn,,,,,
273,Interpreting Distributional Reinforcement Learning A Regularization Perspective.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
274,Off Policy Average Reward Actor Critic with Deterministic Policy Search.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,sac,ddpg,td3,ppo,,
275,Outcome-directed Reinforcement Learning by Uncertainty  Temporal Distance-Aware Curriculum Goal Gene.pdf,True,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
276,Dynamics-aware Skill Generation from Behaviourally Diverse Demonstrations.pdf,False,False,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,sac,,,,,,
277,Robust Multi-Agent Reinforcement Learning with State Uncertainties.pdf,True,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
278,PAC Reinforcement Learning for Predictive State Representations.pdf,False,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
279,Order Matters Agent-by-agent Policy Optimization.pdf,True,True,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
280,Horizon-Free Reinforcement Learning for Latent Markov Decision Processes.pdf,False,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
281,Offline RL with No OOD Actions In-Sample Learning via Implicit Value Regularization.pdf,True,False,False,2023,iclr,iclr_2023,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
282,Knowledge-Grounded Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
283,Generating Diverse Cooperative Agents by Learning Incompatible Policies.pdf,True,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
284,POPGym Benchmarking Partially Observable Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,ddpg,sac,td3,ppo,,
285,Contrastive Value Learning Implicit Models for Simple Offline RL.pdf,False,False,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
286,PD-MORL Preference-Driven Multi-Objective Reinforcement Learning Algorithm.pdf,True,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,dqn,ddpg,sac,td3,ppo,,
287,Composing Task Knowledge With Modular Successor Feature Approximators.pdf,True,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,dqn,,,,,,
288,Learning GFlowNets from partial episodes for improved convergence and stability.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,sac,,,
289,CrystalBox Efficient Model-Agnostic Explanations for Deep RL Controllers.pdf,False,False,False,2023,iclr,iclr_2023,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
290,Boosting Multiagent Reinforcement Learning via Permutation Invariant and Permutation Equivariant Net.pdf,True,False,False,2023,iclr,iclr_2023,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
291,Discovering Generalizable Multi-agent Coordination Skills from Multi-task Offline Data.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dqn,ddpg,sac,,,,
292,Planning With Uncertainty Deep Exploration in Model-Based Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
293,Constrained Hierarchical Deep Reinforcement Learning with Differentiable Formal Specifications.pdf,True,False,False,2023,iclr,iclr_2023,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
294,MAD for Robust Reinforcement Learning in Machine Translation.pdf,True,True,False,2023,iclr,iclr_2023,1-5,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
295,Decision S4 Efficient Sequence-Based RL via State Spaces Layers.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,ddpg,,,,
296,Hierarchical Prototypes for  Unsupervised Dynamics Generalization in Model-Based Reinforcement Learn.pdf,False,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
297,Learning About Progress From Experts.pdf,True,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
298,Proto-Value Networks Scaling Representation Learning with Auxiliary Tasks.pdf,True,False,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
299,Blessing from Experts Super Reinforcement Learning in Confounded Environments.pdf,False,False,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,,,,,,
300,Quasi-optimal Reinforcement Learning with Continuous Actions.pdf,True,False,False,2023,iclr,iclr_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
301,Addressing High-dimensional Continuous Action Space via Decomposed Discrete Policy-Critic.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,dqn,ddpg,sac,,,
302,Near-Optimal Adversarial Reinforcement Learning with Switching Costs.pdf,False,False,False,2023,iclr,iclr_2023,0,state-action\s+pairs,,,,,,,ppo,dqn,sac,,,,
303,Learnable Behavior Control Breaking Atari Human World Records via Sample-Efficient Behavior Selectio.pdf,False,False,False,2023,iclr,iclr_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,sac,,,,,,
304,Can Agents Run Relay Race with Strangers Generalization of RL to Out-of-Distribution Trajectories.pdf,True,False,False,2023,iclr,iclr_2023,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,trpo,dqn,sac,td3,ppo,,
305,Multi-Objective Reinforcement Learning Convexity Stationarity and Pareto Optimality.pdf,True,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
306,Robust Reinforcement Learning with Distributional Risk-averse formulation.pdf,True,True,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
307,Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting.pdf,True,True,False,2023,iclr,iclr_2023,1-5,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,,,,
308,SMART Self-supervised Multi-task pretrAining with contRol Transformers.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,sac,,,,,
309,Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories.pdf,True,False,False,2023,iclr,iclr_2023,over 10,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
310,Spectral Decomposition Representation for Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,dreamer,ppo,sac,,,,
311,Pseudometric guided online query and update for offline reinforcement learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
312,Safe Exploration Incurs Nearly No Additional Sample Complexity for Reward-Free RL.pdf,False,False,False,2023,iclr,iclr_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
313,Stateful Active Facilitator Coordination and Environmental Heterogeneity in Cooperative Multi-Agent .pdf,True,False,False,2023,iclr,iclr_2023,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,sac,,,
314,Solving and Learning non-Markovian Stochastic Control problems in continuous-time with Neural RDEs.pdf,False,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
315,The Impact of Approximation Errors on Warm-Start Reinforcement Learning A Finite-time Analysis.pdf,False,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
316,Multitask Reinforcement Learning by Optimizing Neural Pathways.pdf,True,False,False,2023,iclr,iclr_2023,6-10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
317,AsymQ Asymmetric Q-loss to mitigate overestimation bias in off-policy reinforcement learning.pdf,True,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,td3,dqn,ddpg,sac,,,
318,Pre-Training for Robots Leveraging Diverse Multitask Data via Offline Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
319,Wasserstein Auto-encoded MDPs Formal Verification of Efficiently Distilled RL Policies with Many-sid.pdf,True,False,False,2023,iclr,iclr_2023,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,pets,ppo,dqn,sac,,,
320,Decision Transformer under Random Frame Dropping.pdf,False,True,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
321,A Mixture-of-Expert Approach to RL-based Dialogue Management.pdf,False,False,False,2023,iclr,iclr_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,a3c,ppo,dqn,sac,,,
322,Interval-based Offline Policy Evaluation without Sufficient Exploration or Realizability.pdf,False,False,False,2023,iclr,iclr_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
323,Scaling Pareto-Efficient Decision Making via Offline Multi-Objective RL.pdf,True,False,False,2023,iclr,iclr_2023,over 10,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
324,Causal Imitation Learning via Inverse Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
325,Continuous Goal Sampling A Simple Technique to Accelerate Automatic Curriculum Learning.pdf,False,False,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
326,The In-Sample Softmax for Offline Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,over 10,action-value\s+function,state-action\s+pairs,,,,,,td3,ppo,dqn,sac,,,
327,Optimistic Exploration with Learned Features Provably Solves Markov Decision Processes with Neural D.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
328,Actor-Critic Alignment for Offline-to-Online Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
329,Provable Benefits of Representational Transfer in Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
330,Multi-Task Option Learning and Discovery for Stochastic Path Planning.pdf,False,False,False,2023,iclr,iclr_2023,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
331,Q-Pensieve Boosting Sample Efficiency of Multi-Objective RL Through Memory Sharing of Q-Snapshots.pdf,True,True,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,ddpg,sac,,,
332,Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games A Communication Perspect.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
333,Know Your Boundaries The Advantage of Explicit Behavior Cloning in Offline RL.pdf,False,True,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,,,,
334,Transformer-based World Models Are Happy With 100k Interactions.pdf,True,False,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dreamer,ppo,dqn,,,,
335,Certifiably Robust Policy Learning against Adversarial Multi-Agent Communication.pdf,True,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
336,Near-optimal Policy Identification in Active Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
337,Agent-Controller Representations Principled Offline RL with Rich Exogenous Information.pdf,False,False,False,2023,iclr,iclr_2023,6-10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,td3,ppo,sac,,,,
338,Provable Sim-to-real Transfer in Continuous Domain with Partial Observations.pdf,False,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
339,Model-Based Decentralized Policy Optimization.pdf,False,True,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
340,Revealing Dominant Eigendirections via Spectral Non-Robustness Analysis in the Deep Reinforcement Le.pdf,False,False,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,dqn,,,,,,
341,CLARE Conservative Model-Based Reward Learning for Offline Inverse Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
342,MAESTRO Open-Ended Environment Design for Multi-Agent Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
343,Towards Solving Industrial Sequential Decision-making Tasks under Near-predictable Dynamics via Rein.pdf,True,False,False,2023,iclr,iclr_2023,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,ppo,dqn,a2c,sac,,,
344,Neural Agents Struggle to Take Turns in Bidirectional Emergent Communication.pdf,True,True,False,2023,iclr,iclr_2023,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
345,Protein Sequence Design in a Latent Space via Model-based Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
346,Quantization-aware Policy Distillation QPD.pdf,True,True,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,dqn,ddpg,a2c,sac,ppo,,
347,Toward Effective Deep Reinforcement Learning for 3D Robotic Manipulation End-to-End Learning from Mu.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dqn,ddpg,sac,td3,dreamer,,
348,Is Reinforcement Learning Not for Natural Language Processing Benchmarks Baselines and Building Bloc.pdf,True,False,False,2023,iclr,iclr_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
349,MA2QL A Minimalist Approach to Fully Decentralized Multi-Agent Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,,,,
350,Efficient Deep Reinforcement Learning Requires Regulating Overfitting.pdf,True,False,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
351,When is Offline Hyperparameter Selection Feasible for Reinforcement Learning.pdf,False,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
352,Can We Find Nash Equilibria at a Linear Rate in Markov Games.pdf,False,False,False,2023,iclr,iclr_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
353,RLx2 Training a Sparse Deep Reinforcement Learning Model from Scratch.pdf,True,True,False,2023,iclr,iclr_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
354,Deep Reinforcement Learning for Cost-Effective Medical Diagnosis.pdf,True,True,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
355,On Convergence of Average-Reward Off-Policy Control Algorithms in Weakly-Communicating MDPs.pdf,False,False,False,2023,iclr,iclr_2023,0,action-value\s+function,,,,,,,ppo,dqn,,,,,
356,Posterior Sampling Model-based Policy Optimization under Approximate Inference.pdf,True,True,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,pets,,,
357,SDAC Efficient Safe Reinforcement Learning with Low-Biased Distributional Actor-Critic.pdf,False,True,False,2023,iclr,iclr_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
358,Benchmarking Offline Reinforcement Learning on Real-Robot Hardware.pdf,True,True,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
359,Hyper-Decision Transformer for Efficient Online Policy Adaptation.pdf,False,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
360,Planning Goals for Exploration.pdf,False,True,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,dreamer,sac,,,,,
361,Robust Exploration via Clustering-based Online Density Estimation.pdf,False,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
362,RPM Generalizable Multi-Agent Policies for Multi-Agent Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
363,epsilon-Invariant Hierarchical Reinforcement Learning for Building Generalizable Policy.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,sac,a2c,,,,,
364,Decentralized Policy Optimization.pdf,True,False,False,2023,iclr,iclr_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,,,,
365,Social Network Structure Shapes Innovation Experience-sharing in RL with SAPIENS.pdf,False,True,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,sac,,,
366,Explainability of deep reinforcement learning algorithms in robotic domains by using Layer-wise Rele.pdf,False,True,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
367,Self-Supervised Off-Policy Ranking via Crowd Layer.pdf,True,False,False,2023,iclr,iclr_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
368,Conservative Bayesian Model-Based Value Expansion for Offline Policy Optimization.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
369,On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
370,Towards Minimax Optimal Reward-free Reinforcement Learning in Linear MDPs.pdf,False,False,False,2023,iclr,iclr_2023,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
371,Diagnosing and exploiting the computational demands of videos games for deep reinforcement learning.pdf,True,False,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
372,Safe Reinforcement Learning From Pixels Using a Stochastic Latent Representation.pdf,True,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,trpo,ppo,sac,,,,
373,Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
374,CLUTR Curriculum Learning via Unsupervised Task Representation Learning.pdf,True,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
375,Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier.pdf,True,True,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,ddpg,sac,,,
376,Multi-skill Mobile Manipulation for Object Rearrangement.pdf,True,False,False,2023,iclr,iclr_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
377,Preference Transformer Modeling Human Preferences using Transformers for RL.pdf,True,False,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
378,Representation Learning for Low-rank General-sum Markov Games.pdf,True,True,False,2023,iclr,iclr_2023,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
379,Efficient Exploration using Model-Based Quality-Diversity with Gradients.pdf,True,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,sac,,,,,
380,C3PO Learning to Achieve Arbitrary Goals via Massively Entropic Pretraining.pdf,False,False,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
381,Safer Reinforcement Learning with Counterexample-guided Offline Training.pdf,True,False,False,2023,iclr,iclr_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
382,Unravel Structured Heterogeneity of Tasks in Meta-Reinforcement Learning via Exploratory Clustering.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
383,Learning for Edge-Weighted Online Bipartite Matching with Robustness Guarantees.pdf,False,False,False,2023,iclr,iclr_2023,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
384,Contextual Symbolic Policy For Meta-Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
385,Deep Evidential Reinforcement Learning for Dynamic Recommendations.pdf,True,False,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
386,Reinforcement Learning for Bandits with Continuous Actions and Large Context Spaces.pdf,True,False,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,dqn,ddpg,,,,,
387,CASA Bridging the Gap between Policy Improvement and Policy Evaluation with Conflict Averse Policy I.pdf,False,True,False,2023,iclr,iclr_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
388,Value-Based Membership Inference Attack on Actor-Critic Reinforcement Learning.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
389,Critic Sequential Monte Carlo.pdf,False,False,False,2023,iclr,iclr_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,a2c,sac,,,
390,Achieving Sub-linear Regret in Infinite Horizon Average Reward Constrained MDP with Linear Function .pdf,False,False,False,2023,iclr,iclr_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
391,Integrating Episodic and Global Novelty Bonuses for Efficient Exploration.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
392,ResAct Reinforcing Long-term Engagement in Sequential Recommendation with Residual Actor.pdf,False,False,False,2023,iclr,iclr_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td3,ppo,,
393,The Benefits of Model-Based Generalization in Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,dreamer,ppo,dqn,sac,,,
394,Faster Reinforcement Learning with Value Target Lower Bounding.pdf,False,True,False,2023,iclr,iclr_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,sac,,,
395,Choreographer Learning and Adapting Skills in Imagination.pdf,False,True,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,ddpg,,,
396,Rule-based policy regularization for reinforcement learning-based building control.pdf,False,True,False,2023,iclr,iclr_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,trpo,dqn,ddpg,sac,td3,ppo,
397,Heterogeneous-Agent Mirror Learning.pdf,True,False,False,2023,iclr,iclr_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,ddpg,a2c,,,
398,Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching.pdf,True,False,False,2023,iclr,iclr_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,trpo,ppo,dqn,sac,,,
399,Extreme Q-Learning MaxEnt RL without Entropy.pdf,True,True,False,2023,iclr,iclr_2023,6-10,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
400,Implicit Offline Reinforcement Learning via Supervised Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
401,Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward.pdf,True,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
402,Contextual Transformer for Offline Reinforcement Learning.pdf,True,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
403,CRISP Curriculum inducing Primitive Informed Subgoal Prediction for Hierarchical Reinforcement Learn.pdf,False,True,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
404,Variational Latent Branching Model for Off-Policy Evaluation.pdf,True,True,False,2023,iclr,iclr_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dreamer,,,,,
405,Transformers are Sample-Efficient World Models.pdf,True,True,False,2023,iclr,iclr_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dreamer,,,,,
406,Unsupervised Model-based Pre-training for Data-efficient Control from Pixels.pdf,False,False,False,2023,iclr,iclr_2023,1-5,(?:discount|reward)\s+function,,,,,,,dqn,sac,td-mpc,ppo,dreamer,,
407,Policy Architectures for Compositional Generalization in Control.pdf,True,False,False,2023,iclr,iclr_2023,1-5,action-value\s+function,,,,,,,ppo,ddpg,,,,,
408,Multi-Agent Reinforcement Learning with Shared Resources for Inventory Management.pdf,False,False,False,2023,iclr,iclr_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,,,,
409,Observational Robustness and Invariances in Reinforcement Learning via Lexicographic Objectives.pdf,True,False,False,2023,iclr,iclr_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,sac,a2c,,,,
410,Is Model Ensemble Necessary Model-based RL via a Single Model with Lipschitz Regularized Value Funct.pdf,True,True,False,2023,iclr,iclr_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,a2c,,,,
411,Risk-aware Bayesian RL for Cautious Exploration.pdf,False,False,False,2023,iclr,iclr_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,,,,,ppo,dqn,sac,,,,
412,Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning.pdf,False,False,False,2023,iclr,iclr_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
0,Reinforcement Symbolic Regression Machine.pdf,True,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
1,Reconciling Spatial and Temporal Abstractions for Goal Representation.pdf,True,False,False,2024,iclr,iclr_2024,6-10,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
2,Consistency Models as a Rich and Efficient Policy Class for Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,,,,,
3,Identifying Policy Gradient Subspaces.pdf,True,True,False,2024,iclr,iclr_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,ppo,sac,,,,,
4,On the Role of General Function Approximation in Offline Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
5,Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,trpo,td3,ppo,sac,,,
6,Hindsight PRIORs for Reward Learning from Human Preferences.pdf,False,False,False,2024,iclr,iclr_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
7,Sample-Efficiency in Multi-Batch Reinforcement Learning The Need for Dimension-Dependent Adaptivity.pdf,False,False,False,2024,iclr,iclr_2024,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
8,Efficient Multi-agent Reinforcement Learning by Planning.pdf,True,False,False,2024,iclr,iclr_2024,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,sac,td3,td-mpc,ppo,,
9,Meta-Evolve Continuous Robot Evolution for One-to-many Policy Transfer.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
10,Adaptive Rational Activations to Boost Deep Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,dqn,sac,,,,,
11,Uni-O4 Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimizatio.pdf,False,True,False,2024,iclr,iclr_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,dqn,sac,td3,ppo,,
12,Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,dqn,sac,,,
13,Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game.pdf,True,False,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,sac,,,
14,Reward-Free Curricula for Training Robust World Models.pdf,True,True,False,2024,iclr,iclr_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
15,Searching for High-Value Molecules Using Reinforcement Learning and Transformers.pdf,False,True,False,2024,iclr,iclr_2024,1-5,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,sac,,,,,
16,Uncertainty-aware Constraint Inference in Inverse Constrained Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
17,Tree Search-Based Policy Optimization under Stochastic Execution Delay.pdf,True,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,dqn,sac,,,
18,Quantifying the Sensitivity of Inverse Reinforcement Learning to Misspecification.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
19,Dual RL Unification and New Methods for Reinforcement and Imitation Learning.pdf,False,True,False,2024,iclr,iclr_2024,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,dqn,sac,td3,ppo,,
20,Decoupling regularization from the action space.pdf,False,False,False,2024,iclr,iclr_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
21,Revisiting Data Augmentation in Deep Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,ddpg,,,,
22,Provably Efficient UCB-type Algorithms For Learning Predictive State Representations.pdf,False,False,False,2024,iclr,iclr_2024,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
23,Cleanba A Reproducible and Efficient Distributed Reinforcement Learning Platform.pdf,True,False,False,2024,iclr,iclr_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
24,COPlanner Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL.pdf,True,True,False,2024,iclr,iclr_2024,6-10,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
25,AMAGO Scalable In-Context Reinforcement Learning for Adaptive Agents.pdf,True,True,False,2024,iclr,iclr_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,dreamer,ddpg,,,
26,CrossLoco Human Motion Driven Control of Legged Robots via Guided Unsupervised Reinforcement Learnin.pdf,False,False,False,2024,iclr,iclr_2024,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
27,Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
28,Curiosity-driven Red-teaming for Large Language Models.pdf,True,True,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
29,Integrating Planning and Deep Reinforcement Learning via Automatic Induction of Task Substructures.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
30,Contrastive Difference Predictive Coding.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ddpg,,,,,,
31,Local Search GFlowNets.pdf,True,True,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,sac,,,
32,Safe RLHF Safe Reinforcement Learning from Human Feedback.pdf,True,False,False,2024,iclr,iclr_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,dreamer,ppo,sac,,,,
33,Offline RL with Observation Histories Analyzing and Improving Sample Complexity.pdf,False,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
34,A Dynamical View of the Question of Why.pdf,True,False,False,2024,iclr,iclr_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
35,Enhancing Human Experience in Human-Agent Collaboration A Human-Centered Modeling Approach Based on .pdf,False,False,False,2024,iclr,iclr_2024,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
36,The Wasserstein Believer Learning Belief Updates for Partially Observable Environments through Relia.pdf,True,True,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a2c,,,,,,
37,Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,td3,dqn,,,,,
38,Sample-efficient Learning of Infinite-horizon Average-reward MDPs with General Function Approximatio.pdf,False,False,False,2024,iclr,iclr_2024,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
39,Leftover Lunch Advantage-based Offline Reinforcement Learning for Language Models.pdf,True,True,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
40,Dynamic Layer Tying for Parameter-Efficient Transformers.pdf,False,True,False,2024,iclr,iclr_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,dqn,sac,,,,
41,Chain of Hindsight aligns Language Models with Feedback.pdf,True,False,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
42,PAE Reinforcement Learning from External Knowledge for Efficient Exploration.pdf,True,True,False,2024,iclr,iclr_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
43,Training Diffusion Models with Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
44,MINT Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback.pdf,True,False,False,2024,iclr,iclr_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
45,OMNI Open-endedness via Models of human Notions of Interestingness.pdf,False,True,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
46,Efficient Planning with Latent Diffusion.pdf,True,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,td-mpc,ppo,dqn,sac,,,
47,Unlocking the Power of Representations in Long-term Novelty-based Exploration.pdf,False,False,False,2024,iclr,iclr_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
48,In-context Exploration-Exploitation for Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,dqn,sac,,,,,
49,Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula.pdf,True,True,False,2024,iclr,iclr_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
50,Intelligent Switching for Reset-Free RL.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
51,Distributional Preference Learning Understanding and Accounting for Hidden Context in RLHF.pdf,True,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
52,Learning Multi-Agent Communication from Graph Modeling Perspective.pdf,True,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
53,DMBP Diffusion model-based predictor for robust offline reinforcement learning against state observa.pdf,True,True,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
54,S2AC Energy-Based Reinforcement Learning with Stein Soft Actor Critic.pdf,True,True,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
55,Making RL with Preference-based Feedback Efficient via Randomization.pdf,False,False,False,2024,iclr,iclr_2024,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
56,Rethinking Adversarial Policies A Generalized Attack Formulation and Provable Defense in RL.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,a2c,,,,,
57,Learning Interactive Real-World Simulators.pdf,False,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
58,FLD Fourier Latent Dynamics for Structured Motion Representation and Learning.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
59,Reward Model Ensembles Help Mitigate Overoptimization.pdf,True,True,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
60,Submodular Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
61,Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
62,Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
63,Goodharts Law in Reinforcement Learning.pdf,False,True,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
64,Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations.pdf,False,True,False,2024,iclr,iclr_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
65,Privately Aligning Language Models with Reinforcement Learning.pdf,False,True,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
66,Fast Imitation via Behavior Foundation Models.pdf,True,True,False,2024,iclr,iclr_2024,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,sac,,,,
67,Plan-Seq-Learn Language Model Guided RL for Solving Long Horizon Robotics Tasks.pdf,True,False,False,2024,iclr,iclr_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
68,On the Expressivity of Objective-Specification Formalisms in Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
69,Transformers as Decision Makers Provable In-Context Reinforcement Learning via Supervised Pretrainin.pdf,True,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
70,Learning Decentralized Partially Observable Mean Field Control for Artificial Collective Behavior.pdf,False,True,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
71,Demystifying Linear MDPs and Novel Dynamics Aggregation Framework.pdf,False,False,False,2024,iclr,iclr_2024,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
72,Open the Black Box Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learni.pdf,True,True,False,2024,iclr,iclr_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
73,Bridging State and History Representations Understanding Self-Predictive RL.pdf,True,False,False,2024,iclr,iclr_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,dqn,ddpg,sac,td3,ppo,dreamer,
74,Text2Reward Reward Shaping with Language Models for Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
75,Understanding the Effects of RLHF on LLM Generalisation and Diversity.pdf,True,True,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,pets,ppo,,,,,
76,DittoGym Learning to Control Soft Shape-Shifting Robots.pdf,False,False,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
77,SEABO A Simple Search-Based Method for Offline Imitation Learning.pdf,True,True,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,,,,,
78,Curriculum reinforcement learning for quantum architecture search under hardware errors.pdf,True,True,False,2024,iclr,iclr_2024,1-5,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
79,Meta Inverse Constrained Reinforcement Learning Convergence Guarantee and Generalization Analysis.pdf,False,False,False,2024,iclr,iclr_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
80,On the Hardness of Constrained Cooperative Multi-Agent Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
81,A Policy Gradient Method for Confounded POMDPs.pdf,False,False,False,2024,iclr,iclr_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,ddpg,,,,
82,Diverse Projection Ensembles for Distributional Reinforcement Learning.pdf,False,True,False,2024,iclr,iclr_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
83,Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
84,Deep Reinforcement Learning for Modelling Protein Complexes.pdf,False,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
85,Adaptive Regularization of Representation Rank as an Implicit Constraint of Bellman Equation.pdf,True,False,False,2024,iclr,iclr_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,td3,dqn,sac,,,,
86,Reclaiming the Source of Programmatic Policies Programmatic versus Latent Spaces.pdf,True,False,False,2024,iclr,iclr_2024,over 10,(?:discount|reward)\s+function,,,,,,,pets,ppo,sac,,,,
87,Language Model Self-improvement by Reinforcement Learning Contemplation.pdf,True,False,False,2024,iclr,iclr_2024,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,ppo,,,,,,
88,Provable and Practical Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo.pdf,True,True,False,2024,iclr,iclr_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,ppo,dqn,,,,,
89,Cascading Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
90,Learning from Sparse Offline Datasets via Conservative Density Estimation.pdf,True,False,False,2024,iclr,iclr_2024,1-5,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
91,SafeDreamer Safe Reinforcement Learning with World Models.pdf,True,True,False,2024,iclr,iclr_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,dreamer,ppo,sac,,,
92,Eureka Human-Level Reward Design via Coding Large Language Models.pdf,True,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
93,Multi-Task Reinforcement Learning with Mixture of Orthogonal Experts.pdf,True,True,False,2024,iclr,iclr_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
94,Whittle Index with Multiple Actions and State Constraint for Inventory Management.pdf,True,True,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
95,Adversarial Imitation Learning via Boosting.pdf,True,False,False,2024,iclr,iclr_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
96,Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization in Reinforcement Learn.pdf,True,True,False,2024,iclr,iclr_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
97,Physics-Regulated Deep Reinforcement Learning Invariant Embeddings.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,ppo,sac,ddpg,,,,
98,Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
99,Score Regularized Policy Optimization through Diffusion Behavior.pdf,True,False,False,2024,iclr,iclr_2024,6-10,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,,,,
100,CPPO Continual Learning for Reinforcement Learning with Human Feedback.pdf,True,False,False,2024,iclr,iclr_2024,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
101,True Knowledge Comes from Practice Aligning Large Language Models with Embodied Environments via Rei.pdf,True,True,False,2024,iclr,iclr_2024,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
102,Spatially-Aware Transformers for Embodied Agents.pdf,True,True,False,2024,iclr,iclr_2024,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,dreamer,ppo,dqn,sac,,,
103,Understanding when Dynamics-Invariant Data Augmentations Benefit Model-free Reinforcement Learning U.pdf,True,False,False,2024,iclr,iclr_2024,over 10,(?:discount|reward)\s+function,,,,,,,td3,ppo,ddpg,,,,
104,When should we prefer Decision Transformers for Offline Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
105,Towards Robust Offline Reinforcement Learning under Diverse Data Corruption.pdf,True,True,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
106,Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding.pdf,True,True,False,2024,iclr,iclr_2024,6-10,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
107,The Curse of Diversity in Ensemble-Based Exploration.pdf,True,False,False,2024,iclr,iclr_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,ddpg,sac,,,
108,Towards Principled Representation Learning from Videos for Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
109,Task Adaptation from Skills Information Geometry Disentanglement and New Objectives for Unsupervised.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
110,Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation and Human Feedba.pdf,False,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
111,Query-Policy Misalignment in Preference-Based Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,pets,ppo,dqn,sac,,,
112,Privileged Sensing Scaffolds Reinforcement Learning.pdf,False,True,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
113,Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
114,Discovering Temporally-Aware Reinforcement Learning Algorithms.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,a2c,,,,
115,Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics.pdf,True,True,False,2024,iclr,iclr_2024,6-10,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
116,Dynamic Neighborhood Construction for Structured Large Discrete Action Spaces.pdf,True,True,False,2024,iclr,iclr_2024,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,ddpg,sac,,,
117,Score Models for Offline Goal-Conditioned Reinforcement Learning.pdf,False,True,False,2024,iclr,iclr_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
118,METRA Scalable Unsupervised RL with Metric-Aware Abstraction.pdf,True,False,False,2024,iclr,iclr_2024,6-10,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
119,Impact of Computation in Integral Reinforcement Learning for Continuous-Time Control.pdf,True,True,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
120,The Effective Horizon Explains Deep RL Performance in Stochastic Environments.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
121,The Trickle-down Impact of Reward Inconsistency on RLHF.pdf,True,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
122,On Representation Complexity of Model-based and Model-free Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
123,PARL A Unified Framework for Policy Alignment in Reinforcement Learning from Human Feedback.pdf,False,False,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
124,A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
125,Maximum Entropy Heterogeneous-Agent Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,td3,ppo,
126,Reward Design for Justifiable Sequential Decision-Making.pdf,True,True,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
127,Domain Randomization via Entropy Maximization.pdf,False,True,False,2024,iclr,iclr_2024,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
128,ODICE Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update.pdf,True,True,False,2024,iclr,iclr_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
129,Time-Efficient Reinforcement Learning with Stochastic Stateful Policies.pdf,True,False,False,2024,iclr,iclr_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,td3,ppo,
130,Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies.pdf,True,True,False,2024,iclr,iclr_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,ppo,,,,,
131,Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees.pdf,True,True,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,,,,,trpo,ppo,dqn,sac,,,
132,TD-MPC2 Scalable Robust World Models for Continuous Control.pdf,True,True,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,td-mpc,dreamer,ppo,sac,,,
133,Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,6-10,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,a3c,dqn,a2c,sac,ppo,,
134,Piecewise Linear Parametrization of Policies Towards Interpretable Deep Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,ppo,dqn,sac,,,
135,Vanishing Gradients in Reinforcement Finetuning of Language Models.pdf,True,True,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
136,Soft Robust MDPs and Risk-Sensitive MDPs Equivalence Policy Gradient and Sample Complexity.pdf,False,False,False,2024,iclr,iclr_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
137,MAMBA an Effective World Model Approach for Meta-Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
138,Massively Scalable Inverse Reinforcement Learning in Google Maps.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
139,Compositional Conservatism A Transductive Approach in Offline Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
140,Beam Enumeration Probabilistic Explainability For Sample Efficient Self-conditioned Molecular Design.pdf,True,True,False,2024,iclr,iclr_2024,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,,,,,,
141,Negatively Correlated Ensemble Reinforcement Learning for Online Diverse Game Level Generation.pdf,True,False,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
142,Reasoning with Latent Diffusion in Offline Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,pets,ppo,dqn,sac,,,
143,Belief-Enriched Pessimistic Q-Learning against Adversarial State Perturbations.pdf,True,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
144,Towards Imitation Learning to Branch for MIP A Hybrid Reinforcement Learning based Sample Augmentati.pdf,False,False,False,2024,iclr,iclr_2024,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,a2c,,,,,
145,H-GAP Humanoid Control with a Generalist Planner.pdf,False,True,False,2024,iclr,iclr_2024,over 10,(?:discount|reward)\s+function,,,,,,,td-mpc,ppo,dqn,sac,,,
146,On-Policy Distillation of Language Models Learning from Self-Generated Mistakes.pdf,False,True,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
147,Efficient Dynamics Modeling in Interactive Environments with Koopman Theory.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,td-mpc,ppo,dqn,sac,,,
148,Stabilizing Contrastive RL Techniques for Robotic Goal Reaching from Offline Data.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
149,Addressing Signal Delay in Deep Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,sac,ddpg,,,
150,Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs.pdf,False,False,False,2024,iclr,iclr_2024,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
151,Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
152,Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visua.pdf,False,False,False,2024,iclr,iclr_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,a2c,,,,
153,Unveiling Options with Neural Network Decomposition.pdf,True,True,False,2024,iclr,iclr_2024,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
154,Prioritized Soft Q-Decomposition for Lexicographic Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
155,Sample-Efficient Quality-Diversity by Cooperative Coevolution.pdf,True,False,False,2024,iclr,iclr_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,td3,dqn,sac,,,,
156,SYMBOL Generating Flexible Black-Box Optimizers through Symbolic Equation Learning.pdf,True,True,False,2024,iclr,iclr_2024,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
157,REValueD Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes.pdf,False,False,False,2024,iclr,iclr_2024,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
158,Hybrid Internal Model Learning Agile Legged Locomotion with Simulated Robot Response.pdf,False,False,False,2024,iclr,iclr_2024,over 10,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
159,Large Language Models as Generalizable Policies for Embodied Tasks.pdf,False,False,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
160,Uni-RLHF Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedba.pdf,True,False,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
161,Learning to Act without Actions.pdf,True,True,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
162,AlignDiff Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model.pdf,True,False,False,2024,iclr,iclr_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
163,Provable Reward-Agnostic Preference-Based Reinforcement Learning.pdf,False,True,False,2024,iclr,iclr_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
164,Sample Efficient Myopic Exploration Through Multitask Reinforcement Learning with Diverse Tasks.pdf,False,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
165,Achieving Fairness in Multi-Agent MDP Using Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,other,,,,,,
166,Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
167,mathcalB-Coder Value-Based Deep Reinforcement Learning for Program Synthesis.pdf,True,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
168,Contrastive Preference Learning Learning from Human Feedback without Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
169,On Double Descent in Reinforcement Learning with LSTD and Random Features.pdf,True,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
170,Skill Machines Temporal Logic Skill Composition in Reinforcement Learning.pdf,False,True,False,2024,iclr,iclr_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,,,,
171,Imitation Learning from Observation with Automatic Discount Scheduling.pdf,True,True,False,2024,iclr,iclr_2024,6-10,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
172,Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL.pdf,True,True,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
173,Blending Imitation and Reinforcement Learning for Robust Policy Improvement.pdf,False,False,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,,,,,,
174,Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model.pdf,True,True,False,2024,iclr,iclr_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,dqn,sac,,,,
175,Robust Model Based Reinforcement Learning Using mathcalL_1 Adaptive Control.pdf,False,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,pets,,,,
176,Learning to Make Adherence-aware Advice.pdf,False,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
177,Causally Aligned Curriculum Learning.pdf,True,False,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
178,Exploring the Promise and Limits of Real-Time Recurrent Learning.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,dqn,sac,,,,,
179,Toward Optimal Policy Population Growth in Two-Player Zero-Sum Games.pdf,True,False,False,2024,iclr,iclr_2024,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,sac,,,,
180,Flow to Better Offline Preference-based Reinforcement Learning via Preferred Trajectory Generation.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
181,Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
182,Optimal Sample Complexity for Average Reward Markov Decision Processes.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
183,Achieving Sample and Computational Efficient Reinforcement Learning by Action Space Reduction via Gr.pdf,False,False,False,2024,iclr,iclr_2024,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
184,Free from Bellman Completeness Trajectory Stitching via Model-based Return-conditioned Supervised Le.pdf,True,True,False,2024,iclr,iclr_2024,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
185,Skill or Luck Return Decomposition via Advantage Functions.pdf,False,False,False,2024,iclr,iclr_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,,,,
186,Confronting Reward Model Overoptimization with Constrained RLHF.pdf,True,False,False,2024,iclr,iclr_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,sac,pets,,,
187,Demonstration-Regularized RL.pdf,False,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
188,Proper Laplacian Representation Learning.pdf,True,True,False,2024,iclr,iclr_2024,over 10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
189,Language Control Diffusion Efficiently Scaling through Space Time and Tasks.pdf,True,True,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
190,Maximum Entropy Model Correction in Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
191,Fast Value Tracking for Deep Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
192,Provable Offline Preference-Based Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
193,Entity-Centric Reinforcement Learning for Object Manipulation from Pixels.pdf,True,False,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,,,,
194,Policy Rehearsing Training Generalizable Policies for Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td3,ppo,dreamer,
195,Off-Policy Primal-Dual Safe Reinforcement Learning.pdf,True,False,False,2024,iclr,iclr_2024,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
196,Learning Energy Decompositions for Partial Inference in GFlowNets.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
197,Replay across Experiments A Natural Extension of Off-Policy RL.pdf,False,True,False,2024,iclr,iclr_2024,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
198,Efficient Inverse Multiagent Learning.pdf,True,False,False,2024,iclr,iclr_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,sac,,,,,
199,Reverse Forward Curriculum Learning for Extreme Sample and Demo Efficiency.pdf,True,True,False,2024,iclr,iclr_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
200,Beyond Stationarity Convergence Analysis of Stochastic Softmax Policy Gradient Methods.pdf,False,False,False,2024,iclr,iclr_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
201,Beyond Worst-case Attacks Robust RL with Adaptive Defense via Non-dominated Policies.pdf,True,True,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
202,LOQA Learning with Opponent Q-Learning Awareness.pdf,True,False,False,2024,iclr,iclr_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
203,Active Retrosynthetic Planning Aware of Route Quality.pdf,False,False,False,2024,iclr,iclr_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,sac,,,,,
204,SRL Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores.pdf,True,False,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
205,Learning Multi-Agent Communication with Contrastive Learning.pdf,True,True,False,2024,iclr,iclr_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,a2c,,,,,
206,Sample-Efficient Multi-Agent RL An Optimization Perspective.pdf,False,False,False,2024,iclr,iclr_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,,,,,,
207,Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization.pdf,True,False,False,2024,iclr,iclr_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
208,Improving Intrinsic Exploration by Creating Stationary Objectives.pdf,False,False,False,2024,iclr,iclr_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,sac,,,
209,Provably Efficient CVaR RL in Low-rank MDPs.pdf,False,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
210,Behaviour Distillation.pdf,True,True,False,2024,iclr,iclr_2024,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
211,Stylized Offline Reinforcement Learning Extracting Diverse High-Quality Behaviors from Heterogeneous.pdf,True,False,False,2024,iclr,iclr_2024,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
212,Compositional Preference Models for Aligning LMs.pdf,True,False,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
213,DreamSmooth Improving Model-based Reinforcement Learning via Reward Smoothing.pdf,True,True,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,td-mpc,dreamer,,,,,
214,Harnessing Density Ratios for Online Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
215,Federated Q-Learning Linear Regret Speedup with Low Communication Cost.pdf,False,False,False,2024,iclr,iclr_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
216,CrossQ Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplici.pdf,True,True,False,2024,iclr,iclr_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,dqn,ddpg,sac,,,
217,RLIF Interactive Imitation Learning as Reinforcement Learning.pdf,False,False,False,2024,iclr,iclr_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
218,Augmented Bayesian Policy Search.pdf,True,True,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
219,Retroformer Retrospective Large Language Agents with Policy Gradient Optimization.pdf,True,False,False,2024,iclr,iclr_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
220,Decision ConvFormer Local Filtering in MetaFormer is Sufficient for Decision Making.pdf,True,True,False,2024,iclr,iclr_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
221,Pre-training with Synthetic Data Helps Offline Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,over 10,state-action\s+pairs,,,,,,,dqn,,,,,,
222,DrM Mastering Visual Reinforcement Learning through Dormant Ratio Minimization.pdf,False,True,False,2024,iclr,iclr_2024,6-10,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
223,RLCD Reinforcement Learning from Contrastive Distillation for LM Alignment.pdf,True,True,False,2024,iclr,iclr_2024,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
224,Improving Offline RL by Blending Heuristics.pdf,True,True,False,2024,iclr,iclr_2024,1-5,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
225,Jumanji a Diverse Suite of Scalable Reinforcement Learning Environments in JAX.pdf,True,False,False,2024,iclr,iclr_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,a2c,,,,
226,The Generalization Gap in Offline Reinforcement Learning.pdf,True,True,False,2024,iclr,iclr_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
227,CivRealm A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents.pdf,True,False,False,2024,iclr,iclr_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
0,Towards General Negotiation Strategies with End-to-End Reinforcement Learning.pdf,True,False,False,2024,rlj,rlj_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
1,Co-Learning Empirical Games  World Models.pdf,True,False,False,2024,rlj,rlj_2024,0,,,,,,,,Not specified,,,,,,
2,Tiered Reward Designing Rewards for Specification and Fast Learning of Desired Behavior.pdf,True,False,False,2024,rlj,rlj_2024,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,ppo,,,,,
3,Aquatic Navigation A Challenging Benchmark for Deep Reinforcement Learning.pdf,True,True,False,2024,rlj,rlj_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,,,,,,
4,Mixture of Experts in a Mixture of RL settings.pdf,True,True,False,2024,rlj,rlj_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
5,Offline Reinforcement Learning from Datasets with Structured Non-Stationarity.pdf,True,False,False,2024,rlj,rlj_2024,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,td3,sac,,,,,
6,Learning to Navigate in Mazes with Novel Layouts using Abstract Top-down Maps.pdf,False,False,False,2024,rlj,rlj_2024,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,dqn,ppo,sac,,,,
7,Online Planning in POMDPs with State-Requests.pdf,False,False,False,2024,rlj,rlj_2024,over 10,(?:discount|reward)\s+function,,,,,,,dqn,ppo,,,,,
8,Reward Centering.pdf,True,False,False,2024,rlj,rlj_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,,,,,dqn,trpo,ppo,sac,,,
9,RL for Consistency Models Reward Guided Text-to-Image Generation with Fast Inference.pdf,True,True,False,2024,rlj,rlj_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
10,Bidirectional-Reachable Hierarchical Reinforcement Learning with Mutually Responsive Policies.pdf,True,False,False,2024,rlj,rlj_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
11,A Natural Extension To Online Algorithms For Hybrid RL With Limited Coverage.pdf,True,False,False,2024,rlj,rlj_2024,over 10,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
12,Representation Alignment from Human Feedback for Cross-Embodiment Reward Learning from Mixed-Quality.pdf,True,False,False,2024,rlj,rlj_2024,1-5,(?:discount|reward)\s+function,,,,,,,dqn,ppo,sac,,,,
13,Investigating the Interplay of Prioritized Replay and Generalization.pdf,False,False,False,2024,rlj,rlj_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,ppo,sac,,,,
14,Improving Thompson Sampling via Information Relaxation for Budgeted Multi-armed Bandits.pdf,False,False,False,2024,rlj,rlj_2024,0,,,,,,,,Not specified,,,,,,
15,Policy Gradient Algorithms with Monte Carlo Tree Learning for Non-Markov Decision Processes.pdf,False,False,False,2024,rlj,rlj_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,trpo,ppo,sac,,,
16,Optimizing Rewards while meeting omega-regular Constraints.pdf,True,True,False,2024,rlj,rlj_2024,0,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
17,Stabilizing Extreme Q-learning by Maclaurin Expansion.pdf,False,False,False,2024,rlj,rlj_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,trpo,ppo,sac,,,
18,ROER Regularized Optimal Experience Replay.pdf,True,True,False,2024,rlj,rlj_2024,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,dqn,trpo,ppo,sac,,,
19,Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal Policy Optimization.pdf,True,True,False,2024,rlj,rlj_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,a3c,ddpg,ppo,,,,
20,Boosting Soft Q-Learning by Bounding.pdf,True,True,False,2024,rlj,rlj_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,dqn,ddpg,ppo,sac,,,
21,Demystifying the Recency Heuristic in Temporal-Difference Learning.pdf,True,False,False,2024,rlj,rlj_2024,over 10,action-value\s+function,state-action\s+pairs,,,,,,dqn,ppo,sac,,,,
22,Causal Contextual Bandits with Adaptive Context.pdf,False,False,False,2024,rlj,rlj_2024,0,,,,,,,,Not specified,,,,,,
23,Agent-Centric Human Demonstrations Train World Models.pdf,True,True,False,2024,rlj,rlj_2024,0,(?:discount|reward)\s+function,,,,,,,dreamer,td-mpc,ppo,,,,
24,OCAtari Object-Centric Atari 2600 Reinforcement Learning Environments.pdf,True,True,False,2024,rlj,rlj_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,ppo,,,,,
25,When does Self-Prediction help Understanding Auxiliary Tasks in Reinforcement Learning.pdf,True,True,False,2024,rlj,rlj_2024,over 10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,dqn,td3,ppo,,,,
26,On the consistency of hyper-parameter selection in value-based deep reinforcement learning.pdf,True,True,False,2024,rlj,rlj_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dqn,trpo,ppo,sac,,,
27,Semi-Supervised One Shot Imitation Learning.pdf,False,False,False,2024,rlj,rlj_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
28,Combining Automated Optimisation of Hyperparameters and Reward Shape.pdf,True,True,False,2024,rlj,rlj_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
29,Dreaming of Many Worlds Learning Contextual World Models aids Zero-Shot Generalization.pdf,True,False,False,2024,rlj,rlj_2024,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,a2c,sac,,,,
30,SwiftTD A Fast and Robust Algorithm for Temporal Difference Learning.pdf,False,True,False,2024,rlj,rlj_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,ppo,sac,,,,
31,Reinforcement Learning from Human Feedback without Reward Inference Model-Free Algorithm and Instanc.pdf,False,False,False,2024,rlj,rlj_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,ppo,,,,,
32,Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms.pdf,True,False,False,2024,rlj,rlj_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
33,Learning Abstract World Models for Value-preserving Planning with Options.pdf,False,True,False,2024,rlj,rlj_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,td3,sac,dreamer,td-mpc,ppo,
34,PASTA Pretrained Action-State Transformer Agents.pdf,True,True,False,2024,rlj,rlj_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,td3,trpo,sac,ppo,,
35,Revisiting Sparse Rewards for Goal-Reaching Reinforcement Learning.pdf,True,False,False,2024,rlj,rlj_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
36,SplAgger Split Aggregation for Meta-Reinforcement Learning.pdf,True,True,False,2024,rlj,rlj_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
37,Verification-Guided Shielding for Deep Reinforcement Learning.pdf,False,False,False,2024,rlj,rlj_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
38,Learning Action-based Representations Using Invariance.pdf,False,True,False,2024,rlj,rlj_2024,1-5,(?:discount|reward)\s+function,,,,,,,dqn,ppo,sac,,,,
39,Informed POMDP Leveraging Additional Information in Model-Based RL.pdf,True,False,False,2024,rlj,rlj_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,sac,dreamer,ddpg,ppo,,
40,Resource Usage Evaluation of Discrete Model-Free Deep Reinforcement Learning Algorithms.pdf,True,True,False,2024,rlj,rlj_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,a2c,dqn,ppo,sac,,,
41,Imitation Learning from Observation through Optimal Transport.pdf,False,False,False,2024,rlj,rlj_2024,1-5,(?:discount|reward)\s+function,,,,,,,trpo,td3,sac,,,,
42,Human-compatible driving agents through data-regularized self-play reinforcement learning.pdf,True,True,False,2024,rlj,rlj_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
43,A Provably Efficient Option-Based Algorithm for both High-Level and Low-Level Learning.pdf,False,False,False,2024,rlj,rlj_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
44,Mitigating the Curse of Horizon in Monte-Carlo Returns.pdf,False,False,False,2024,rlj,rlj_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
45,Trust-based Consensus in Multi-Agent Reinforcement Learning Systems.pdf,True,True,False,2024,rlj,rlj_2024,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,dqn,ppo,sac,,,,
46,Dissecting Deep RL with High Update Ratios Combatting Value Divergence.pdf,True,True,False,2024,rlj,rlj_2024,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,sac,ddpg,td-mpc,ppo,,
47,Cross-environment Hyperparameter Tuning for Reinforcement Learning.pdf,False,True,False,2024,rlj,rlj_2024,over 10,(?:discount|reward)\s+function,,,,,,,dqn,ddpg,ppo,sac,,,
48,Bandits with Multimodal Structure.pdf,False,False,False,2024,rlj,rlj_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
49,Physics-Informed Model and Hybrid Planning for Efficient Dyna-Style Reinforcement Learning.pdf,True,False,False,2024,rlj,rlj_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,sac,pets,dreamer,td-mpc,,
50,JoinGym An Efficient Join Order Selection Environment.pdf,True,True,False,2024,rlj,rlj_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dqn,ppo,sac,,,,
51,Surprise-Adaptive Intrinsic Motivation for Unsupervised Reinforcement Learning.pdf,False,False,False,2024,rlj,rlj_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,ppo,sac,,,,
52,Non-adaptive Online Finetuning for Offline Reinforcement Learning.pdf,False,False,False,2024,rlj,rlj_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
53,Multi-view Disentanglement for Reinforcement Learning with Multiple Cameras.pdf,True,True,False,2024,rlj,rlj_2024,1-5,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
54,A Simple Mixture Policy Parameterization for Improving Sample Efficiency of CVaR Optimization.pdf,False,False,False,2024,rlj,rlj_2024,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,dqn,ppo,sac,,,,
55,Policy-Guided Diffusion.pdf,True,False,False,2024,rlj,rlj_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,td3,sac,pets,ppo,,
56,Light-weight Probing of Unsupervised Representations for Reinforcement Learning.pdf,False,True,False,2024,rlj,rlj_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,dreamer,ppo,,,,
57,Unifying Model-Based and Model-Free Reinforcement Learning with Equivalent Policy Sets.pdf,False,False,False,2024,rlj,rlj_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,td3,sac,dreamer,ddpg,ppo,
58,Constant Stepsize Q-learning Distributional Convergence Bias and Extrapolation.pdf,False,True,False,2024,rlj,rlj_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,ppo,,,,,
59,Guided Data Augmentation for Offline Reinforcement Learning and Imitation Learning.pdf,True,True,False,2024,rlj,rlj_2024,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,td3,ppo,,,,
60,States as goal-directed concepts an epistemic approach to state-representation learning.pdf,False,False,False,2024,rlj,rlj_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
61,A Recipe for Unbounded Data Augmentation in Visual Reinforcement Learning.pdf,False,True,False,2024,rlj,rlj_2024,1-5,(?:discount|reward)\s+function,,,,,,,dqn,ppo,sac,,,,
62,Zero-shot cross-modal transfer of Reinforcement Learning policies through a Global Workspace.pdf,False,False,False,2024,rlj,rlj_2024,0,,,,,,,,Not specified,,,,,,
63,PID Accelerated Temporal Difference Algorithms.pdf,False,True,False,2024,rlj,rlj_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,ppo,sac,,,,
64,An Idiosyncrasy of Time-discretization in Reinforcement Learning.pdf,False,False,False,2024,rlj,rlj_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,ppo,sac,,,,
65,Sequential Decision-Making for Inline Text Autocomplete.pdf,False,False,False,2024,rlj,rlj_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dqn,trpo,ppo,sac,,,
66,On Welfare-Centric Fair Reinforcement Learning.pdf,False,False,False,2024,rlj,rlj_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
67,The Limits of Pure Exploration in POMDPs When the Observation Entropy is Enough.pdf,False,False,False,2024,rlj,rlj_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
68,Cyclicity-Regularized Coordination Graphs.pdf,False,False,False,2024,rlj,rlj_2024,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,dqn,ppo,,,,,
69,ROIL Robust Offline Imitation Learning without Trajectories.pdf,False,False,False,2024,rlj,rlj_2024,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
70,Best Response Shaping.pdf,True,True,False,2024,rlj,rlj_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
71,Quantifying Interaction Level Between Agents Helps Cost-efficient Generalization in Multi-agent Rein.pdf,True,False,False,2024,rlj,rlj_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
72,Learning Discrete World Models for Heuristic Search.pdf,True,False,False,2024,rlj,rlj_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,dqn,,,,,,
73,Reinforcement Learning from Delayed Observations via World Models.pdf,True,True,False,2024,rlj,rlj_2024,0,,,,,,,,Not specified,,,,,,
74,Harnessing Discrete Representations for Continual Reinforcement Learning.pdf,True,True,False,2024,rlj,rlj_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,dqn,dreamer,ppo,,,,
75,Offline Diversity Maximization under Imitation Constraints.pdf,False,False,False,2024,rlj,rlj_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,ppo,,,,,
76,Exploring Uncertainty in Distributional Reinforcement Learning.pdf,False,True,False,2024,rlj,rlj_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,ppo,sac,,,,
77,Distributionally Robust Constrained Reinforcement Learning under Strong Duality.pdf,False,False,False,2024,rlj,rlj_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dqn,ppo,sac,,,,
78,A Batch Sequential Halving Algorithm without Performance Degradation.pdf,True,True,False,2024,rlj,rlj_2024,0,,,,,,,,Not specified,,,,,,
79,MultiHyRL Robust Hybrid RL for Obstacle Avoidance against Adversarial Attacks on the Observation Spa.pdf,True,True,False,2024,rlj,rlj_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
80,Bad Habits Policy Confounding and Out-of-Trajectory Generalization in RL.pdf,False,False,False,2024,rlj,rlj_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
81,Graph Neural Thompson Sampling.pdf,False,True,False,2024,rlj,rlj_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
82,Robotic Manipulation Datasets for Offline Compositional Reinforcement Learning.pdf,True,True,False,2024,rlj,rlj_2024,1-5,(?:discount|reward)\s+function,,,,,,,dqn,ppo,sac,,,,
83,Towards Principled Practical Policy Gradient for Bandits and Tabular MDPs.pdf,False,False,False,2024,rlj,rlj_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
84,BetaZero Belief-State Planning for Long-Horizon POMDPs using Learned Approximations.pdf,True,True,False,2024,rlj,rlj_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
85,Three Dogmas of Reinforcement Learning.pdf,False,False,False,2024,rlj,rlj_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
86,Can Differentiable Decision Trees Enable Interpretable Reward Learning from Human Feedback.pdf,True,False,False,2024,rlj,rlj_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
87,Policy Gradient with Active Importance Sampling.pdf,False,True,False,2024,rlj,rlj_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
88,An Open-Loop Baseline for Reinforcement Learning Locomotion Tasks.pdf,True,True,False,2024,rlj,rlj_2024,6-10,(?:discount|reward)\s+function,,,,,,,ddpg,ppo,sac,,,,
89,Enabling Intelligent Interactions between an Agent and an LLM A Reinforcement Learning Approach.pdf,True,False,False,2024,rlj,rlj_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
90,Multistep Inverse Is Not All You Need.pdf,True,False,False,2024,rlj,rlj_2024,0,,,,,,,,Not specified,,,,,,
91,The Role of Inherent Bellman Error in Offline Reinforcement Learning with Linear Function Approximat.pdf,False,False,False,2024,rlj,rlj_2024,1-5,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
92,An Optimal Tightness Bound for the Simulation Lemma.pdf,False,False,False,2024,rlj,rlj_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
93,Sample Complexity of Offline Distributionally Robust Linear Markov Decision Processes.pdf,False,False,False,2024,rlj,rlj_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,ppo,sac,,,,
94,More Efficient Randomized Exploration for Reinforcement Learning via Approximate Sampling.pdf,True,True,False,2024,rlj,rlj_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,dqn,ppo,,,,,
95,Contextualized Hybrid Ensemble Q-learning Learning Fast with Control Priors.pdf,True,True,False,2024,rlj,rlj_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
96,Bounding-Box Inference for Error-Aware Model-Based Reinforcement Learning.pdf,True,True,False,2024,rlj,rlj_2024,over 10,(?:discount|reward)\s+function,,,,,,,dqn,dreamer,ppo,sac,,,
97,Cost Aware Best Arm Identification.pdf,False,False,False,2024,rlj,rlj_2024,0,,,,,,,,Not specified,,,,,,
98,A Super-human Vision-based Reinforcement Learning Agent for Autonomous Racing in Gran Turismo.pdf,False,True,False,2024,rlj,rlj_2024,1-5,(?:discount|reward)\s+function,,,,,,,dqn,ppo,sac,a3c,a2c,,
99,Inverse Reinforcement Learning with Multiple Planning Horizons.pdf,False,True,False,2024,rlj,rlj_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
100,Posterior Sampling for Continuing Environments.pdf,False,False,False,2024,rlj,rlj_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,dqn,ppo,,,,,
101,Learning to Optimize for Reinforcement Learning.pdf,True,True,False,2024,rlj,rlj_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,a2c,ppo,,,,,
102,Inception Efficiently Computable Misinformation Attacks on Markov Games.pdf,False,False,False,2024,rlj,rlj_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
103,Combining Reconstruction and Contrastive Methods for Multimodal Representations in RL.pdf,True,True,False,2024,rlj,rlj_2024,0,,,,,,,,Not specified,,,,,,
104,Weight Clipping for Deep Continual and Reinforcement Learning.pdf,True,True,False,2024,rlj,rlj_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,dqn,ppo,sac,,,,
105,Planning to Go Out-of-Distribution in Offline-to-Online Reinforcement Learning.pdf,True,True,False,2024,rlj,rlj_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,sac,,,,,,
106,ICU-Sepsis A Benchmark MDP Built from Real Medical Data.pdf,True,True,False,2024,rlj,rlj_2024,6-10,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,ppo,sac,,,,
107,A Tighter Convergence Proof of Reverse Experience Replay.pdf,True,False,False,2024,rlj,rlj_2024,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,dqn,ppo,,,,,
108,D5RL Diverse Datasets for Data-Driven Deep Reinforcement Learning.pdf,True,False,False,2024,rlj,rlj_2024,0,(?:discount|reward)\s+function,,,,,,,dqn,td3,ppo,,,,
109,Shield Decomposition for Safe Reinforcement Learning in General Partially Observable Multi-Agent Env.pdf,False,False,False,2024,rlj,rlj_2024,over 10,(?:discount|reward)\s+function,,,,,,,dqn,ppo,sac,,,,
110,The Cliff of Overcommitment with Policy Gradient Step Sizes.pdf,False,True,False,2024,rlj,rlj_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
111,Policy Architectures for Compositional Generalization in Control.pdf,True,False,False,2024,rlj,rlj_2024,1-5,action-value\s+function,,,,,,,ddpg,ppo,sac,,,,
112,Value Internalization Learning and Generalizing from Social Reward.pdf,True,False,False,2024,rlj,rlj_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
0,State Abstractions for Lifelong Reinforcement Learning.pdf,True,False,False,2018,icml,icml_2018,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
1,Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement.pdf,False,False,False,2018,icml,icml_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
2,Scalable Bilinear Pi Learning Using State and Action Features.pdf,False,False,False,2018,icml,icml_2018,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
3,Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents.pdf,False,False,False,2018,icml,icml_2018,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
4,Structured Evolution with Compact Architectures for Scalable Policy Optimization.pdf,False,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
5,Graph Networks as Learnable Physics Engines for Inference and Control.pdf,False,False,False,2018,icml,icml_2018,6-10,(?:discount|reward)\s+function,,,,,,,ppo,ddpg,,,,,
6,Efficient Neural Architecture Search via Parameters Sharing.pdf,False,True,False,2018,icml,icml_2018,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
7,SBEED Convergent Reinforcement Learning with Nonlinear Function Approximation.pdf,False,False,False,2018,icml,icml_2018,1-5,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,ppo,,
8,An Efficient Generalized Bellman Update For Cooperative Inverse Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
9,RLlib Abstractions for Distributed Reinforcement Learning.pdf,True,True,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a3c,ppo,dqn,ddpg,,,
10,Discovering and Removing Exogenous State Variables and Rewards for Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
11,Deep Reinforcement Learning in Continuous Action Spaces a Case Study in the Game of Simulated Curlin.pdf,True,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,ppo,sac,,,,,
12,Synthesizing Programs for Images using Reinforced Adversarial Learning.pdf,False,False,False,2018,icml,icml_2018,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a2c,,,,,,
13,Noisy Natural Gradient as Variational Inference.pdf,False,False,False,2018,icml,icml_2018,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
14,Modeling Others using Oneself in Multi-Agent Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,over 10,(?:discount|reward)\s+function,,,,,,,a3c,ppo,dqn,a2c,,,
15,Learning Policy Representations in Multiagent Systems.pdf,False,True,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,ddpg,,,,
16,Implicit Quantile Networks for Distributional Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
17,Composable Planning with Attributes.pdf,False,True,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,ppo,,,,,,
18,Time Limits in Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,pets,ppo,dqn,,,,
19,Path-Level Network Transformation for Efficient Architecture Search.pdf,True,True,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
20,The Mirage of Action-Dependent Baselines in Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,,,,,,
21,Self-Imitation Learning.pdf,True,False,False,2018,icml,icml_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,,,,trpo,a3c,dqn,a2c,ppo,,
22,Fourier Policy Gradients.pdf,True,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,,,,,ppo,,,,,,
23,Thompson Sampling for Combinatorial Semi-Bandits.pdf,False,False,False,2018,icml,icml_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
24,Focused Hierarchical RNNs for Conditional Sequence Processing.pdf,False,False,False,2018,icml,icml_2018,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,pets,,,,,,
25,Learning to Act in Decentralized Partially Observable MDPs.pdf,False,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,,,,,ppo,dqn,,,,,
26,Stagewise Safe Bayesian Optimization with Gaussian Processes.pdf,False,False,False,2018,icml,icml_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
27,Self-Consistent Trajectory Autoencoder Hierarchical Reinforcement Learning with Trajectory Embedding.pdf,False,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,trpo,a3c,ppo,,,,
28,Structured Control Nets for Deep Reinforcement Learning.pdf,True,True,False,2018,icml,icml_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
29,Regret Minimization for Partially Observable Deep Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,,,,trpo,ppo,dqn,ddpg,,,
30,Visualizing and Understanding Atari Agents.pdf,True,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,ppo,a2c,,,,
31,Hierarchical Imitation and Reinforcement Learning.pdf,True,False,False,2018,icml,icml_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
32,Gated Path Planning Networks.pdf,False,False,False,2018,icml,icml_2018,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
33,End-to-end Active Object Tracking via Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,ppo,sac,,,,
34,More Robust Doubly Robust Off-policy Evaluation.pdf,False,False,False,2018,icml,icml_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,,,,,ppo,,,,,,
35,Importance Weighted Transfer of Samples in Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
36,Differentiable plasticity training plastic neural networks with backpropagation.pdf,True,False,False,2018,icml,icml_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a3c,ppo,a2c,,,,
37,Decoupling Gradient-Like Learning Rules from Representations.pdf,False,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,sac,,,,
38,Soft Actor-Critic Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.pdf,True,True,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,dqn,ddpg,sac,td3,ppo,
39,Learning to Explore via Meta-Policy Gradient.pdf,True,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,dqn,ddpg,,,,,
40,Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,over 10,state-action\s+pairs,,,,,,,ppo,,,,,,
41,Neural Program Synthesis from Diverse Demonstration Videos.pdf,False,False,False,2018,icml,icml_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
42,Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam.pdf,True,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,ddpg,,,,,
43,Path Consistency Learning in Tsallis Entropy Regularized MDPs.pdf,False,False,False,2018,icml,icml_2018,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,a3c,ppo,,,,
44,Stochastic Variance-Reduced Policy Gradient.pdf,True,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
45,Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games.pdf,True,True,False,2018,icml,icml_2018,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,dqn,a2c,,,,
46,Learning by Playing Solving Sparse Reward Tasks from Scratch.pdf,False,False,False,2018,icml,icml_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
47,Machine Theory of Mind.pdf,False,False,False,2018,icml,icml_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
48,Configurable Markov Decision Processes.pdf,False,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
49,Universal Planning Networks Learning Generalizable Representations for Visuomotor Control.pdf,False,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
50,Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation.pdf,False,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,,,,,,
51,Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control.pdf,False,False,False,2018,icml,icml_2018,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,ddpg,,,,,
52,Smoothed Action Value Functions for Learning Gaussian Policies.pdf,False,True,False,2018,icml,icml_2018,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,ddpg,,,
53,Mean Field Multi-Agent Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,sac,,,
54,Convergent Tree Backup and Retrace with Function Approximation.pdf,False,False,False,2018,icml,icml_2018,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
55,Compressing Neural Networks using the Variational Information Bottleneck.pdf,True,False,False,2018,icml,icml_2018,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
56,Competitive Multi-agent Inverse Reinforcement Learning with Sub-optimal Demonstrations.pdf,False,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
57,Learning to Coordinate with Coordination Graphs in Repeated Single-Stage Multi-Agent Decision Proble.pdf,False,False,False,2018,icml,icml_2018,over 10,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
58,PIPPS Flexible Model-Based Policy Search Robust to the Curse of Chaos.pdf,False,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
59,TACO Learning Task Decomposition via Temporal Alignment for Control.pdf,False,False,False,2018,icml,icml_2018,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
60,Tighter Variational Bounds are Not Necessarily Better.pdf,False,False,False,2018,icml,icml_2018,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
61,Feedback-Based Tree Search for Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
62,Adversarial Attack on Graph Structured Data.pdf,False,True,False,2018,icml,icml_2018,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,,,,,,,ppo,dqn,a2c,sac,,,
63,GraphRNN Generating Realistic Graphs with Deep Auto-regressive Models.pdf,True,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
64,GEP-PG Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms.pdf,True,False,False,2018,icml,icml_2018,over 10,(?:discount|reward)\s+function,,,,,,,trpo,dqn,ddpg,sac,ppo,,
65,Learning with Abandonment.pdf,True,False,False,2018,icml,icml_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
66,The Uncertainty Bellman Equation and Exploration.pdf,False,False,False,2018,icml,icml_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,dqn,,,,,,
67,Learning to search with MCTSnets.pdf,False,True,False,2018,icml,icml_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
68,Recurrent Predictive State Policy Networks.pdf,True,False,False,2018,icml,icml_2018,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,dqn,,,,
69,Policy Optimization as Wasserstein Gradient Flows.pdf,False,False,False,2018,icml,icml_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,dqn,a2c,sac,ppo,,
70,Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace.pdf,False,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
71,Least-Squares Temporal Difference Learning for the Linear Quadratic Regulator.pdf,False,False,False,2018,icml,icml_2018,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
72,IMPALA Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures.pdf,True,True,False,2018,icml,icml_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,a3c,dqn,a2c,sac,ppo,,
73,Spotlight Optimizing Device Placement for Training Deep Neural Networks.pdf,True,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
74,Addressing Function Approximation Error in Actor-Critic Methods.pdf,True,False,False,2018,icml,icml_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,trpo,dqn,ddpg,sac,td3,ppo,
75,Fast Bellman Updates for Robust MDPs.pdf,False,False,False,2018,icml,icml_2018,1-5,value\s+function\s+approximation,,,,,,,ppo,,,,,,
76,Adversarially Regularized Autoencoders.pdf,True,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
77,Efficient Gradient-Free Variational Inference using Policy Search.pdf,True,False,False,2018,icml,icml_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,sac,,,,,,
78,Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator.pdf,False,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,,,,,
79,Improving Regression Performance with Distributional Losses.pdf,True,False,False,2018,icml,icml_2018,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
80,An Inference-Based Policy Gradient Method for Learning Options.pdf,False,False,False,2018,icml,icml_2018,6-10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,,,,,a3c,sac,,,,,
81,Latent Space Policies for Hierarchical Reinforcement Learning.pdf,True,False,False,2018,icml,icml_2018,0,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,ppo,,
82,Deep Variational Reinforcement Learning for POMDPs.pdf,False,False,False,2018,icml,icml_2018,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,a3c,dqn,a2c,sac,ppo,,
83,Clipped Action Policy Gradient.pdf,True,True,False,2018,icml,icml_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,trpo,ppo,,,,,
84,Programmatically Interpretable Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,ddpg,,,,,
85,Lipschitz Continuity in Model-based Reinforcement Learning.pdf,True,False,False,2018,icml,icml_2018,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
86,Continual Reinforcement Learning with Complex Synapses.pdf,False,False,False,2018,icml,icml_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
87,Beyond the One-Step Greedy Approach in Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
88,Minimax Concave Penalized Multi-Armed Bandit Model with High-Dimensional Covariates.pdf,False,False,False,2018,icml,icml_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
89,Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning.pdf,True,False,False,2018,icml,icml_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
90,Adversarial Risk and the Dangers of Evaluating Against Weak Attacks.pdf,False,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
91,Learning the Reward Function for a Misspecified Model.pdf,True,False,False,2018,icml,icml_2018,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
92,QMIX Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning.pdf,False,False,False,2018,icml,icml_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
93,Automatic Goal Generation for Reinforcement Learning Agents.pdf,False,False,False,2018,icml,icml_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
94,DiCE The Infinitely Differentiable Monte Carlo Estimator.pdf,True,False,False,2018,icml,icml_2018,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,,,,,
95,Policy Optimization with Demonstrations.pdf,False,False,False,2018,icml,icml_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,dqn,ddpg,,,
96,Policy and Value Transfer in Lifelong Reinforcement Learning.pdf,True,False,False,2018,icml,icml_2018,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
0,Maximum Entropy-Regularized Multi-Goal Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,a3c,sac,ddpg,,,
1,Learning to select for a predefined ranking.pdf,True,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
2,Social Influence as Intrinsic Motivation for Multi-Agent Deep Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,1-5,(?:discount|reward)\s+function,,,,,,,a3c,ppo,a2c,,,,
3,Provably Efficient Maximum Entropy Exploration.pdf,True,False,False,2019,icml,icml_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
4,Policy Certificates Towards Accountable Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
5,Random Expert Distillation Imitation Learning via Expert Policy Support Estimation.pdf,True,True,False,2019,icml,icml_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
6,Myopic Posterior Sampling for Adaptive Goal Oriented Design of Experiments.pdf,True,True,False,2019,icml,icml_2019,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
7,A Deep Reinforcement Learning Perspective on Internet Congestion Control.pdf,True,True,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
8,Taming MAML Efficient unbiased meta-reinforcement learning.pdf,False,False,False,2019,icml,icml_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
9,Action Robust Reinforcement Learning and Applications in Continuous Control.pdf,True,True,False,2019,icml,icml_2019,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,ddpg,,,,
10,Information-Theoretic Considerations in Batch Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
11,Nonlinear Distributional Gradient Temporal-Difference Learning.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,,,,,ppo,dqn,,,,,
12,Learning Context-dependent Label Permutations for Multi-label Classification.pdf,False,False,False,2019,icml,icml_2019,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
13,Addressing the Loss-Metric Mismatch with Adaptive Loss Alignment.pdf,False,True,False,2019,icml,icml_2019,6-10,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
14,Discovering Options for Exploration by Minimizing Cover Time.pdf,False,False,False,2019,icml,icml_2019,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
15,Remember and Forget for Experience Replay.pdf,True,False,False,2019,icml,icml_2019,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,trpo,dqn,ddpg,sac,ppo,,
16,Combining parametric and nonparametric models for off-policy evaluation.pdf,False,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
17,Simple Black-box Adversarial Attacks.pdf,True,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
18,Learning Action Representations for Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
19,Importance Sampling Policy Evaluation with an Estimated Behavior Policy.pdf,True,False,False,2019,icml,icml_2019,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
20,Dimension-Wise Importance Sampling Weight Clipping for Sample-Efficient Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,td3,ppo,
21,Discovering Context Effects from Raw Choice Data.pdf,False,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
22,Imitation Learning from Imperfect Demonstration.pdf,False,False,False,2019,icml,icml_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
23,The Value Function Polytope in Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
24,POLITEX Regret Bounds for Policy Iteration using Expert Prediction.pdf,False,False,False,2019,icml,icml_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
25,Imitating Latent Policies from Observation.pdf,True,False,False,2019,icml,icml_2019,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
26,A Theory of Regularized Markov Decision Processes.pdf,False,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,trpo,dqn,sac,,,,
27,Improving Neural Network Quantization without Retraining using Outlier Channel Splitting.pdf,True,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
28,Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations.pdf,True,True,False,2019,icml,icml_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
29,Transfer of Samples in Policy Search via Multiple Importance Sampling.pdf,False,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
30,Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation.pdf,True,False,False,2019,icml,icml_2019,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,a3c,a2c,,,,,
31,Trajectory-Based Off-Policy Deep Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,ddpg,,,,,
32,DeepMDP Learning Continuous Latent Space Models for Representation Learning.pdf,False,False,False,2019,icml,icml_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
33,Provably efficient RL with Rich Observations via Latent State Decoding.pdf,True,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
34,Fast Context Adaptation via Meta-Learning.pdf,True,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,trpo,,,,,,
35,Understanding the Impact of Entropy on Policy Optimization.pdf,False,False,False,2019,icml,icml_2019,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,trpo,ppo,dqn,,,,
36,Distributional Multivariate Policy Evaluation and Exploration with the Bellman GAN.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,dqn,,,,,
37,Finite-Time Analysis of Distributed TD0 with Linear Function Approximation on Multi-Agent Reinforcem.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
38,Kernel-Based Reinforcement Learning in Robust Markov Decision Processes.pdf,False,False,False,2019,icml,icml_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,,,,,,
39,Per-Decision Option Discounting.pdf,False,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
40,Multi-Agent Adversarial Inverse Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
41,Scalable Training of Inference Networks for Gaussian-Process Models.pdf,True,False,False,2019,icml,icml_2019,0,value\s+function\s+approximation,,,,,,,other,,,,,,
42,A Composite Randomized Incremental Gradient Method.pdf,False,False,False,2019,icml,icml_2019,over 10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
43,Off-Policy Deep Reinforcement Learning without Exploration.pdf,True,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,trpo,dqn,ddpg,,,,
44,Collaborative Evolutionary Reinforcement Learning.pdf,True,True,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,,,,td3,dqn,ddpg,,,,
45,Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
46,Batch Policy Learning under Constraints.pdf,False,False,False,2019,icml,icml_2019,over 10,action-value\s+function,,,,,,,ppo,,,,,,
47,Quantifying Generalization in Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
48,Reinforcement Learning in Configurable Continuous Environments.pdf,False,False,False,2019,icml,icml_2019,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
49,Deep Counterfactual Regret Minimization.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
50,Dynamic Measurement Scheduling for Event Forecasting using Deep RL.pdf,True,True,False,2019,icml,icml_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
51,SOLAR Deep Structured Representations for Model-Based Reinforcement Learning.pdf,True,True,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
52,Hessian Aided Policy Gradient.pdf,False,True,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
53,Guided evolutionary strategies augmenting random search with surrogate gradients.pdf,True,True,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
54,Policy Consolidation for Continual Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
55,CURIOUS Intrinsically Motivated Modular Multi-Goal Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,6-10,(?:discount|reward)\s+function,,,,,,,dqn,ddpg,sac,,,,
56,Weakly-Supervised Temporal Localization via Occurrence Count Learning.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,pets,ppo,sac,,,,
57,Grid-Wise Control for Multi-Agent Reinforcement Learning in Video Game AI.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
58,Bayesian Counterfactual Risk Minimization.pdf,False,True,False,2019,icml,icml_2019,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
59,Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables.pdf,True,False,False,2019,icml,icml_2019,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,sac,,,,,,
60,Learning Linear-Quadratic Regulators Efficiently with only sqrtT Regret.pdf,False,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
61,Fingerprint Policy Optimisation for Robust Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
62,Cautious Regret Minimization Online Optimization with Long-Term Budget Constraints.pdf,False,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
63,Structured agents for physical construction.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
64,Separating value functions across time-scales.pdf,True,False,False,2019,icml,icml_2019,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
65,Probability Functional Descent A Unifying Perspective on GANs Variational Inference and Reinforcemen.pdf,False,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,a2c,,,,,
66,Learning Neurosymbolic Generative Models via Program Synthesis.pdf,False,False,False,2019,icml,icml_2019,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
67,Curiosity-Bottleneck Exploration By Distilling Task-Specific Novelty.pdf,True,False,False,2019,icml,icml_2019,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
68,Distributional Reinforcement Learning for Efficient Exploration.pdf,False,False,False,2019,icml,icml_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
69,Learning from a Learner.pdf,False,False,False,2019,icml,icml_2019,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,ddpg,sac,td3,ppo,,
70,An Investigation of Model-Free Planning.pdf,True,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a3c,,,,,,
71,Insertion Transformer Flexible Sequence Generation via Insertion Operations.pdf,False,True,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
72,Learning a Prior over Intent via Meta-Inverse Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
73,Adaptive Sensor Placement for Continuous Spaces.pdf,False,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
74,Generative Adversarial User Model for Reinforcement Learning Based Recommendation System.pdf,False,False,False,2019,icml,icml_2019,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
75,QTRAN Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
76,Composing Value Functions in Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
77,Exploration Conscious Reinforcement Learning Revisited.pdf,True,True,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,a3c,dqn,ddpg,,,
78,Accelerated Flow for Probability Distributions.pdf,False,False,False,2019,icml,icml_2019,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
79,A Baseline for Any Order Gradient Estimation in Stochastic Computation Graphs.pdf,False,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
80,On the Generalization Gap in Reparameterizable Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
81,Learning Novel Policies For Tasks.pdf,False,False,False,2019,icml,icml_2019,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
82,A fully differentiable beam search decoder.pdf,False,True,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
83,Revisiting the Softmax Bellman Operator New Benefits and New Perspective.pdf,True,True,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
84,Probabilistic Neural Symbolic Models for Interpretable Visual Question Answering.pdf,False,False,False,2019,icml,icml_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
85,Model-Based Active Exploration.pdf,True,True,False,2019,icml,icml_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
86,A Wrapped Normal Distribution on Hyperbolic Space for Gradient-Based Learning.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,,,,,,
87,Online Control with Adversarial Disturbances.pdf,False,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
88,Dead-ends and Secure Exploration in Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
89,ARSM Augment-REINFORCE-Swap-Merge Estimator for Gradient Backpropagation Through Categorical Variabl.pdf,True,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,other,,,,,,
90,Control Regularization for Reduced Variance Reinforcement Learning.pdf,True,True,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,ddpg,,,,,
91,Diagnosing Bottlenecks in Deep Q-learning Algorithms.pdf,False,False,False,2019,icml,icml_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,dqn,sac,,,
92,Actor-Attention-Critic for Multi-Agent Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,sac,ddpg,,,
93,Learning to Collaborate in Markov Decision Processes.pdf,False,False,False,2019,icml,icml_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
94,Predictor-Corrector Policy Optimization.pdf,True,False,False,2019,icml,icml_2019,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,,,,,
95,Composing Entropic Policies using Divergence Correction.pdf,False,False,False,2019,icml,icml_2019,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
96,Graphite Iterative Generative Modeling of Graphs.pdf,False,True,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
97,Garbage In Reward Out Bootstrapping Exploration in Multi-Armed Bandits.pdf,False,False,False,2019,icml,icml_2019,over 10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
98,Online Variance Reduction with Mixtures.pdf,True,False,False,2019,icml,icml_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
99,Task-Agnostic Dynamics Priors for Deep Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
100,The Natural Language of Actions.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
101,Neural Logic Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,trpo,ppo,,,,,
102,On the Feasibility of Learning Rather than Assuming Human Biases for Reward Inference.pdf,True,False,False,2019,icml,icml_2019,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
103,Self-Supervised Exploration via Disagreement.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
104,TarMAC Targeted Multi-Agent Communication.pdf,True,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
105,Calibrated Model-Based Deep Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,6-10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
106,Bayesian Optimization Meets Bayesian Optimal Stopping.pdf,False,True,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,ddpg,,,,
107,On the Design of Estimators for Bandit Off-Policy Evaluation.pdf,False,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
108,Sample-Optimal Parametric Q-Learning Using Linearly Additive Features.pdf,False,False,False,2019,icml,icml_2019,0,state-action\s+pairs,,,,,,,ppo,dqn,,,,,
109,Optimistic Policy Optimization via Multiple Importance Sampling.pdf,True,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
110,Optimal Algorithms for Lipschitz Bandits with Heavy-tailed Rewards.pdf,False,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
111,Dynamic Weights in Multi-Objective Deep Reinforcement Learning.pdf,True,False,False,2019,icml,icml_2019,6-10,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
112,Learning to Generalize from Sparse and Underspecified Rewards.pdf,True,True,False,2019,icml,icml_2019,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
113,Target-Based Temporal-Difference Learning.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,ddpg,sac,,,
114,Learning Latent Dynamics for Planning from Pixels.pdf,False,False,False,2019,icml,icml_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,,,,,,
115,TibGM A Transferable and Information-Based Graphical Model Approach for Reinforcement Learning.pdf,False,False,False,2019,icml,icml_2019,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
116,Iterative Linearized Control Stable Algorithms and Complexity Guarantees.pdf,True,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,sac,,,,,,
117,More Efficient Off-Policy Evaluation through Regularized Targeted Learning.pdf,False,False,False,2019,icml,icml_2019,over 10,action-value\s+function,,,,,,,ppo,,,,,,
118,Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Val.pdf,False,False,False,2019,icml,icml_2019,0,value\s+function\s+approximation,,,,,,,ppo,,,,,,
119,EMI Exploration with Mutual Information.pdf,True,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,a3c,ppo,,,,
120,Contextual Memory Trees.pdf,True,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
121,Finding Options that Minimize Planning Time.pdf,False,False,False,2019,icml,icml_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
122,Online Adaptive Principal Component Analysis and Its extensions.pdf,True,False,False,2019,icml,icml_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
123,Making Deep Q-learning methods robust to time discretization.pdf,False,False,False,2019,icml,icml_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,trpo,a3c,dqn,ddpg,ppo,,
0,One Policy to Control Them All Shared Modular Policies for Agent-Agnostic Control.pdf,False,True,False,2020,icml,icml_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,ppo,,,,,
1,Revisiting Fundamentals of Experience Replay.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
2,A Chance-Constrained Generative Framework for Sequence Optimization.pdf,False,True,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
3,From Importance Sampling to Doubly Robust Policy Gradient.pdf,False,False,False,2020,icml,icml_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
4,Safe Reinforcement Learning in Constrained Markov Decision Processes.pdf,True,False,False,2020,icml,icml_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
5,Q-value Path Decomposition for Deep Multiagent Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
6,Dual Mirror Descent for Online Allocation Problems.pdf,False,False,False,2020,icml,icml_2020,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
7,Minimax-Optimal Off-Policy Evaluation with Linear Function Approximation.pdf,False,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
8,Reward-Free Exploration for Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
9,Online Dense Subgraph Discovery via Blurred-Graph Feedback.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
10,Double Reinforcement Learning for Efficient and Robust Off-Policy Evaluation.pdf,False,False,False,2020,icml,icml_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
11,On the Generalization Effects of Linear Transformations in Data Augmentation.pdf,False,False,False,2020,icml,icml_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
12,Optimizing for the Future in Non-Stationary MDPs.pdf,True,False,False,2020,icml,icml_2020,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
13,CURL Contrastive Unsupervised Representations for Reinforcement Learning.pdf,True,False,False,2020,icml,icml_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dreamer,ppo,dqn,sac,,,
14,What can I do here A Theory of Affordances in Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
15,Model-free Reinforcement Learning in Infinite-horizon Average-reward Markov Decision Processes.pdf,False,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,,,,,,
16,Distributionally Robust Policy Evaluation and Learning in Offline Contextual Bandits.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
17,Sequential Transfer in Reinforcement Learning with a Generative Model.pdf,False,False,False,2020,icml,icml_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,ppo,dqn,,,,,
18,Reinforcement Learning for Non-Stationary Markov Decision Processes The Blessing of More Optimism.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
19,Fiduciary Bandits.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
20,Generative Teaching Networks Accelerating Neural Architecture Search by Learning to Generate Synthet.pdf,True,True,False,2020,icml,icml_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
21,Selective Dyna-Style Planning Under Limited Model Capacity.pdf,False,False,False,2020,icml,icml_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
22,Off-Policy Actor-Critic with Shared Experience Replay.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,dqn,,,,,,
23,Multi-step Greedy Reinforcement Learning Algorithms.pdf,True,False,False,2020,icml,icml_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,dqn,,,,,
24,Can Autonomous Vehicles Identify Recover From and Adapt to Distribution Shifts.pdf,False,False,False,2020,icml,icml_2020,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
25,Evolutionary Reinforcement Learning for Sample-Efficient Multiagent Coordination.pdf,False,True,False,2020,icml,icml_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,td3,ppo,ddpg,,,,
26,Estimating Qss with Deep Deterministic Dynamics Gradients.pdf,True,True,False,2020,icml,icml_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,ddpg,,,
27,Improving Molecular Design by Stochastic Iterative Target Augmentation.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
28,Near-optimal Regret Bounds for Stochastic Shortest Path.pdf,False,False,False,2020,icml,icml_2020,0,state-action\s+pairs,,,,,,,ppo,,,,,,
29,R2-B2 Recursive Reasoning-Based Bayesian Optimization for No-Regret Learning in Games.pdf,False,True,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
30,Optimizing Long-term Social Welfare in Recommender Systems A Constrained Matching Approach.pdf,True,False,False,2020,icml,icml_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
31,Learning Robot Skills with Temporal Variational Inference.pdf,True,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
32,Lookahead-Bounded Q-learning.pdf,True,False,False,2020,icml,icml_2020,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
33,Causal Effect Estimation and Optimal Dose Suggestions in Mobile Health.pdf,True,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
34,Hierarchical Generation of Molecular Graphs using Structural Motifs.pdf,True,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
35,A Natural Lottery Ticket Winner Reinforcement Learning with Ordinary Neural Circuits.pdf,True,True,False,2020,icml,icml_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
36,Task-Oriented Active Perception and Planning in Environments with Partially Known Semantics.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
37,Minimax Weight and Q-Function Learning for Off-Policy Evaluation.pdf,False,False,False,2020,icml,icml_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
38,Deep PQR Solving Inverse Reinforcement Learning using Anchor Actions.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
39,Generative Adversarial Imitation Learning with Neural Network Parameterization Global Optimality and.pdf,False,False,False,2020,icml,icml_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,,,,,,
40,Doubly robust off-policy evaluation with shrinkage.pdf,False,True,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
41,On the Expressivity of Neural Networks for Deep Reinforcement Learning.pdf,True,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
42,Goal-Aware Prediction Learning to Model What Matters.pdf,False,False,False,2020,icml,icml_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
43,Active World Model Learning with Progress Curiosity.pdf,False,False,False,2020,icml,icml_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
44,Information Particle Filter Tree An Online Algorithm for POMDPs with Belief-Based Rewards on Continu.pdf,True,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
45,Likelihood-free MCMC with Amortized Approximate Ratio Estimators.pdf,True,True,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
46,Min-Max Optimization without Gradients Convergence and Applications to Black-Box Evasion and Poisoni.pdf,True,False,False,2020,icml,icml_2020,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
47,Accountable Off-Policy Evaluation With Kernel Bellman Statistics.pdf,False,False,False,2020,icml,icml_2020,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
48,Efficiently Solving MDPs with Stochastic Mirror Descent.pdf,False,False,False,2020,icml,icml_2020,0,state-action\s+pairs,,,,,,,ppo,dqn,,,,,
49,Reinforcement Learning for Molecular Design Guided by Quantum Mechanics.pdf,True,True,False,2020,icml,icml_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
50,Bayesian Optimisation over Multiple Continuous and Categorical Inputs.pdf,True,True,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
51,BINOCULARS for efficient nonmyopic sequential experimental design.pdf,True,True,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
52,Multi-Agent Determinantal Q-Learning.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,,,,,dqn,,,,,,
53,Tuning-free Plug-and-Play Proximal Algorithm for Inverse Imaging Problems.pdf,False,True,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,trpo,ppo,sac,ddpg,,,
54,Bootstrap Latent-Predictive Representations for Multitask Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
55,ROMA Multi-Agent Reinforcement Learning with Emergent Roles.pdf,True,True,False,2020,icml,icml_2020,0,action-value\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
56,Explore Discover and Learn Unsupervised Discovery of State-Covering Skills.pdf,True,True,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
57,AR-DAE Towards Unbiased Neural Entropy Gradient Estimation.pdf,False,False,False,2020,icml,icml_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
58,Policy Teaching via Environment Poisoning Training-time Adversarial Attacks against Reinforcement Le.pdf,False,False,False,2020,icml,icml_2020,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
59,Provable Representation Learning for Imitation Learning via Bi-level Optimization.pdf,False,False,False,2020,icml,icml_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
60,Inductive-bias-driven Reinforcement Learning For Efficient Schedules in Heterogeneous Clusters.pdf,True,False,False,2020,icml,icml_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,a2c,,,,,
61,Skew-Fit State-Covering Self-Supervised Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
62,GradientDICE Rethinking Generalized Offline Estimation of Stationary Values.pdf,True,True,False,2020,icml,icml_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,,,,,,
63,Multi-Objective Molecule Generation using Interpretable Substructures.pdf,True,False,False,2020,icml,icml_2020,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,ppo,,,,,,
64,GraphOpt Learning Optimization Models of Graph Formation.pdf,False,True,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
65,Countering Language Drift with Seeded Iterated Learning.pdf,True,False,False,2020,icml,icml_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
66,Intrinsic Reward Driven Imitation Learning via Generative Model.pdf,True,False,False,2020,icml,icml_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
67,Optimally Solving Two-Agent Decentralized POMDPs Under One-Sided Information Sharing.pdf,False,False,False,2020,icml,icml_2020,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
68,Training Deep Energy-Based Models with f-Divergence Minimization.pdf,True,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
69,Striving for Simplicity and Performance in Off-Policy DRL Output Normalization and Non-Uniform Sampl.pdf,True,False,False,2020,icml,icml_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,td3,ppo,
70,Graphical Models Meet Bandits A Variational Thompson Sampling Approach.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
71,Statistically Efficient Off-Policy Policy Gradients.pdf,False,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
72,Student-Teacher Curriculum Learning via Reinforcement Learning Predicting Hospital Inpatient Admissi.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,,,,,ppo,dqn,ddpg,,,,
73,Deep Reinforcement Learning with Robust and Smooth Policy.pdf,False,True,False,2020,icml,icml_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,ppo,,
74,Learning Near Optimal Policies with Low Inherent Bellman Error.pdf,False,False,False,2020,icml,icml_2020,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
75,Inverse Active Sensing Modeling and Understanding Timely Decision-Making.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
76,A Finite-Time Analysis of Q-Learning with Neural Network Function Approximation.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
77,Learning Human Objectives by Evaluating Hypothetical Behavior.pdf,False,False,False,2020,icml,icml_2020,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
78,Bandits for BMO Functions.pdf,False,False,False,2020,icml,icml_2020,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
79,Kernel Methods for Cooperative Multi-Agent Contextual Bandits.pdf,False,False,False,2020,icml,icml_2020,over 10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
80,Representations for Stable Off-Policy Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,other,,,,,,
81,Discount Factor as a Regularizer in Reinforcement Learning.pdf,True,True,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,dqn,ddpg,sac,td3,ppo,,
82,Learning Adversarial Markov Decision Processes with Bandit Feedback and Unknown Transition.pdf,False,False,False,2020,icml,icml_2020,0,state-action\s+pairs,,,,,,,sac,,,,,,
83,Tightening Exploration in Upper Confidence Reinforcement Learning.pdf,True,False,False,2020,icml,icml_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
84,Decentralized Reinforcement Learning Global Decision-Making via Local Economic Transactions.pdf,True,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
85,Deep Coordination Graphs.pdf,True,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
86,Learning with Good Feature Representations in Bandits and in RL with a Generative Model.pdf,False,False,False,2020,icml,icml_2020,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
87,History-Gradient Aided Batch Size Adaptation for Variance Reduced Algorithms.pdf,False,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
88,Private Outsourced Bayesian Optimization.pdf,False,True,False,2020,icml,icml_2020,over 10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
89,Learning Optimal Tree Models under Beam Search.pdf,False,False,False,2020,icml,icml_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
90,Logarithmic Regret for Learning Linear Quadratic Regulators Efficiently.pdf,False,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
91,Learning Portable Representations for High-Level Planning.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
92,Learning Selection Strategies in Buchbergers Algorithm.pdf,False,False,False,2020,icml,icml_2020,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
93,Description Based Text Classification with Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,,,,,,
94,Model-Based Reinforcement Learning with Value-Targeted Regression.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
95,CoMic Complementary Task Learning  Mimicry for Reusable Skills.pdf,False,False,False,2020,icml,icml_2020,1-5,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,(?:discount|reward)\s+function,,,,,,other,,,,,,
96,Evaluating the Performance of Reinforcement Learning Algorithms.pdf,True,True,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,,,,,,ppo,sac,,,,,
97,Option Discovery in the Absence of Rewards with Manifold Analysis.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
98,Provably Convergent Two-Timescale Off-Policy Actor-Critic with Function Approximation.pdf,True,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,,,,,,
99,Provable Self-Play Algorithms for Competitive Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
100,Batch Stationary Distribution Estimation.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,a2c,,,,
101,Learning to Score Behaviors for Guided Policy Optimization.pdf,True,True,False,2020,icml,icml_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,,,,
102,Optimizing Data Usage via Differentiable Rewards.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
103,Low-Variance and Zero-Variance Baselines for Extensive-Form Games.pdf,False,False,False,2020,icml,icml_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
104,Does the Markov Decision Process Fit the Data Testing for the Markov Property in Sequential Decision.pdf,True,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,a3c,dqn,a2c,sac,ppo,,
105,Control Frequency Adaptation via Action Persistence in Batch Reinforcement Learning.pdf,True,False,False,2020,icml,icml_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,trpo,ppo,dqn,sac,,,
106,Learning Calibratable Policies using Programmatic Style-Consistency.pdf,True,False,False,2020,icml,icml_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,other,,,,,,
107,Hierarchically Decoupled Imitation For Morphological Transfer.pdf,True,False,False,2020,icml,icml_2020,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
108,Implicit Generative Modeling for Efficient Exploration.pdf,False,False,False,2020,icml,icml_2020,1-5,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
109,What Can Learned Intrinsic Rewards Capture.pdf,False,False,False,2020,icml,icml_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
110,Clinician-in-the-Loop Decision Making Reinforcement Learning with Near-Optimal Set-Valued Policies.pdf,False,False,False,2020,icml,icml_2020,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
111,Neural Network Control Policy Verification With Persistent Adversarial Perturbation.pdf,True,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
112,Logarithmic Regret for Adversarial Online Control.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
113,Finite-Time Last-Iterate Convergence for Multi-Agent Learning in Games.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
114,Generalization to New Actions in Reinforcement Learning.pdf,True,True,False,2020,icml,icml_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
115,Improved Optimistic Algorithms for Logistic Bandits.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
116,Domain Adaptive Imitation Learning.pdf,False,False,False,2020,icml,icml_2020,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
117,Variational Imitation Learning with Diverse-quality Demonstrations.pdf,True,False,False,2020,icml,icml_2020,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
118,A Game Theoretic Framework for Model Based Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
119,Sequence Generation with Mixed Representations.pdf,True,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
120,Understanding the Curse of Horizon in Off-Policy Evaluation via Conditional Importance Sampling.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
121,Growing Action Spaces.pdf,True,True,False,2020,icml,icml_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
122,Provably Efficient Model-based Policy Adaptation.pdf,False,True,False,2020,icml,icml_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
123,A Graph to Graphs Framework for Retrosynthesis Prediction.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
124,Asynchronous Coagent Networks.pdf,False,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
125,An Optimistic Perspective on Offline Reinforcement Learning.pdf,True,True,False,2020,icml,icml_2020,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
126,Stochastically Dominant Distributional Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,sac,,,,
127,On the Global Optimality of Model-Agnostic Meta-Learning.pdf,False,True,False,2020,icml,icml_2020,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
128,Accelerated Stochastic Gradient-free and Projection-free Methods.pdf,True,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
129,Learning Efficient Multi-agent Communication An Information Bottleneck Approach.pdf,True,False,False,2020,icml,icml_2020,1-5,action-value\s+function,,,,,,,ppo,ddpg,,,,,
130,Sub-Goal Trees a Framework for Goal-Based Reinforcement Learning.pdf,True,True,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,,,,,,
131,ConQUR Mitigating Delusional Bias in Deep Q-Learning.pdf,True,False,False,2020,icml,icml_2020,1-5,state-action\s+pairs,,,,,,,dqn,,,,,,
132,Breaking the Curse of Many Agents Provable Mean Embedding Q-Iteration for Mean-Field Reinforcement L.pdf,False,False,False,2020,icml,icml_2020,0,value\s+function\s+approximation,action-value\s+function,,,,,,ppo,,,,,,
133,Adaptive Estimator Selection for Off-Policy Evaluation.pdf,True,True,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
134,Adaptive Reward-Poisoning Attacks against Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,over 10,(?:discount|reward)\s+function,,,,,,,td3,dqn,ddpg,sac,,,
135,Reinforcement Learning in Feature Space Matrix Bandit Kernels and Regret Bound.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
136,Naive Exploration is Optimal for Online LQR.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
137,Learning Compound Tasks without Task-specific Knowledge via Imitation and Self-supervised Learning.pdf,False,False,False,2020,icml,icml_2020,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
138,Monte-Carlo Tree Search as Regularized Policy Optimization.pdf,False,False,False,2020,icml,icml_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,,,,,
139,Thompson Sampling via Local Uncertainty.pdf,True,False,False,2020,icml,icml_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
140,Context-aware Dynamics Model for Generalization in Model-Based Reinforcement Learning.pdf,True,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
141,Taylor Expansion Policy Optimization.pdf,False,False,False,2020,icml,icml_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
142,Online Learned Continual Compression with Adaptive Quantization Modules.pdf,False,False,False,2020,icml,icml_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
143,Working Memory Graphs.pdf,True,True,False,2020,icml,icml_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a3c,ppo,dqn,sac,,,
144,Hallucinative Topological Memory for Zero-Shot Visual Planning.pdf,False,True,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
145,Inferring DQN structure for high-dimensional continuous control.pdf,True,False,False,2020,icml,icml_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dqn,ddpg,,,,,
146,Sample Factory Egocentric 3D Control from Pixels at 100000 FPS with Asynchronous Reinforcement Learn.pdf,True,False,False,2020,icml,icml_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,a3c,ppo,sac,a2c,,,
147,Global Concavity and Optimization in a Class of Dynamic Discrete Choice Models.pdf,False,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
148,Dynamic Knapsack Optimization Towards Efficient Multi-Channel Sequential Advertising.pdf,False,False,False,2020,icml,icml_2020,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
149,Prediction-Guided Multi-Objective Reinforcement Learning for Continuous Robot Control.pdf,True,False,False,2020,icml,icml_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
150,Adaptive Droplet Routing in Digital Microfluidic Biochips Using Deep Reinforcement Learning.pdf,True,False,False,2020,icml,icml_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
151,A distributional view on multi-objective policy optimization.pdf,True,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
152,Bidirectional Model-based Policy Optimization.pdf,False,True,False,2020,icml,icml_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,pets,ppo,sac,,,,
153,Bandits with Adversarial Scaling.pdf,False,False,False,2020,icml,icml_2020,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
154,Data Valuation using Reinforcement Learning.pdf,True,False,False,2020,icml,icml_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,other,,,,,,
155,Reducing Sampling Error in Batch Temporal Difference Learning.pdf,False,True,False,2020,icml,icml_2020,over 10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
156,Learning to Navigate The Synthetically Accessible Chemical Space Using Reinforcement Learning.pdf,True,True,False,2020,icml,icml_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,a3c,dqn,ddpg,sac,td3,ppo,
157,Constrained Markov Decision Processes via Backward Value Functions.pdf,True,False,False,2020,icml,icml_2020,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,a2c,,,,,
158,Multi-Agent Routing Value Iteration Network.pdf,True,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
159,Kinematic State Abstraction and Provably Efficient Rich-Observation Reinforcement Learning.pdf,True,True,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
160,Can Increasing Input Dimensionality Improve Deep Reinforcement Learning.pdf,False,False,False,2020,icml,icml_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,ppo,sac,ddpg,,,
161,Structured Policy Iteration for Linear Quadratic Regulator.pdf,False,True,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
162,Responsive Safety in Reinforcement Learning by PID Lagrangian Methods.pdf,True,False,False,2020,icml,icml_2020,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
163,Provably Efficient Exploration in Policy Optimization.pdf,False,True,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,,,,,
164,Neural Contextual Bandits with UCB-based Exploration.pdf,False,True,False,2020,icml,icml_2020,6-10,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
165,Planning to Explore via Self-Supervised World Models.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,dreamer,,,,,,
166,A Markov Decision Process Model for Socio-Economic Systems Impacted by Climate Change.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,ppo,dqn,,,,,
167,Maximum Entropy Gain Exploration for Long Horizon Multi-goal Reinforcement Learning.pdf,True,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,ppo,,
168,Closed Loop Neural-Symbolic Learning via Integrating Neural Perception Grammar Parsing and Symbolic .pdf,False,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
169,Momentum-Based Policy Gradient Methods.pdf,True,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
170,Automated Synthetic-to-Real Generalization.pdf,True,False,False,2020,icml,icml_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,other,,,,,,
171,Agent57 Outperforming the Atari Human Benchmark.pdf,False,False,False,2020,icml,icml_2020,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
172,Batch Reinforcement Learning with Hyperparameter Gradients.pdf,False,True,False,2020,icml,icml_2020,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
173,Explicit Gradient Learning for Black-Box Optimization.pdf,True,True,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,ddpg,,,,,
174,Locally Differentially Private Combinatorial Semi-Bandits.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
175,Invariant Causal Prediction for Block MDPs.pdf,True,False,False,2020,icml,icml_2020,6-10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
176,Interpretable Off-Policy Evaluation in Reinforcement Learning by Highlighting Influential Transition.pdf,True,False,False,2020,icml,icml_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
177,Interference and Generalization in Temporal Difference Learning.pdf,False,True,False,2020,icml,icml_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
178,Ready Policy One World Building Through Active Learning.pdf,True,False,False,2020,icml,icml_2020,6-10,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
179,Fast Adaptation to New Environments via Policy-Dynamics Value Functions.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
180,Leveraging Procedural Generation to Benchmark Reinforcement Learning.pdf,True,True,False,2020,icml,icml_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
181,Cautious Adaptation For Reinforcement Learning in Safety-Critical Settings.pdf,True,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,pets,,,,,,
182,Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
183,Population-Based Black-Box Optimization for Biological Sequence Design.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
184,Controlling Overestimation Bias with Truncated Mixture of Continuous Distributional Quantile Critics.pdf,True,True,False,2020,icml,icml_2020,over 10,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
185,Fast computation of Nash Equilibria in Imperfect Information Games.pdf,False,False,False,2020,icml,icml_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
186,Learning Fair Policies in Multi-Objective Deep Reinforcement Learning with Average and Discounted Re.pdf,False,False,False,2020,icml,icml_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,sac,,,
187,On the Global Convergence Rates of Softmax Policy Gradient Methods.pdf,False,False,False,2020,icml,icml_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,,,,,
188,Flexible and Efficient Long-Range Planning Through Curious Exploration.pdf,False,False,False,2020,icml,icml_2020,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,,,,,,
0,Finding the Stochastic Shortest Path with Low Regret the Adversarial Cost and Unknown Transition Cas.pdf,False,False,False,2021,icml,icml_2021,0,state-action\s+pairs,,,,,,,ppo,,,,,,
1,Joining datasets via data augmentation in the label space for neural networks.pdf,False,True,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
2,Model-Based Reinforcement Learning via Latent-Space Collocation.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
3,Scaling Multi-Agent Reinforcement Learning with Selective Parameter Sharing.pdf,True,True,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,a2c,,,,,
4,Near Optimal Reward-Free Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
5,Adversarial Option-Aware Hierarchical Imitation Learning.pdf,False,False,False,2021,icml,icml_2021,0,state-action\s+pairs,,,,,,,ppo,,,,,,
6,Imitation by Predicting Observations.pdf,True,True,False,2021,icml,icml_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
7,Temporal Predictive Coding For Model-Based Planning In Latent Space.pdf,False,False,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,sac,,,,,
8,Inverse Decision Modeling Learning Interpretable Representations of Behavior.pdf,False,False,False,2021,icml,icml_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
9,Neuro-algorithmic Policies Enable Fast Combinatorial Generalization.pdf,False,False,False,2021,icml,icml_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
10,Joint Online Learning and Decision-making via Dual Mirror Descent.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
11,Hyperparameter Selection for Imitation Learning.pdf,True,True,False,2021,icml,icml_2021,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
12,Demonstration-Conditioned Reinforcement Learning for Few-Shot Imitation.pdf,True,False,False,2021,icml,icml_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
13,Zeroth-Order Non-Convex Learning via Hierarchical Dual Averaging.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
14,Learning and Planning in Complex Action Spaces.pdf,True,True,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,sac,ddpg,,,
15,Combinatorial Blocking Bandits with Stochastic Delays.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
16,Model-Free Reinforcement Learning from Clipped Pseudo-Regret to Sample Complexity.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
17,Robust Policy Gradient against Strong Data Corruption.pdf,False,False,False,2021,icml,icml_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
18,APS Active Pretraining with Successor Features.pdf,True,False,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
19,Online Limited Memory Neural-Linear Bandits with Likelihood Matching.pdf,True,False,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
20,Online Learning for Load Balancing of Unknown Monotone Resource Allocation Games.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
21,Solving Challenging Dexterous Manipulation Tasks With Trajectory Optimisation and Reinforcement Lear.pdf,True,True,False,2021,icml,icml_2021,6-10,(?:discount|reward)\s+function,,,,,,,td3,dqn,ddpg,,,,
22,Deeply-Debiased Off-Policy Interval Estimation.pdf,True,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
23,Coach-Player Multi-agent Reinforcement Learning for Dynamic Team Composition.pdf,False,False,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,ppo,dqn,,,,,
24,Robust Asymmetric Learning in POMDPs.pdf,True,True,False,2021,icml,icml_2021,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
25,Modularity in Reinforcement Learning via Algorithmic Independence in Credit Assignment.pdf,False,False,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
26,Cross-domain Imitation from Observations.pdf,False,False,False,2021,icml,icml_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,sac,,,
27,A Language for Counterfactual Generative Models.pdf,True,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
28,Decoupling Representation Learning from Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
29,Exponential Lower Bounds for Batch Reinforcement Learning Batch RL can be Exponentially Harder than .pdf,False,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
30,Tightening the Dependence on Horizon in the Sample Complexity of Q-Learning.pdf,False,False,False,2021,icml,icml_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
31,PID Accelerated Value Iteration Algorithm.pdf,False,False,False,2021,icml,icml_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,,,,,ppo,dqn,sac,,,,
32,Dynamic Planning and Learning under Recovering Rewards.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
33,PC-MLP Model-based Reinforcement Learning with Policy Cover Guided Exploration.pdf,False,True,False,2021,icml,icml_2021,1-5,state-action\s+pairs,,,,,,,trpo,,,,,,
34,Zoo-Tuning Adaptive Transfer from A Zoo of Models.pdf,False,True,False,2021,icml,icml_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
35,Learning Fair Policies in Decentralized Cooperative Multi-Agent Reinforcement Learning.pdf,False,True,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
36,Improved Corruption Robust Algorithms for Episodic Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
37,Posterior Value Functions Hindsight Baselines for Policy Gradient Methods.pdf,False,False,False,2021,icml,icml_2021,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
38,Revisiting Pengs QÎ» for Modern Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
39,Policy Caches with Successor Features.pdf,False,False,False,2021,icml,icml_2021,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
40,Efficient Differentiable Simulation of Articulated Bodies.pdf,True,False,False,2021,icml,icml_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
41,Stochastic Iterative Graph Matching.pdf,True,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
42,Offline Meta-Reinforcement Learning with Advantage Weighting.pdf,True,False,False,2021,icml,icml_2021,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
43,PEBBLE Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervi.pdf,False,False,False,2021,icml,icml_2021,6-10,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,a2c,,,
44,Cooperative Exploration for Multi-Agent Deep Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
45,Marginalized Stochastic Natural Gradients for Black-Box Variational Inference.pdf,False,True,False,2021,icml,icml_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,ppo,sac,,,,
46,Approximation Theory Based Methods for RKHS Bandits.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
47,PODS Policy Optimization via Differentiable Simulation.pdf,False,True,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
48,The Power of Log-Sum-Exp Sequential Density Ratio Matrix Estimation for Speed-Accuracy Optimization.pdf,True,True,False,2021,icml,icml_2021,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
49,CRPO A New Approach for Safe Reinforcement Learning with Convergence Guarantee.pdf,False,True,False,2021,icml,icml_2021,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,sac,ddpg,,,
50,Beyond Variance Reduction Understanding the True Impact of Baselines on Policy Optimization.pdf,True,False,False,2021,icml,icml_2021,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
51,Sparsity-Agnostic Lasso Bandit.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
52,Detecting Rewards Deterioration in Episodic Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
53,Confidence-Budget Matching for Sequential Budgeted Learning.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
54,Multi-layered Network Exploration via Random Walks From Offline Optimization to Online Learning.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
55,A New Formalism Method and Open Issues for Zero-Shot Coordination.pdf,True,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
56,Learning While Playing in Mean-Field Games Convergence and Optimality.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
57,Towards Distraction-Robust Active Visual Tracking.pdf,False,False,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
58,TeachMyAgent a Benchmark for Automatic Curriculum Learning in Deep RL.pdf,True,False,False,2021,icml,icml_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
59,Bilinear Classes A Structural Framework for Provable Generalization in RL.pdf,False,False,False,2021,icml,icml_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
60,High-dimensional Experimental Design and Kernel Bandits.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
61,Estimating Î±-Rank from A Few Entries with Low Rank Matrix Completion.pdf,True,False,False,2021,icml,icml_2021,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,,,,,,,ppo,,,,,,
62,Modelling Behavioural Diversity for Learning in Open-Ended Games.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
63,Risk Bounds and Rademacher Complexity in Batch Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
64,Goal-Conditioned Reinforcement Learning with Imagined Subgoals.pdf,True,False,False,2021,icml,icml_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
65,Value Alignment Verification.pdf,True,False,False,2021,icml,icml_2021,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,sac,,,,,,
66,Bootstrapping Fitted Q-Evaluation for Off-Policy Inference.pdf,False,False,False,2021,icml,icml_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
67,Inverse Constrained Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
68,Learning in Nonzero-Sum Stochastic Games with Potentials.pdf,False,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,dqn,ddpg,,,,,
69,Offline Contextual Bandits with Overparameterized Models.pdf,True,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
70,Global Convergence of Policy Gradient for Linear-Quadratic Mean-Field ControlGame in Continuous Time.pdf,False,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
71,Off-Belief Learning.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,ppo,dqn,,,,,
72,Trajectory Diversity for Zero-Shot Coordination.pdf,True,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
73,Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
74,LTL2Action Generalizing LTL Instructions for Multi-Task RL.pdf,True,True,False,2021,icml,icml_2021,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
75,A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
76,On Proximal Policy Optimizations Heavy-tailed Gradients.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,a2c,,,,
77,Dynamic Balancing for Model Selection in Bandits and RL.pdf,False,True,False,2021,icml,icml_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,,,,,,
78,Provably Correct Optimization and Exploration with Non-linear Policies.pdf,True,False,False,2021,icml,icml_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,sac,,,,
79,Top-k eXtreme Contextual Bandits with Arm Hierarchy.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
80,Regularized Online Allocation Problems Fairness and Beyond.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
81,Provably Efficient Learning of Transferable Rewards.pdf,False,False,False,2021,icml,icml_2021,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
82,GMAC A Distributional Perspective on Actor-Critic Framework.pdf,False,True,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,sac,,,
83,Provably Efficient Reinforcement Learning for Discounted MDPs with Feature Mapping.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
84,Fast active learning for pure exploration in reinforcement learning.pdf,True,False,False,2021,icml,icml_2021,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
85,State Relevance for Off-Policy Evaluation.pdf,True,False,False,2021,icml,icml_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
86,LIME Learning Inductive Bias for Primitives of Mathematical Reasoning.pdf,True,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
87,Diversity Actor-Critic Sample-Aware Entropy Regularization for Sample-Efficient Exploration.pdf,True,False,False,2021,icml,icml_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
88,Towards Better Laplacian Representation in Reinforcement Learning with Generalized Graph Drawing.pdf,True,False,False,2021,icml,icml_2021,1-5,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,other,,,,,,
89,MetaCURE Meta Reinforcement Learning with Empowerment-Driven Exploration.pdf,True,False,False,2021,icml,icml_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
90,A Lower Bound for the Sample Complexity of Inverse Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
91,Reinforcement Learning with Prototypical Representations.pdf,True,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
92,SUNRISE A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,pets,dqn,sac,td3,dreamer,
93,Safe Reinforcement Learning with Linear Function Approximation.pdf,False,False,False,2021,icml,icml_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,other,,,,,,
94,Ensemble Bootstrapping for Q-Learning.pdf,True,False,False,2021,icml,icml_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,sac,,,,,
95,Learning Routines for Effective Off-Policy Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,dqn,ddpg,sac,,,
96,Towards Tight Bounds on the Sample Complexity of Average-reward MDPs.pdf,False,False,False,2021,icml,icml_2021,0,state-action\s+pairs,,,,,,,ppo,dqn,,,,,
97,A New Representation of Successor Features for Transfer across Dissimilar Environments.pdf,False,False,False,2021,icml,icml_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,,,,,,
98,Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting Pot.pdf,False,False,False,2021,icml,icml_2021,over 10,(?:discount|reward)\s+function,,,,,,,a3c,ppo,dqn,,,,
99,Convex Regularization in Monte-Carlo Tree Search.pdf,True,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
100,Leveraging Non-uniformity in First-order Non-convex Optimization.pdf,False,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
101,GraphDF A Discrete Flow Model for Molecular Graph Generation.pdf,False,False,False,2021,icml,icml_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
102,Skill Discovery for Exploration and Planning using Deep Skill Graphs.pdf,False,False,False,2021,icml,icml_2021,over 10,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
103,The Emergence of Individuality.pdf,False,False,False,2021,icml,icml_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,sac,,,,,,
104,Logarithmic Regret for Reinforcement Learning with Linear Function Approximation.pdf,False,False,False,2021,icml,icml_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
105,Reinforcement Learning for Cost-Aware Markov Decision Processes.pdf,False,False,False,2021,icml,icml_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
106,Continuous-time Model-based Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,pets,,,,,,
107,Generalizable Episodic Memory for Deep Reinforcement Learning.pdf,True,True,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,td3,ppo,dqn,,,,
108,Offline Reinforcement Learning with Fisher Divergence Critic Regularization.pdf,True,False,False,2021,icml,icml_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
109,Multi-Task Reinforcement Learning with Context-based Representations.pdf,True,False,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
110,REPAINT Knowledge Transfer in Deep Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
111,Taylor Expansion of Discount Factors.pdf,True,False,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
112,Optimal regret algorithm for Pseudo-1d Bandit Convex Optimization.pdf,False,True,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
113,PsiPhi-Learning Reinforcement Learning with Demonstrations using Successor Features and Inverse Temp.pdf,True,False,False,2021,icml,icml_2021,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
114,Spectral Normalisation for Deep Reinforcement Learning An Optimisation Perspective.pdf,True,True,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
115,OptiDICE Offline Policy Optimization via Stationary Distribution Correction Estimation.pdf,False,False,False,2021,icml,icml_2021,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
116,Learning to Weight Imperfect Demonstrations.pdf,True,False,False,2021,icml,icml_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
117,Randomized Entity-wise Factorization for Multi-Agent Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
118,Model-based Reinforcement Learning for Continuous Control with Posterior Sampling.pdf,False,False,False,2021,icml,icml_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,pets,dqn,sac,,,,
119,Phasic Policy Gradient.pdf,True,True,False,2021,icml,icml_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,sac,,,,
120,Adversarial Policy Learning in Two-player Competitive Games.pdf,True,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
121,Near-Optimal Model-Free Reinforcement Learning in Non-Stationary Episodic MDPs.pdf,False,False,False,2021,icml,icml_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
122,Bias-Robust Bayesian Optimization via Dueling Bandits.pdf,False,True,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
123,SAINT-ACC Safety-Aware Intelligent Adaptive Cruise Control for Autonomous Vehicles Using Deep Reinfo.pdf,False,False,False,2021,icml,icml_2021,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
124,Causal Curiosity RL Agents Discovering Self-supervised Experiments for Causal Representation Learnin.pdf,True,False,False,2021,icml,icml_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
125,Deep Reinforcement Learning amidst Continual Structured Non-Stationarity.pdf,False,True,False,2021,icml,icml_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
126,Provably Efficient Fictitious Play Policy Optimization for Zero-Sum Markov Games with Structured Tra.pdf,False,False,False,2021,icml,icml_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
127,Reward Identification in Inverse Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
128,Policy Gradient Bayesian Robust Optimization for Imitation Learning.pdf,True,False,False,2021,icml,icml_2021,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
129,Locally Persistent Exploration in Continuous Control Tasks with Sparse Rewards.pdf,False,True,False,2021,icml,icml_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,ddpg,sac,,,,
130,AdaXpert Adapting Neural Architecture for Growing Data.pdf,True,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
131,Structured World Belief for Reinforcement Learning in POMDP.pdf,True,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
132,Is Pessimism Provably Efficient for Offline RL.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,,,,,,
133,Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks.pdf,True,False,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
134,Unsupervised Skill Discovery with Bottleneck Option Learning.pdf,True,False,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,sac,,,,,,
135,Exploration in Approximate Hyper-State Space for Meta Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
136,Self-Improved Retrosynthetic Planning.pdf,True,False,False,2021,icml,icml_2021,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
137,Parallel Droplet Control in MEDA Biochips using Multi-Agent Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
138,DFAC Framework Factorizing the Value Function via Quantile Mixture for Multi-Agent Distributional Q-.pdf,True,False,False,2021,icml,icml_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
139,Combining Pessimism with Optimism for Robust and Efficient Model-Based Deep Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,pets,dqn,sac,ppo,,
140,Muesli Combining Improvements in Policy Optimization.pdf,True,False,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,dqn,sac,ppo,dreamer,,
141,Actionable Models Unsupervised Offline Reinforcement Learning of Robotic Skills.pdf,False,False,False,2021,icml,icml_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
142,Near-Optimal Representation Learning for Linear Bandits and Linear RL.pdf,False,False,False,2021,icml,icml_2021,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
143,Variational Empowerment as Representation Learning for Goal-Conditioned Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,other,,,,,,
144,Model-Free and Model-Based Policy Evaluation when Causality is Uncertain.pdf,False,False,False,2021,icml,icml_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
145,Emergent Social Learning via Multi-agent Reinforcement Learning.pdf,True,True,False,2021,icml,icml_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
146,Emphatic Algorithms for Deep Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
147,Megaverse Simulating Embodied Agents at One Million Experiences per Second.pdf,True,True,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
148,Instabilities of Offline RL with Pre-Trained Neural Representation.pdf,False,True,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,td3,ppo,dqn,ddpg,,,
149,RRL Resnet as representation for Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
150,Principled Exploration via Optimistic Bootstrapping and Backward Induction.pdf,True,False,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,,,,,,
151,On Reward-Free RL with Kernel and Neural Function Approximations Single-Agent MDP and Markov Game.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
152,Offline Reinforcement Learning with Pseudometric Learning.pdf,True,False,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,dqn,ddpg,sac,td3,ppo,,
153,Online Policy Gradient for Model Free Learning of Linear Quadratic Regulators with sqrtT Regret.pdf,False,True,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
154,Interactive Learning from Activity Description.pdf,True,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
155,Decoupling Value and Policy for Generalization in Reinforcement Learning.pdf,True,True,False,2021,icml,icml_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,a2c,,,,,
156,Task-Optimal Exploration in Linear Dynamical Systems.pdf,False,False,False,2021,icml,icml_2021,over 10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
157,High Confidence Generalization for Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,over 10,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
158,Neural Architecture Search without Training.pdf,True,True,False,2021,icml,icml_2021,over 10,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,,,,,,,other,,,,,,
159,Guided Exploration with Proximal Policy Optimization using a Single Demonstration.pdf,True,False,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,a2c,,,,
160,On Reinforcement Learning with Adversarial Corruption and Its Application to Block MDP.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
161,On-Policy Deep Reinforcement Learning for the Average-Reward Criterion.pdf,False,False,False,2021,icml,icml_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
162,Preferential Temporal Difference Learning.pdf,False,True,False,2021,icml,icml_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
163,Of Moments and Matching A Game-Theoretic Framework for Closing the Imitation Gap.pdf,True,False,False,2021,icml,icml_2021,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
164,MURAL Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
165,Discovering symbolic policies with deep reinforcement learning.pdf,True,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
166,Sample Efficient Reinforcement Learning In Continuous State Spaces A Perspective Beyond Linearity.pdf,False,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
167,Self-Paced Context Evaluation for Contextual Reinforcement Learning.pdf,True,True,False,2021,icml,icml_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
168,Adversarial Robustness Guarantees for Random Deep Neural Networks.pdf,True,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
169,Continuous Coordination As a Realistic Scenario for Lifelong Learning.pdf,True,False,False,2021,icml,icml_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
170,Decentralized Single-Timescale Actor-Critic on Zero-Sum Two-Player Stochastic Games.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
171,Tesseract Tensorised Actors for Multi-Agent Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,dqn,sac,,,,,
172,Randomized Exploration in Reinforcement Learning with General Value Function Approximation.pdf,True,False,False,2021,icml,icml_2021,1-5,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
173,EMaQ Expected-Max Q-Learning Operator for Simple Yet Effective Offline and Online RL.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
174,Finite-Sample Analysis of Off-Policy Natural Actor-Critic Algorithm.pdf,False,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
175,A Deep Reinforcement Learning Approach to Marginalized Importance Sampling with the Successor Repres.pdf,True,False,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,dqn,,,,,
176,Online Learning in Unknown Markov Games.pdf,False,False,False,2021,icml,icml_2021,0,state-action\s+pairs,,,,,,,ppo,dqn,,,,,
177,Risk-Sensitive Reinforcement Learning with Function Approximation A Debiasing Approach.pdf,False,False,False,2021,icml,icml_2021,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
178,TempoRL Learning When to Act.pdf,True,False,False,2021,icml,icml_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,ddpg,,,,,
179,Keyframe-Focused Visual Imitation Learning.pdf,False,True,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,ppo,,,,,
180,Large-Scale Multi-Agent Deep FBSDEs.pdf,False,False,False,2021,icml,icml_2021,over 10,action-value\s+function,,,,,,,ppo,,,,,,
181,Targeted Data Acquisition for Evolving Negotiation Agents.pdf,False,False,False,2021,icml,icml_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
182,Unsupervised Learning of Visual 3D Keypoints for Control.pdf,False,False,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
183,Adversarial Combinatorial Bandits with General Non-linear Reward Functions.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
184,ARMS Antithetic-REINFORCE-Multi-Sample Gradient for Binary Variables.pdf,True,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
185,Accelerating Safe Reinforcement Learning with Constraint-mismatched Baseline Policies.pdf,True,False,False,2021,icml,icml_2021,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
186,Grounding Language to Entities and Dynamics for Generalization in Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,1-5,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,action-value\s+function,(?:discount|reward)\s+function,,,,,other,,,,,,
187,Robust Reinforcement Learning using Least Squares Policy Iteration with Provable Performance Guarant.pdf,True,False,False,2021,icml,icml_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,,,,
188,Decision-Making Under Selective Labels Optimal Finite-Domain Policies and Beyond.pdf,True,True,False,2021,icml,icml_2021,0,value\s+function\s+approximation,,,,,,,ppo,,,,,,
189,Deep Coherent Exploration for Continuous Control.pdf,True,False,False,2021,icml,icml_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,sac,a2c,,,
190,UCB Momentum Q-learning Correcting the bias without forgetting.pdf,True,False,False,2021,icml,icml_2021,6-10,state-action\s+pairs,,,,,,,dqn,,,,,,
191,Learning and Planning in Average-Reward Markov Decision Processes.pdf,False,False,False,2021,icml,icml_2021,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,sac,,,,
192,Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environmen.pdf,False,False,False,2021,icml,icml_2021,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
193,State Entropy Maximization with Random Encoders for Efficient Exploration.pdf,True,True,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dreamer,a2c,,,,
194,Monotonic Robust Policy Optimization with Model Discrepancy.pdf,False,False,False,2021,icml,icml_2021,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
195,Doubly Robust Off-Policy Actor-Critic Convergence and Optimality.pdf,False,False,False,2021,icml,icml_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
196,Explore Visual Concept Formation for Image Classification.pdf,True,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
197,The Logical Options Framework.pdf,True,False,False,2021,icml,icml_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
198,Modeling Hierarchical Structures with Continuous Recursive Neural Networks.pdf,True,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
199,GLSearch Maximum Common Subgraph Detection via Learning to Search.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
200,Recomposing the Reinforcement Learning Building Blocks with Hypernetworks.pdf,True,False,False,2021,icml,icml_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,dqn,sac,,,,
201,Expressive 1-Lipschitz Neural Networks for Robust Multiple Graph Learning against Adversarial Attack.pdf,False,False,False,2021,icml,icml_2021,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
202,AGENT A Benchmark for Core Psychological Reasoning.pdf,False,False,False,2021,icml,icml_2021,over 10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
203,Efficient Performance Bounds for Primal-Dual Reinforcement Learning from Demonstrations.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,,,,trpo,ppo,dqn,sac,,,
204,Collaborative Bayesian Optimization with Fair Regret.pdf,False,True,False,2021,icml,icml_2021,6-10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
205,Counterfactual Credit Assignment in Model-Free Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
206,Revisiting Rainbow Promoting more insightful and inclusive deep reinforcement learning research.pdf,True,True,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
207,UneVEn Universal Value Exploration for Multi-Agent Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
208,FOP Factorizing Optimal Joint Policy of Maximum-Entropy Multi-Agent Reinforcement Learning.pdf,False,False,False,2021,icml,icml_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,,,,
209,A Regret Minimization Approach to Iterative Learning Control.pdf,True,True,False,2021,icml,icml_2021,0,state-action\s+pairs,,,,,,,ppo,sac,,,,,
210,Average-Reward Off-Policy Policy Evaluation with Function Approximation.pdf,True,True,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,sac,,,,,,
211,Kernel-Based Reinforcement Learning A Finite-Time Analysis.pdf,True,False,False,2021,icml,icml_2021,6-10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
212,First-Order Methods for Wasserstein Distributionally Robust MDP.pdf,True,False,False,2021,icml,icml_2021,0,value\s+function\s+approximation,,,,,,,ppo,,,,,,
213,Safe Reinforcement Learning Using Advantage-Based Intervention.pdf,True,False,False,2021,icml,icml_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
214,World Model as a Graph Learning Latent Landmarks for Planning.pdf,True,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,,,,
215,Breaking the Deadly Triad with a Target Network.pdf,True,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
216,DouZero Mastering DouDizhu with Self-Play Deep Reinforcement Learning.pdf,True,True,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,,,,,
217,Decoupling Exploration and Exploitation for Meta-Reinforcement Learning without Sacrifices.pdf,True,False,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
218,Density Constrained Reinforcement Learning.pdf,True,False,False,2021,icml,icml_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
219,SECANT Self-Expert Cloning for Zero-Shot Generalization of Visual Policies.pdf,True,True,False,2021,icml,icml_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
220,Policy Information Capacity Information-Theoretic Measure for Task Complexity in Deep Reinforcement .pdf,True,True,False,2021,icml,icml_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,,,,,,
221,Towards Open Ad Hoc Teamwork Using Graph-based Policy Learning.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,a3c,ppo,dqn,,,,
222,A Sharp Analysis of Model-based Reinforcement Learning with Self-Play.pdf,False,False,False,2021,icml,icml_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
223,Reinforcement Learning Under Moral Uncertainty.pdf,True,False,False,2021,icml,icml_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,sac,,,,,,
224,Adapting to misspecification in contextual bandits with offline regression oracles.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
225,Batch Value-function Approximation with Only Realizability.pdf,False,False,False,2021,icml,icml_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
226,Reinforcement Learning of Implicit and Explicit Control Flow Instructions.pdf,False,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
227,Characterizing the Gap Between Actor-Critic and Policy Gradient.pdf,False,False,False,2021,icml,icml_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,trpo,dqn,a2c,sac,ppo,,
228,Online Submodular Resource Allocation with Applications to Rebalancing Shared Mobility Systems.pdf,False,False,False,2021,icml,icml_2021,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
229,Improved Regret Bound and Experience Replay in Regularized Policy Iteration.pdf,False,False,False,2021,icml,icml_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
230,Path Planning using Neural A Search.pdf,True,False,False,2021,icml,icml_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
231,Sparse Feature Selection Makes Batch Reinforcement Learning More Sample Efficient.pdf,False,False,False,2021,icml,icml_2021,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
0,Showing Your Offline Reinforcement Learning Work Online Evaluation Budget Matters.pdf,False,True,False,2022,icml,icml_2022,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,,,,,
1,Lyapunov Density Models Constraining Distribution Shift in Learning-Based Control.pdf,True,False,False,2022,icml,icml_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
2,Prompting Decision Transformer for Few-Shot Policy Generalization.pdf,False,False,False,2022,icml,icml_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
3,Improving Policy Optimization with Generalist-Specialist Learning.pdf,False,True,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
4,Optimizing Sequential Experimental Design with Deep Reinforcement Learning.pdf,True,True,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
5,Parametric Visual Program Induction with Function Modularization.pdf,False,False,False,2022,icml,icml_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
6,Online Learning with Knapsacks the Best of Both Worlds.pdf,False,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
7,Distributionally Robust Q-Learning.pdf,False,False,False,2022,icml,icml_2022,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
8,Learning Markov Games with Adversarial Opponents Efficient Algorithms and Fundamental Limits.pdf,False,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
9,The Power of Exploiter Provable Multi-Agent RL in Large State Spaces.pdf,False,False,False,2022,icml,icml_2022,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
10,Breaking the sqrtT Barrier Instance-Independent Logarithmic Regret in Stochastic Contextual Linear B.pdf,False,False,False,2022,icml,icml_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
11,Learning Mixtures of Linear Dynamical Systems.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,sac,,,,
12,Model Selection in Batch Policy Optimization.pdf,False,True,False,2022,icml,icml_2022,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
13,Augment with Care Contrastive Learning for Combinatorial Problems.pdf,True,False,False,2022,icml,icml_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,,,,,,
14,Federated Reinforcement Learning Linear Speedup Under Markovian Sampling.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,a3c,dqn,a2c,sac,ppo,,
15,From Dirichlet to Rubin Optimistic Exploration in RL without Bonuses.pdf,False,False,False,2022,icml,icml_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,,,,,ppo,dqn,sac,,,,
16,On Last-Iterate Convergence Beyond Zero-Sum Games.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
17,Adapting to Mixing Time in Stochastic Optimization with Markovian Data.pdf,False,False,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
18,Near-Optimal Algorithms for Autonomous Exploration and Multi-Goal Stochastic Shortest Path.pdf,False,False,False,2022,icml,icml_2022,0,state-action\s+pairs,,,,,,,ppo,dqn,sac,,,,
19,Cascaded Gaps Towards Logarithmic Regret for Risk-Sensitive Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
20,Bisimulation Makes Analogies in Goal-Conditioned Reinforcement Learning.pdf,False,True,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
21,OFA Unifying Architectures Tasks and Modalities Through a Simple Sequence-to-Sequence Learning Frame.pdf,True,True,False,2022,icml,icml_2022,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
22,EAT-C Environment-Adversarial sub-Task Curriculum for Efficient Reinforcement Learning.pdf,True,True,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,sac,,,,,,
23,Offline Meta-Reinforcement Learning with Online Self-Supervision.pdf,True,True,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
24,Retrieval-Augmented Reinforcement Learning.pdf,True,False,False,2022,icml,icml_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,pets,dqn,,,,,
25,Influence-Augmented Local Simulators a Scalable Solution for Fast Deep RL in Large Networked Systems.pdf,False,False,False,2022,icml,icml_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
26,A Natural Actor-Critic Framework for Zero-Sum Markov Games.pdf,False,True,False,2022,icml,icml_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,,,,,,
27,Individual Reward Assisted Multi-Agent Reinforcement Learning.pdf,True,False,False,2022,icml,icml_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
28,Self-Organized Polynomial-Time Coordination Graphs.pdf,True,False,False,2022,icml,icml_2022,over 10,action-value\s+function,,,,,,,ppo,dqn,sac,,,,
29,Reward-Free RL is No Harder Than Reward-Aware RL in Linear Markov Decision Processes.pdf,False,False,False,2022,icml,icml_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
30,Biological Sequence Design with GFlowNets.pdf,True,True,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
31,A State-Distribution Matching Approach to Non-Episodic Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
32,Addressing Optimism Bias in Sequence Modeling for Reinforcement Learning.pdf,True,False,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
33,Nearly Minimax Optimal Reinforcement Learning with Linear Function Approximation.pdf,False,False,False,2022,icml,icml_2022,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
34,Topology-Aware Network Pruning using Multi-stage Graph Embedding and Reinforcement Learning.pdf,True,True,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,ddpg,,,,
35,Efficient Distributionally Robust Bayesian Optimization with Worst-case Sensitivity.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
36,Plan Your Target and Learn Your Skills Transferable State-Only Imitation Learning via Decoupled Poli.pdf,True,False,False,2022,icml,icml_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
37,Training Characteristic Functions with Reinforcement Learning XAI-methods play Connect Four.pdf,True,False,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
38,Deep Hierarchy in Bandits.pdf,False,False,False,2022,icml,icml_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
39,Phasic Self-Imitative Reduction for Sparse-Reward Goal-Conditioned Reinforcement Learning.pdf,False,True,False,2022,icml,icml_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
40,Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent RL.pdf,False,False,False,2022,icml,icml_2022,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,trpo,dqn,ddpg,sac,a2c,ppo,
41,Choosing Answers in Epsilon-Best-Answer Identification for Linear Bandits.pdf,False,False,False,2022,icml,icml_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
42,The Importance of Non-Markovianity in Maximum State Entropy Exploration.pdf,False,False,False,2022,icml,icml_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
43,A Reduction from Linear Contextual Bandits Lower Bounds to Estimations Lower Bounds.pdf,False,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
44,Learning Pseudometric-based Action Representations for Offline Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
45,On the Hidden Biases of Policy Mirror Ascent in Continuous Action Spaces.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
46,Disentangling Sources of Risk for Distributional Multi-Agent Reinforcement Learning.pdf,True,False,False,2022,icml,icml_2022,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
47,Supervised Off-Policy Ranking.pdf,True,False,False,2022,icml,icml_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
48,Rotting Infinitely Many-Armed Bandits.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
49,Human-in-the-loop Provably Efficient Preference-based Reinforcement Learning with General Function A.pdf,False,True,False,2022,icml,icml_2022,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
50,Why Should I Trust You Bellman The Bellman Error is a Poor Replacement for Value Error.pdf,True,False,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,dqn,sac,td3,ppo,,
51,Cliff Diving Exploring Reward Surfaces in Reinforcement Learning Environments.pdf,True,False,False,2022,icml,icml_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,a2c,,,,
52,Mirror Learning A Unifying Framework of Policy Optimisation.pdf,True,True,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,a3c,ppo,dqn,,,
53,A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines.pdf,True,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
54,Decentralized Online Convex Optimization in Networked Systems.pdf,False,False,False,2022,icml,icml_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
55,A Self-Play Posterior Sampling Algorithm for Zero-Sum Markov Games.pdf,False,False,False,2022,icml,icml_2022,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,,,,,ppo,dqn,,,,,
56,On the Impossibility of Learning to Cooperate with Adaptive Partner Strategies in Repeated Games.pdf,False,False,False,2022,icml,icml_2022,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
57,Learning-based Optimisation of Particle Accelerators Under Partial Observability Without Real-World .pdf,True,True,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
58,Estimating and Penalizing Induced Preference Shifts in Recommender Systems.pdf,False,False,False,2022,icml,icml_2022,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,pets,ppo,,,,,
59,Making Linear MDPs Practical via Contrastive Representation Learning.pdf,False,False,False,2022,icml,icml_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
60,Delayed Reinforcement Learning by Imitation.pdf,False,False,False,2022,icml,icml_2022,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
61,REvolveR Continuous Evolutionary Models for Robot-to-robot Policy Transfer.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
62,Koopman Q-learning Offline Reinforcement Learning via Symmetries of Dynamics.pdf,False,False,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
63,On Improving Model-Free Algorithms for Decentralized Multi-Agent Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
64,Reinforcement Learning from Partial Observation Linear Function Approximation with Provable Sample E.pdf,False,False,False,2022,icml,icml_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,,,,,,
65,Nearly Optimal Policy Optimization with Stable at Any Time Guarantee.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
66,Modeling Strong and Human-Like Gameplay with KL-Regularized Search.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
67,Saute RL Almost Surely Safe Reinforcement Learning Using State Augmentation.pdf,True,True,False,2022,icml,icml_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,trpo,ppo,sac,pets,,,
68,Contextual Bandits with Large Action Spaces Made Practical.pdf,True,True,False,2022,icml,icml_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
69,A Simple Reward-free Approach to Constrained Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
70,Biased Gradient Estimate with Drastic Variance Reduction for Meta Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,,,,,
71,CtrlFormer Learning Transferable State Representation for Visual Control via Transformer.pdf,False,False,False,2022,icml,icml_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,ppo,dqn,sac,,,
72,Sample and Communication-Efficient Decentralized Actor-Critic Algorithms with Finite-Time Analysis.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
73,Thresholded Lasso Bandit.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
74,DRIBO Robust Deep Reinforcement Learning via Multi-View Information Bottleneck.pdf,False,False,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dreamer,ppo,dqn,sac,,,
75,Analysis of Stochastic Processes through Replay Buffers.pdf,False,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
76,Revisiting Some Common Practices in Cooperative Multi-Agent Reinforcement Learning.pdf,False,True,False,2022,icml,icml_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
77,Reducing Variance in Temporal-Difference Value Estimation via Ensemble of Deep Networks.pdf,True,False,False,2022,icml,icml_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
78,Recurrent Model-Free RL Can Be a Strong Baseline for Many POMDPs.pdf,True,True,False,2022,icml,icml_2022,over 10,(?:discount|reward)\s+function,,,,,,,td3,ppo,sac,a2c,,,
79,Guarantees for Epsilon-Greedy Reinforcement Learning with Function Approximation.pdf,False,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
80,Planning with Diffusion for Flexible Behavior Synthesis.pdf,True,False,False,2022,icml,icml_2022,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,pets,dreamer,ppo,dqn,,,
81,The Geometry of Robust Value Functions.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
82,Regularizing a Model-based Policy Stationary Distribution to Stabilize Offline Reinforcement Learnin.pdf,False,True,False,2022,icml,icml_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,sac,,,,
83,How to Stay Curious while avoiding Noisy TVs using Aleatoric Uncertainty Estimation.pdf,True,True,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
84,On Well-posedness and Minimax Optimal Rates of Nonparametric Q-function Estimation in Off-policy Eva.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
85,The Primacy Bias in Deep Reinforcement Learning.pdf,True,True,False,2022,icml,icml_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
86,Robust Policy Learning over Multiple Uncertainty Sets.pdf,False,False,False,2022,icml,icml_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
87,Shuffle Private Linear Contextual Bandits.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
88,RieszNet and ForestRiesz Automatic Debiased Machine Learning with Neural Nets and Random Forests.pdf,True,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
89,Improved Regret for Differentially Private Exploration in Linear MDP.pdf,False,False,False,2022,icml,icml_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
90,Bayesian Optimization under Stochastic Delayed Feedback.pdf,True,True,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
91,Controlling Conditional Language Models without Catastrophic Forgetting.pdf,True,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
92,Leveraging Approximate Symbolic Models for Reinforcement Learning via Skill Diversity.pdf,True,False,False,2022,icml,icml_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
93,AnyMorph Learning Transferable Polices By Inferring Agent Morphology.pdf,False,True,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,,,,,
94,Cooperative Online Learning in Stochastic and Adversarial MDPs.pdf,False,False,False,2022,icml,icml_2022,0,state-action\s+pairs,,,,,,,dqn,sac,,,,,
95,Scalable Deep Reinforcement Learning Algorithms for Mean Field Games.pdf,True,False,False,2022,icml,icml_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
96,Off-Policy Reinforcement Learning with Delayed Rewards.pdf,False,False,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
97,Robust Imitation Learning against Variations in Environment Dynamics.pdf,True,False,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,sac,a2c,,,
98,Sample-Efficient Reinforcement Learning with loglogT Switching Cost.pdf,False,False,False,2022,icml,icml_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
99,Blocks Assemble Learning to Assemble with Large-Scale Structured Reinforcement Learning.pdf,True,False,False,2022,icml,icml_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
100,Learning Iterative Reasoning through Energy Minimization.pdf,False,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
101,Langevin Monte Carlo for Contextual Bandits.pdf,True,True,False,2022,icml,icml_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
102,Pessimism meets VCG Learning Dynamic Mechanism Design via Offline Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
103,Learning from a Learning User for Optimal Recommendations.pdf,False,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
104,Greedy based Value Representation for Optimal Coordination in Multi-agent Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
105,Regret Bounds for Stochastic Shortest Path Problems with Linear Function Approximation.pdf,False,False,False,2022,icml,icml_2022,0,action-value\s+function,state-action\s+pairs,,,,,,ppo,,,,,,
106,A Single-Loop Gradient Descent and Perturbed Ascent Algorithm for Nonconvex Functional Constrained O.pdf,False,False,False,2022,icml,icml_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
107,Evolving Curricula with Regret-Based Environment Design.pdf,True,True,False,2022,icml,icml_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
108,Utility Theory for Sequential Decision Making.pdf,False,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
109,Difference Advantage Estimation for Multi-Agent Policy Gradients.pdf,False,False,False,2022,icml,icml_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,sac,,,
110,Reachability Constrained Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,sac,,,,,,
111,Asking for Knowledge AFK Training RL Agents to Query External Knowledge Using Language.pdf,False,False,False,2022,icml,icml_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
112,Temporal Difference Learning for Model Predictive Control.pdf,True,True,False,2022,icml,icml_2022,6-10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td-mpc,ppo,dreamer,
113,Goal Misgeneralization in Deep Reinforcement Learning.pdf,True,False,False,2022,icml,icml_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
114,Stabilizing Off-Policy Deep Reinforcement Learning from Pixels.pdf,True,False,False,2022,icml,icml_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,ppo,sac,,,,,
115,Policy Gradient Method For Robust Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,,,,,trpo,ppo,sac,,,,
116,The Neural Race Reduction Dynamics of Abstraction in Gated Networks.pdf,True,False,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
117,Efficient Model-based Multi-agent Reinforcement Learning via Optimistic Equilibrium Computation.pdf,False,False,False,2022,icml,icml_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
118,Model-Value Inconsistency as a Signal for Epistemic Uncertainty.pdf,False,True,False,2022,icml,icml_2022,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,dreamer,dqn,sac,,,,
119,Learning Stochastic Shortest Path with Linear Function Approximation.pdf,False,False,False,2022,icml,icml_2022,over 10,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
120,PAGE-PG A Simple and Loopless Variance-Reduced Policy Gradient Method with Probabilistic Gradient Es.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,a2c,,,,,
121,Provably Efficient Offline Reinforcement Learning for Partially Observable Markov Decision Processes.pdf,False,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,other,,,,,,
122,Deconfounded Value Decomposition for Multi-Agent Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
123,Feature and Parameter Selection in Stochastic Linear Bandits.pdf,False,False,False,2022,icml,icml_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
124,How to Leverage Unlabeled Data in Offline Reinforcement Learning.pdf,True,True,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
125,Adversarially Trained Actor Critic for Offline Reinforcement Learning.pdf,True,True,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,ppo,sac,,,,
126,Lagrangian Method for Q-Function Learning with Applications to Machine Translation.pdf,True,False,False,2022,icml,icml_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
127,Improved No-Regret Algorithms for Stochastic Shortest Path with Linear MDP.pdf,False,False,False,2022,icml,icml_2022,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,,,,,ppo,dqn,,,,,
128,Online Decision Transformer.pdf,True,True,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
129,Learning Infinite-horizon Average-reward Markov Decision Process with Constraints.pdf,False,True,False,2022,icml,icml_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,other,,,,,,
130,MASER Multi-Agent Reinforcement Learning with Subgoals Generated from Experience Replay Buffer.pdf,True,True,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
131,Balancing Sample Efficiency and Suboptimality in Inverse Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,,,,,,
132,Divergence-Regularized Multi-Agent Actor-Critic.pdf,True,True,False,2022,icml,icml_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
133,Model-Free Opponent Shaping.pdf,True,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
134,Model-based Meta Reinforcement Learning using Graph Structured Surrogate Models and Amortized Policy.pdf,True,False,False,2022,icml,icml_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
135,Reinforcement Learning with Action-Free Pre-Training from Videos.pdf,True,False,False,2022,icml,icml_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dreamer,,,,,
136,Constrained Offline Policy Optimization.pdf,False,False,False,2022,icml,icml_2022,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
137,Learning Bellman Complete Representations for Offline Policy Evaluation.pdf,True,False,False,2022,icml,icml_2022,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dreamer,ppo,sac,,,,
138,Unified Scaling Laws for Routed Language Models.pdf,True,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
139,Bayesian Nonparametrics for Offline Skill Discovery.pdf,True,False,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
140,Greedy when Sure and Conservative when Uncertain about the Opponents.pdf,True,False,False,2022,icml,icml_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,ppo,dqn,,,,
141,POEM Out-of-Distribution Detection with Posterior Sampling.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
142,Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations.pdf,True,False,False,2022,icml,icml_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
143,Optimistic Linear Support and Successor Features as a Basis for Optimal Policy Transfer.pdf,True,False,False,2022,icml,icml_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
144,First-Order Regret in Reinforcement Learning with Linear Function Approximation A Robust Estimation .pdf,False,False,False,2022,icml,icml_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
145,A Simple Unified Framework for High Dimensional Bandit Problems.pdf,False,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
146,Convergence of Policy Gradient for Entropy Regularized MDPs with Neural Network Approximation in the.pdf,False,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
147,Generalizing Gaussian Smoothing for Random Search.pdf,True,True,False,2022,icml,icml_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
148,On the Sample Complexity of Learning Infinite-horizon Discounted Linear Kernel MDPs.pdf,False,False,False,2022,icml,icml_2022,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,,,,
149,Stabilizing Q-learning with Linear Architectures for Provable Efficient Learning.pdf,False,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,ppo,dqn,,,,,
150,A Regret Minimization Approach to Multi-Agent Control.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,sac,,,,
151,Off-Policy Evaluation for Large Action Spaces via Embeddings.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
152,Versatile Offline Imitation from Observations and Examples via Regularized State-Occupancy Matching.pdf,True,False,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
153,Generative Flow Networks for Discrete Probabilistic Modeling.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
154,Translating Robot Skills Learning Unsupervised Skill Correspondences Across Robots.pdf,False,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
155,Robust Task Representations for Offline Meta-Reinforcement Learning via Contrastive Learning.pdf,True,True,False,2022,icml,icml_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
156,Inverse Contextual Bandits Learning How Behavior Evolves over Time.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
157,Learning from Demonstration Provably Efficient Adversarial Policy Imitation with Linear Function App.pdf,True,False,False,2022,icml,icml_2022,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
158,On the Role of Discount Factor in Offline Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,,,,,
159,Proving Theorems using Incremental Learning and Hindsight Experience Replay.pdf,False,False,False,2022,icml,icml_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,sac,,,,,,
160,Denoised MDPs Learning World Models Better Than the World Itself.pdf,True,False,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,dreamer,sac,,,,,
161,Imitation Learning by Estimating Expertise of Demonstrators.pdf,True,False,False,2022,icml,icml_2022,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,,,,,,
162,Large Batch Experience Replay.pdf,True,True,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,td3,dqn,sac,,,,
163,Contextual Information-Directed Sampling.pdf,False,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
164,Towards Evaluating Adaptivity of Model-Based Reinforcement Learning Methods.pdf,True,True,False,2022,icml,icml_2022,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dreamer,,,,,
165,Constrained Variational Policy Optimization for Safe Reinforcement Learning.pdf,True,True,False,2022,icml,icml_2022,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
166,Interactive Inverse Reinforcement Learning for Cooperative Games.pdf,True,False,False,2022,icml,icml_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
167,Symmetric Machine Theory of Mind.pdf,True,False,False,2022,icml,icml_2022,6-10,(?:discount|reward)\s+function,,,,,,,ddpg,,,,,,
168,Contrastive UCB Provably Efficient Contrastive Self-Supervised Learning in Online Reinforcement Lear.pdf,True,False,False,2022,icml,icml_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
169,The State of Sparse Training in Deep Reinforcement Learning.pdf,True,True,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,a2c,sac,td3,ppo,,
170,Meta-Learning Hypothesis Spaces for Sequential Decision-making.pdf,False,True,False,2022,icml,icml_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
171,Branching Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
172,Communicating via Markov Decision Processes.pdf,True,False,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,a2c,,,,
173,Discovering Generalizable Spatial Goal Representations via Graph-based Active Reward Learning.pdf,True,False,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
174,Optimizing Tensor Network Contraction Using Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
175,Towards Uniformly Superhuman Autonomy via Subdominance Minimization.pdf,False,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
176,Off-Policy Fitted Q-Evaluation with Differentiable Function Approximators Z-Estimation and Inference.pdf,False,False,False,2022,icml,icml_2022,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
177,Welfare Maximization in Competitive Equilibrium Reinforcement Learning for Markov Exchange Economy.pdf,True,False,False,2022,icml,icml_2022,1-5,action-value\s+function,state-action\s+pairs,,,,,,ppo,dqn,sac,,,,
178,A Minimax Learning Approach to Off-Policy Evaluation in Confounded Partially Observable Markov Decis.pdf,True,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
179,Congested Bandits Optimal Routing via Short-term Resets.pdf,False,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
180,ModLaNets Learning Generalisable Dynamics via Modularity and Physical Inductive Bias.pdf,True,True,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
181,LeNSE Learning To Navigate Subgraph Embeddings for Large-Scale Combinatorial Optimisation.pdf,True,False,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
182,EqR Equivariant Representations for Data-Efficient Reinforcement Learning.pdf,True,True,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
183,Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters.pdf,True,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
184,Robust Deep Reinforcement Learning through Bootstrapped Opportunistic Curriculum.pdf,True,False,False,2022,icml,icml_2022,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
185,Zero-Shot Reward Specification via Grounded Natural Language.pdf,False,False,False,2022,icml,icml_2022,over 10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
186,Provable Reinforcement Learning with a Short-Term Memory.pdf,False,False,False,2022,icml,icml_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
187,A Temporal-Difference Approach to Policy Gradient Estimation.pdf,True,False,False,2022,icml,icml_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,dqn,ddpg,sac,td3,ppo,,
188,An Analytical Update Rule for General Policy Optimization.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
189,LIMO Latent Inceptionism for Targeted Molecule Generation.pdf,True,True,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
190,Independent Policy Gradient for Large-Scale Markov Potential Games Sharper Rates Function Approximat.pdf,False,False,False,2022,icml,icml_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
191,Adaptive Model Design for Markov Decision Process.pdf,False,True,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
192,Pessimistic Q-Learning for Offline Reinforcement Learning Towards Optimal Sample Complexity.pdf,False,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
193,Near-Optimal Learning of Extensive-Form Games with Imperfect Information.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
194,Generalized Data Distribution Iteration.pdf,False,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,dreamer,ppo,dqn,,,,
195,Fast Aquatic Swimmer Optimization with Differentiable Projective Dynamics and Neural Network Hydrody.pdf,False,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
196,Do Differentiable Simulators Give Better Policy Gradients.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
197,Pessimistic Minimax Value Iteration Provably Efficient Equilibrium Learning from Offline Datasets.pdf,False,False,False,2022,icml,icml_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
198,Direct Behavior Specification via Constrained Reinforcement Learning.pdf,True,True,False,2022,icml,icml_2022,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,sac,,,,
199,Interactively Learning Preference Constraints in Linear Bandits.pdf,True,False,False,2022,icml,icml_2022,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
200,Learning Dynamics and Generalization in Deep Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
201,Extracting Latent State Representations with Linear Dynamics from Rich Observations.pdf,True,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
202,Stochastic Rising Bandits.pdf,True,False,False,2022,icml,icml_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
203,Optimal Estimation of Policy Gradient via Double Fitted Iteration.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
204,Transformers are Meta-Reinforcement Learners.pdf,True,False,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
205,Actor-Critic based Improper Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
206,Curriculum Reinforcement Learning via Constrained Optimal Transport.pdf,True,True,False,2022,icml,icml_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
207,Improve Single-Point Zeroth-Order Optimization Using High-Pass and Low-Pass Filters.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
208,A Framework for Learning to Request Rich and Contextually Useful Information from Humans.pdf,True,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,a2c,,,,,
209,Contextual Bandits with Smooth Regret Efficient Learning in Continuous Action Spaces.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
210,Fast Population-Based Reinforcement Learning on a Single Machine.pdf,True,True,False,2022,icml,icml_2022,over 10,(?:discount|reward)\s+function,,,,,,,dqn,ddpg,sac,td3,ppo,,
211,Toward Compositional Generalization in Object-Oriented World Modeling.pdf,True,False,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
212,Understanding Policy Gradient Algorithms A Sensitivity-Based Approach.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,trpo,ppo,sac,,,,
213,Generative Cooperative Networks for Natural Language Generation.pdf,False,True,False,2022,icml,icml_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
214,Action-Sufficient State Representation Learning for Control with Structural Constraints.pdf,False,True,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,ppo,dqn,ddpg,,,
215,Private Streaming SCO in ell_p geometry with Applications in High Dimensional Online Decision Making.pdf,False,False,False,2022,icml,icml_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
216,Causal Dynamics Learning for Task-Independent State Abstraction.pdf,False,True,False,2022,icml,icml_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
217,DNS Determinantal Point Process Based Neural Network Sampler for Ensemble Reinforcement Learning.pdf,True,True,False,2022,icml,icml_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,dqn,,,,,,
218,Simplex Neural Population Learning Any-Mixture Bayes-Optimality in Symmetric Zero-sum Games.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
219,Learning Symmetric Embeddings for Equivariant World Models.pdf,True,False,False,2022,icml,icml_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
220,Large-Scale Graph Neural Architecture Search.pdf,True,True,False,2022,icml,icml_2022,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,,,,,,
221,Align-RUDDER Learning From Few Demonstrations by Reward Redistribution.pdf,True,True,False,2022,icml,icml_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
222,A Parametric Class of Approximate Gradient Updates for Policy Optimization.pdf,False,False,False,2022,icml,icml_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,ppo,dqn,,,,,
223,Plan Better Amid Conservatism Offline Multi-Agent Reinforcement Learning with Actor Rectification.pdf,True,True,False,2022,icml,icml_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,ddpg,,,
224,Efficient Learning for AlphaZero via Path Consistency.pdf,True,False,False,2022,icml,icml_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
225,Distributional Hamilton-Jacobi-Bellman Equations for Continuous-Time Reinforcement Learning.pdf,False,False,False,2022,icml,icml_2022,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
226,Offline RL Policies Should Be Trained to be Adaptive.pdf,True,True,False,2022,icml,icml_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
227,Risk-Averse No-Regret Learning in Online Convex Games.pdf,False,False,False,2022,icml,icml_2022,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
228,Continuous Control with Action Quantization from Demonstrations.pdf,True,True,False,2022,icml,icml_2022,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,trpo,dqn,ddpg,sac,td3,ppo,
229,Efficient Reinforcement Learning in Block MDPs A Model-free Representation Learning approach.pdf,True,False,False,2022,icml,icml_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
0,Superhuman Fairness.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
1,Optimal Horizon-Free Reward-Free Exploration for Linear Mixture MDPs.pdf,False,False,False,2023,icml,icml_2023,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
2,Q-learning Decision Transformer Leveraging Dynamic Programming for Conditional Sequence Modelling in.pdf,True,False,False,2023,icml,icml_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
3,Simplified Temporal Consistency Reinforcement Learning.pdf,True,True,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,pets,dqn,ddpg,sac,td-mpc,ppo,dreamer
4,Provable Reset-free Reinforcement Learning by No-Regret Reduction.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
5,Principled Offline RL in the Presence of Rich Exogenous Information.pdf,False,False,False,2023,icml,icml_2023,6-10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
6,FedHPO-Bench A Benchmark Suite for Federated Hyperparameter Optimization.pdf,True,True,False,2023,icml,icml_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
7,Live in the Moment Learning Dynamics Model Adapted to Evolving Policy.pdf,True,False,False,2023,icml,icml_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
8,LipsNet A Smooth and Robust Neural Network with Adaptive Lipschitz Constant for High Accuracy Optima.pdf,True,True,False,2023,icml,icml_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,td3,ppo,ddpg,,,,
9,StriderNet A Graph Reinforcement Learning Approach to Optimize Atomic Structures on Rough Energy Lan.pdf,True,False,False,2023,icml,icml_2023,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
10,Invariance in Policy Optimisation and Partial Identifiability in Reward Learning.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
11,Adapting to game trees in zero-sum imperfect information games.pdf,True,True,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
12,Towards Understanding and Improving GFlowNet Training.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
13,Towards Omni-generalizable Neural Methods for Vehicle Routing Problems.pdf,True,True,False,2023,icml,icml_2023,6-10,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,,,,,,,ppo,sac,,,,,
14,GFlowOut Dropout with Generative Flow Networks.pdf,True,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
15,Constrained Decision Transformer for Offline Safe Reinforcement Learning.pdf,False,True,False,2023,icml,icml_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
16,Facial Expression Recognition with Adaptive Frame Rate based on Multiple Testing Correction.pdf,True,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
17,Jump-Start Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
18,Improving Bi-level Optimization Based Methods with Inspiration from Humans Classroom Study Technique.pdf,True,True,False,2023,icml,icml_2023,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
19,An Adaptive Entropy-Regularization Framework for Multi-Agent Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,sac,,,
20,Emergence of Adaptive Circadian Rhythms in Deep Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
21,Adversarial Cheap Talk.pdf,False,True,False,2023,icml,icml_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
22,MANSA Learning Fast and Slow in Multi-Agent Systems.pdf,False,True,False,2023,icml,icml_2023,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
23,Hardness of Independent Learning and Sparse Equilibrium Computation in Markov Games.pdf,False,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
24,Combinatorial Neural Bandits.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
25,Regret Bounds for Markov Decision Processes with Recursive Optimized Certainty Equivalents.pdf,False,False,False,2023,icml,icml_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
26,Delay-Adapted Policy Optimization and Improved Regret for Adversarial MDP with Delayed Bandit Feedba.pdf,False,True,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,trpo,ppo,,,,,
27,On the Global Convergence of Risk-Averse Policy Gradient Methods with Expected Conditional Risk Meas.pdf,False,False,False,2023,icml,icml_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,dqn,sac,,,,
28,Revisiting the Linear-Programming Framework for Offline RL with General Function Approximation.pdf,False,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
29,Low-Switching Policy Gradient with Exploration via Online Sensitivity Sampling.pdf,False,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,,,,,
30,Online Learning in Stackelberg Games with an Omniscient Follower.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,ddpg,,,,
31,Semi-Offline Reinforcement Learning for Optimized Text Generation.pdf,True,True,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
32,Policy Contrastive Imitation Learning.pdf,False,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
33,Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning.pdf,True,True,False,2023,icml,icml_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
34,ReLOAD Reinforcement Learning with Optimistic Ascent-Descent for Last-Iterate Convergence in Constra.pdf,True,False,False,2023,icml,icml_2023,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,ddpg,,,,
35,Deep Laplacian-based Options for Temporally-Extended Exploration.pdf,True,True,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
36,ED-Batch Efficient Automatic Batching of Dynamic Neural Networks via Learned Finite State Machines.pdf,True,True,False,2023,icml,icml_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
37,Langevin Thompson Sampling with Logarithmic Communication Bandits and Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
38,Distance Weighted Supervised Learning for Offline Interaction Data.pdf,False,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,trpo,td3,ppo,dqn,,,
39,Hindsight Learning for MDPs with Exogenous Inputs.pdf,True,True,False,2023,icml,icml_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
40,QAS-Bench Rethinking Quantum Architecture Search and A Benchmark.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
41,Attention-Based Recurrence for Multi-Agent Reinforcement Learning under Stochastic Partial Observabi.pdf,True,True,False,2023,icml,icml_2023,over 10,value\s+function\s+approximation,,,,,,,ppo,dqn,,,,,
42,Beyond Reward Offline Preference-guided Policy Optimization.pdf,True,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
43,On the Convergence of SARSA with Linear Function Approximation.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
44,Eventual Discounting Temporal Logic Counterfactual Experience Replay.pdf,True,False,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
45,The Unintended Consequences of Discount Regularization Improving Regularization in Certainty Equival.pdf,False,True,False,2023,icml,icml_2023,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
46,Incentivizing Exploration with Linear Contexts and Combinatorial Actions.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
47,Fascinating Supervisory Signals and Where to Find Them Deep Anomaly Detection with Scale Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
48,Transformer-based Stagewise Decomposition for Large-Scale Multistage Stochastic Optimization.pdf,False,False,False,2023,icml,icml_2023,0,value\s+function\s+approximation,,,,,,,ppo,,,,,,
49,Interactive Object Placement with Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,ppo,sac,a2c,,,
50,What is Essential for Unseen Goal Generalization of Offline Goal-conditioned RL.pdf,True,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
51,Performative Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
52,Multi-task Representation Learning for Pure Exploration in Linear Bandits.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
53,ChiPFormer Transferable Chip Placement via Offline Decision Transformer.pdf,True,True,False,2023,icml,icml_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
54,SpotEM Efficient Video Search for Episodic Memory.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
55,Pretraining Language Models with Human Preferences.pdf,True,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
56,Boosting Offline Reinforcement Learning with Action Preference Query.pdf,True,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,sac,,,,
57,Unsupervised Skill Discovery for Learning Shared Structures across Changing Environments.pdf,False,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
58,The Wisdom of Hindsight Makes Language Models Better Instruction Followers.pdf,True,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
59,Anti-Exploration by Random Network Distillation.pdf,True,True,False,2023,icml,icml_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
60,Adaptive Barrier Smoothing for First-Order Policy Gradient with Contact Dynamics.pdf,False,True,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
61,Arithmetic Sampling Parallel Diverse Decoding for Large Language Models.pdf,True,False,False,2023,icml,icml_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
62,Generating Language Corrections for Teaching Physical Control Tasks.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
63,On the Interplay Between Misspecification and Sub-optimality Gap in Linear Contextual Bandits.pdf,False,True,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
64,Learning Control by Iterative Inversion.pdf,True,False,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,a2c,,,,,
65,Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,ppo,dqn,,,,,
66,Short-lived High-volume Bandits.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
67,ILLUME Rationalizing Vision-Language Models through Human Interactions.pdf,True,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
68,Hierarchical Programmatic Reinforcement Learning via Learning to Compose Programs.pdf,False,False,False,2023,icml,icml_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
69,Reachability-Aware Laplacian Representation in Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
70,Differentially Private Episodic Reinforcement Learning with Heavy-tailed Rewards.pdf,False,False,False,2023,icml,icml_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
71,Lower Bounds for Learning in Revealing POMDPs.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
72,Meta Learning of Interface Conditions for Multi-Domain Physics-Informed Neural Networks.pdf,False,True,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
73,Representations and Exploration for Deep Reinforcement Learning using Singular Value Decomposition.pdf,False,False,False,2023,icml,icml_2023,1-5,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
74,Off-Policy Average Reward Actor-Critic with Deterministic Policy Search.pdf,True,True,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,td3,ppo,
75,Hierarchies of Reward Machines.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
76,MetricGAN-OKD Multi-Metric Optimization of MetricGAN via Online Knowledge Distillation for Speech En.pdf,False,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
77,Distilling Internet-Scale Vision-Language Models into Embodied Agents.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
78,Revisiting Bellman Errors for Offline Model Selection.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,trpo,ppo,dqn,sac,,,
79,Flipping Coins to Estimate Pseudocounts for Exploration in Reinforcement Learning.pdf,True,True,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
80,Controllability-Aware Unsupervised Skill Discovery.pdf,True,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
81,Representation Learning with Multi-Step Inverse Kinematics An Efficient and Optimal Approach to Rich.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
82,Better Training of GFlowNets with Local Credit and Incomplete Trajectories.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
83,Best Arm Identification in Multi-Agent Multi-Armed Bandits.pdf,False,False,False,2023,icml,icml_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
84,Beyond Exponentially Fast Mixing in Average-Reward Reinforcement Learning via Multi-Level Monte Carl.pdf,False,True,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,sac,,,,,,
85,Quantile Credit Assignment.pdf,False,True,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,dqn,,,,,,
86,A theory of continuous generative flow networks.pdf,False,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
87,Partially Observable Multi-agent RL with Quasi-Efficiency The Blessing of Information Sharing.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
88,Provably and Practically Efficient Neural Contextual Bandits.pdf,False,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
89,TGRL An Algorithm for Teacher Guided Reinforcement Learning.pdf,False,True,False,2023,icml,icml_2023,6-10,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
90,Guiding Pretraining in Reinforcement Learning with Large Language Models.pdf,False,False,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
91,Model-based Offline Reinforcement Learning with Count-based Conservatism.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,a2c,sac,td3,ppo,,
92,An Instrumental Variable Approach to Confounded Off-Policy Evaluation.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
93,Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear Contextual Bandits and Markov .pdf,False,False,False,2023,icml,icml_2023,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
94,Information-Theoretic State Space Model for Multi-View Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
95,Curious Replay for Model-based Adaptation.pdf,True,True,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,ppo,sac,,,,
96,Meta-learning Parameterized Skills.pdf,True,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
97,Target-based Surrogates for Stochastic Optimization.pdf,True,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,sac,,,,
98,Model-Bellman Inconsistency for Model-based Offline Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
99,Language Instructed Reinforcement Learning for Human-AI Coordination.pdf,True,False,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
100,Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning.pdf,True,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
101,Reinforcement Learning in Low-rank MDPs with Density Features.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
102,Reinforcement Learning with History Dependent Dynamic Contexts.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
103,Curiosity in Hindsight Intrinsic Exploration in Stochastic Environments.pdf,False,False,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
104,Robust Satisficing MDPs.pdf,True,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
105,Global Optimization with Parametric Function Approximation.pdf,False,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
106,Optimal Rates and Efficient Algorithms for Online Bayesian Persuasion.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
107,Robust Budget Pacing with a Single Sample.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
108,Scalable Safe Policy Improvement via Monte Carlo Tree Search.pdf,True,False,False,2023,icml,icml_2023,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
109,Smooth Non-stationary Bandits.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
110,Reward-Mixing MDPs with Few Latent Contexts are Learnable.pdf,False,False,False,2023,icml,icml_2023,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
111,On the Power of Pre-training for Generalization in RL Provable Benefits and Hardness.pdf,False,False,False,2023,icml,icml_2023,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
112,The Blessing of Heterogeneity in Federated Q-Learning Linear Speedup and Beyond.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
113,Discovering Object-Centric Generalized Value Functions From Pixels.pdf,True,False,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,dqn,,,,,,
114,Learning Globally Smooth Functions on Manifolds.pdf,False,False,False,2023,icml,icml_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
115,An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
116,Simple Embodied Language Learning as a Byproduct of Meta-Reinforcement Learning.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
117,SNeRL Semantic-aware Neural Radiance Fields for Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
118,Online Prototype Alignment for Few-shot Policy Transfer.pdf,True,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
119,Robust Subtask Learning for Compositional Generalization.pdf,True,True,False,2023,icml,icml_2023,6-10,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,sac,,,
120,Learning Compiler Pass Orders using Coreset and Normalized Value Prediction.pdf,False,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
121,For Pre-Trained Vision Models in Motor Control Not All Policy Learning Methods are Created Equal.pdf,False,False,False,2023,icml,icml_2023,over 10,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,,,,
122,Which Tricks are Important for Learning to Rank.pdf,False,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
123,Parallel Q-Learning Scaling Off-policy Reinforcement Learning under Massively Parallel Simulation.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a3c,dqn,ddpg,a2c,sac,ppo,
124,Oracles  Followers Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning.pdf,False,True,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
125,A Study of Global and Episodic Bonuses for Exploration in Contextual MDPs.pdf,True,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
126,Stein Variational Goal Generation for adaptive Exploration in Multi-Goal Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,ddpg,,,,,
127,Reinforcement Learning with General Utilities Simpler Variance Reduction and Large State-Action Spac.pdf,False,False,False,2023,icml,icml_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
128,Learning Temporally AbstractWorld Models without Online Experimentation.pdf,False,False,False,2023,icml,icml_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
129,LESSON Learning to Integrate Exploration Strategies for Reinforcement Learning via an Option Framewo.pdf,True,False,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,,,,,,
130,Regret Minimization and Convergence to Equilibria in General-sum Markov Games.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,,,,,ppo,,,,,,
131,Safe Offline Reinforcement Learning with Real-Time Budget Constraints.pdf,True,False,False,2023,icml,icml_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,pets,ppo,dqn,sac,,,
132,Toward Efficient Gradient-Based Value Estimation.pdf,False,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,a3c,ppo,dqn,ddpg,,,
133,Internally Rewarded Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
134,Warm-Start Actor-Critic From Approximation Error to Sub-optimality Gap.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
135,Emergent Agentic Transformer from Chain of Hindsight Experience.pdf,False,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,td3,ppo,,,,
136,Variational Curriculum Reinforcement Learning for Unsupervised Discovery of Skills.pdf,True,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,pets,ppo,dqn,sac,,,
137,A Connection between One-Step RL and Critic Regularization in Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
138,Convergence of Proximal Point and Extragradient-Based Methods Beyond Monotonicity the Case of Negati.pdf,True,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
139,Universal Morphology Control via Contextual Modulation.pdf,True,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
140,Sharp Variance-Dependent Bounds in Reinforcement Learning Best of Both Worlds in Stochastic and Dete.pdf,False,False,False,2023,icml,icml_2023,0,state-action\s+pairs,,,,,,,ppo,dqn,,,,,
141,Learning in POMDPs is Sample-Efficient with Hindsight Observability.pdf,False,False,False,2023,icml,icml_2023,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
142,Nearly Minimax Optimal Reinforcement Learning for Linear Markov Decision Processes.pdf,False,False,False,2023,icml,icml_2023,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
143,Efficient Exploration via Epistemic-Risk-Seeking Policy Optimization.pdf,False,False,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
144,Model-Free Robust Average-Reward Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
145,Supported Trust Region Optimization for Offline Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,td3,ppo,dqn,,,
146,Prefer to Classify Improving Text Classifiers via Auxiliary Preference Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
147,Revisiting Domain Randomization via Relaxed State-Adversarial Policy Optimization.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
148,A Coupled Flow Approach to Imitation Learning.pdf,True,False,False,2023,icml,icml_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
149,Learning Mixtures of Markov Chains and MDPs.pdf,True,False,False,2023,icml,icml_2023,over 10,state-action\s+pairs,,,,,,,ppo,,,,,,
150,Bayesian Reparameterization of Reward-Conditioned Reinforcement Learning with Energy-based Models.pdf,False,False,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
151,Who Needs to Know Minimal Knowledge for Optimal Coordination.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,a2c,,,,
152,Optimizing DDPM Sampling with Shortcut Fine-Tuning.pdf,True,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
153,Detecting Adversarial Directions in Deep Reinforcement Learning to Make Robust Decisions.pdf,False,True,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
154,Consistency Models.pdf,False,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
155,Fair yet Asymptotically Equal Collaborative Learning.pdf,True,False,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
156,Quantum Policy Gradient Algorithm with Optimized Action Decoding.pdf,False,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,sac,,,,,
157,Learning to Incentivize Information Acquisition Proper Scoring Rules Meet Principal-Agent Model.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
158,Weighted Sampling without Replacement for Deep Top-k Classification.pdf,False,False,False,2023,icml,icml_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
159,Predictable MDP Abstraction for Unsupervised Model-Based RL.pdf,True,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
160,UPSCALE Unconstrained Channel Pruning.pdf,True,False,False,2023,icml,icml_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
161,Layered State Discovery for Incremental Autonomous Exploration.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
162,Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
163,RLang A Declarative Language for Describing Partial World Knowledge to Reinforcement Learning Agents.pdf,True,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
164,Why Target Networks Stabilise Temporal Difference Methods.pdf,False,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,,,,,,ppo,dqn,sac,,,,
165,Enhancing Activity Prediction Models in Drug Discovery with the Ability to Understand Human Language.pdf,True,False,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
166,Bandits with Knapsacks Advice on Time-Varying Demands.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
167,Posterior Sampling for Deep Reinforcement Learning.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,dreamer,ppo,dqn,,,,
168,Multi-task Hierarchical Adversarial Inverse Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
169,Representation-Driven Reinforcement Learning.pdf,False,True,False,2023,icml,icml_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
170,The Optimal Approximation Factors in Misspecified Off-Policy Value Function Estimation.pdf,False,True,False,2023,icml,icml_2023,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
171,Explaining Reinforcement Learning with Shapley Values.pdf,True,False,False,2023,icml,icml_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
172,SeMAIL Eliminating Distractors in Visual Imitation via Separated Models.pdf,True,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
173,Bootstrapped Representations in Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
174,Offline Learning in Markov Games with General Function Approximation.pdf,False,False,False,2023,icml,icml_2023,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
175,Deep Anomaly Detection under Labeling Budget Constraints.pdf,True,False,False,2023,icml,icml_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
176,Meta-SAGE Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shif.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
177,Reinforcement Learning from Passive Data via Latent Intentions.pdf,True,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
178,Reparameterized Policy Learning for Multimodal Trajectory Optimization.pdf,True,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dreamer,ppo,sac,,,,
179,Near-Optimal Î¦-Regret Learning in Extensive-Form Games.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
180,Towards Robust and Safe Reinforcement Learning with Benign Off-policy Data.pdf,False,False,False,2023,icml,icml_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
181,Multi-Agent Learning from Learners.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
182,Improved Policy Evaluation for Randomized Trials of Algorithmic Resource Allocation.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
183,RACE Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evol.pdf,True,False,False,2023,icml,icml_2023,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,ddpg,,,
184,Diffusion Models for Black-Box Optimization.pdf,True,True,False,2023,icml,icml_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
185,Demonstration-free Autonomous Reinforcement Learning via Implicit and Bidirectional Curriculum.pdf,True,False,False,2023,icml,icml_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,sac,,,,,
186,Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
187,Best of Both Worlds Policy Optimization.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
188,Multi-Environment Pretraining Enables Transfer to Action Limited Datasets.pdf,False,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
189,Multi-User Reinforcement Learning with Low Rank Rewards.pdf,False,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
190,Exponential Smoothing for Off-Policy Learning.pdf,False,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
191,NNSplitter An Active Defense Solution for DNN Model via Automated Weight Obfuscation.pdf,True,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
192,Mastering the Unsupervised Reinforcement Learning Benchmark from Pixels.pdf,False,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,dqn,sac,td-mpc,ppo,dreamer,,
193,Set-membership Belief State-based Reinforcement Learning for POMDPs.pdf,False,False,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,ppo,,,,,,
194,Does Sparsity Help in Learning Misspecified Linear Bandits.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
195,ConCerNet A Contrastive Learning Based Framework for Automated Conservation Law Discovery and Trustw.pdf,True,False,False,2023,icml,icml_2023,1-5,state-action\s+pairs,,,,,,,ppo,sac,,,,,
196,Model-based Reinforcement Learning with Scalable Composite Policy Gradient Estimators.pdf,True,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dreamer,,,,,
197,Deep Graph Representation Learning and Optimization for Influence Maximization.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
198,On the Importance of Feature Decorrelation for Unsupervised Representation Learning in Reinforcement.pdf,True,True,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
199,Policy Regularization with Dataset Constraint for Offline Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,,,,
200,Understanding the Complexity Gains of Single-Task RL with a Curriculum.pdf,True,False,False,2023,icml,icml_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
201,Do the Rewards Justify the Means Measuring Trade-Offs Between Rewards and Ethical Behavior in the Ma.pdf,True,True,False,2023,icml,icml_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
202,Multi-channel Autobidding with Budget and ROI Constraints.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
203,Leveraging Offline Data in Online Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,0,action-value\s+function,,,,,,,ppo,,,,,,
204,Subequivariant Graph Reinforcement Learning in 3D Environments.pdf,True,False,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
205,Autoregressive Diffusion Model for Graph Generation.pdf,True,False,False,2023,icml,icml_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
206,A Robust Test for the Stationarity Assumption in Sequential Decision Making.pdf,True,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
207,Enforcing Hard Constraints with Soft Barriers Safe Reinforcement Learning in Unknown Stochastic Envi.pdf,False,False,False,2023,icml,icml_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,sac,,,,,
208,Contextual Reliability When Different Features Matter in Different Contexts.pdf,True,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
209,Internet Explorer Targeted Representation Learning on the Open Web.pdf,True,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,pets,ppo,sac,,,,
210,Distributional Offline Policy Evaluation with Predictive Error Guarantees.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
211,Offline Reinforcement Learning with Closed-Form Policy Improvement Operators.pdf,True,True,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,trpo,dqn,sac,td3,ppo,,
212,Learning to Bid in Repeated First-Price Auctions with Budgets.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
213,Do Embodied Agents Dream of Pixelated Sheep Embodied Decision Making using Language Guided World Mod.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
214,Fair and Accurate Decision Making through Group-Aware Learning.pdf,False,False,False,2023,icml,icml_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
215,Accelerated Stochastic Optimization Methods under Quasar-convexity.pdf,True,True,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
216,DoMo-AC Doubly Multi-step Off-policy Actor-Critic Algorithm.pdf,False,False,False,2023,icml,icml_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
217,Policy Gradient in Robust MDPs with Global Convergence Guarantee.pdf,True,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
218,Semi Bandit dynamics in Congestion Games Convergence to Nash Equilibrium and No-Regret Guarantees.pdf,True,False,False,2023,icml,icml_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
219,Contrastive Energy Prediction for Exact Energy-Guided Diffusion Sampling in Offline Reinforcement Le.pdf,True,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
220,Abstract-to-Executable Trajectory Translation for One-Shot Task Generalization.pdf,False,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
221,A Model-Based Method for Minimizing CVaR and Beyond.pdf,False,True,False,2023,icml,icml_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
222,Biases in Evaluation of Molecular Optimization Methods and Bias Reduction Strategies.pdf,True,False,False,2023,icml,icml_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
223,On the Effectiveness of Offline RL for Dialogue Response Generation.pdf,True,True,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
224,Stochastic Gradient Succeeds for Bandits.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
225,MAHALO Unifying Offline Reinforcement Learning and Imitation Learning from Observations.pdf,True,True,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
226,Efficient Rate Optimal Regret for Adversarial Contextual MDPs Using Online Function Approximation.pdf,False,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
227,Scalable Multi-Agent Reinforcement Learning through Intelligent Information Aggregation.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,ddpg,sac,td3,ppo,,
228,Offline Meta Reinforcement Learning with In-Distribution Online Adaptation.pdf,True,False,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
229,Hierarchical Diffusion for Offline Decision Making.pdf,True,True,False,2023,icml,icml_2023,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
230,Truncating Trajectories in Monte Carlo Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
231,Sequential Counterfactual Risk Minimization.pdf,True,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
232,Symmetry-Aware Robot Design with Structured Subgroups.pdf,True,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
233,Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning.pdf,True,True,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,a2c,,,,
234,Explainability as statistical inference.pdf,False,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
235,On the Global Convergence of Fitted Q-Iteration with Two-layer Neural Network Parametrization.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
236,Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons.pdf,False,False,False,2023,icml,icml_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
237,A Framework for Adapting Offline Algorithms to Solve Combinatorial Multi-Armed Bandit Problems with .pdf,False,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
238,On the Occupancy Measure of Non-Markovian Policies in Continuous MDPs.pdf,False,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
239,Graph Reinforcement Learning for Network Control via Bi-Level Optimization.pdf,True,True,False,2023,icml,icml_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,a2c,,,,,
240,On Penalty-based Bilevel Gradient Descent Method.pdf,False,False,False,2023,icml,icml_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
241,Bigger Better Faster Human-level Atari with human-level efficiency.pdf,False,False,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
242,Spatial-Temporal Graph Learning with Adversarial Contrastive Adaptation.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
243,Learning GFlowNets From Partial Episodes For Improved Convergence And Stability.pdf,False,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,sac,,,
244,Non-stationary Reinforcement Learning under General Function Approximation.pdf,False,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
245,Adaptive Coordination in Social Embodied Rearrangement.pdf,False,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
246,Contextual Combinatorial Bandits with Probabilistically Triggered Arms.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
247,Nearly Optimal Competitive Ratio for Online Allocation Problems with Two-sided Resource Constraints .pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
248,Efficient Online Reinforcement Learning with Offline Data.pdf,True,True,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,pets,dqn,sac,ppo,,
249,MyoDex A Generalizable Prior for Dexterous Manipulation.pdf,False,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
250,Provably Efficient Representation Learning with Tractable Planning in Low-Rank POMDP.pdf,True,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
251,When is Realizability Sufficient for Off-Policy Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,,,,dqn,,,,,,
252,What can online reinforcement learning with function approximation benefit from general coverage con.pdf,False,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,,,ppo,dqn,,,,,
253,Contextual Conservative Interleaving Bandits.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
254,Revisiting Weighted Aggregation in Federated Learning with Neural Networks.pdf,False,True,False,2023,icml,icml_2023,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
255,Lazy Agents A New Perspective on Solving Sparse Reward Problem in Multi-agent Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,ddpg,,,,,
256,Atari-5 Distilling the Arcade Learning Environment down to Five Games.pdf,True,True,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a3c,dqn,,,,,
257,CircuitNet A Generic Neural Network to Realize Universal Circuit Motif Modeling.pdf,False,True,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,ppo,sac,,,,
258,Efficient RL via Disentangled Environment and Agent Representations.pdf,False,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
259,Deep Temporal Sets with Evidential Reinforced Attentions for Unique Behavioral Pattern Discovery.pdf,True,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
260,Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories.pdf,True,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,td3,dqn,sac,,,,
261,ContraBAR Contrastive Bayes-Adaptive Deep RL.pdf,True,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
262,Generative Pretraining for Black-Box Optimization.pdf,True,True,False,2023,icml,icml_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
263,Robust Situational Reinforcement Learning in Face of Context Disturbances.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
264,Improved Regret for Efficient Online Reinforcement Learning with Linear Function Approximation.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
265,Horizon-Free and Variance-Dependent Reinforcement Learning for Latent Markov Decision Processes.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
266,An Information-Theoretic Analysis of Nonstationary Bandit Learning.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
267,QuantumDARTS Differentiable Quantum Architecture Search for Variational Quantum Algorithms.pdf,False,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
268,Continual Task Allocation in Meta-Policy Network via Sparse Prompting.pdf,True,False,False,2023,icml,icml_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
269,Computationally Efficient PAC RL in POMDPs with Latent Determinism and Conditional Embeddings.pdf,True,False,False,2023,icml,icml_2023,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
270,PPG Reloaded An Empirical Study on What Matters in Phasic Policy Gradient.pdf,False,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
271,On Many-Actions Policy Gradient.pdf,True,True,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,dreamer,ppo,dqn,sac,,,
272,Behavior Contrastive Learning for Unsupervised Skill Discovery.pdf,True,True,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,ppo,sac,,,,
273,NtextAtext2Q Neural Attention Additive Model for Interpretable Multi-Agent Q-Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,action-value\s+function,,,,,,,dqn,sac,,,,,
274,Go Beyond Imagination Maximizing Episodic Reachability with World Models.pdf,True,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
275,Actor-Critic Alignment for Offline-to-Online Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
276,Bayesian Design Principles for Frequentist Sequential Learning.pdf,False,False,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
277,Learning to Initiate and Reason in Event-Driven Cascading Processes.pdf,False,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
278,Cooperative Open-ended Learning Framework for Zero-Shot Coordination.pdf,True,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
279,Diagnosis Feedback Adaptation A Human-in-the-Loop Framework for Test-Time Policy Adaptation.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,pets,ppo,sac,,,,
280,Fast Rates for Maximum Entropy Exploration.pdf,True,False,False,2023,icml,icml_2023,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
281,PromptBoosting Black-Box Text Classification with Ten Forward Passes.pdf,True,True,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
282,Exploring the Benefits of Training Expert Language Models over Instruction Tuning.pdf,True,True,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
283,On the Statistical Benefits of Temporal Difference Learning.pdf,False,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
284,AdaptDiffuser Diffusion Models as Adaptive Self-evolving Planners.pdf,True,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
285,Settling the Reward Hypothesis.pdf,False,False,False,2023,icml,icml_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
286,Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heterosced.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
287,MetaDiffuser Diffusion Model as Conditional Planner for Offline Meta-RL.pdf,True,False,False,2023,icml,icml_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
288,Inverse Reinforcement Learning without Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,dqn,sac,,,,
289,One-shot Imitation in a Non-Stationary Environment via Multi-Modal Skill.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
290,Hyperparameters in Reinforcement Learning and How To Tune Them.pdf,True,True,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,sac,,,,
291,Near-optimal Conservative Exploration in Reinforcement Learning under Episode-wise Constraints.pdf,False,False,False,2023,icml,icml_2023,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
292,Aligning Language Models with Preferences through f-divergence Minimization.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
293,Online Nonstochastic Control with Adversarial and Static Constraints.pdf,False,False,False,2023,icml,icml_2023,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
294,Future-conditioned Unsupervised Pretraining for Decision Transformer.pdf,True,True,False,2023,icml,icml_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
295,Understanding Self-Predictive Learning for Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,sac,,,,,,
296,Reinforcement Learning Can Be More Efficient with Multiple Rewards.pdf,False,False,False,2023,icml,icml_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
297,Towards a better understanding of representation dynamics under TD-learning.pdf,False,False,False,2023,icml,icml_2023,1-5,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
298,LIV Language-Image Representations and Rewards for Robotic Control.pdf,True,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
299,Regularization and Variance-Weighted Regression Achieves Minimax Optimality in Linear MDPs Theory an.pdf,True,False,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
300,Enabling First-Order Gradient-Based Learning for Equilibrium Computation in Markets.pdf,True,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
301,CO-BED Information-Theoretic Contextual Optimization via Bayesian Experimental Design.pdf,True,False,False,2023,icml,icml_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
302,HarsanyiNet Computing Accurate Shapley Values in a Single Forward Propagation.pdf,True,False,False,2023,icml,icml_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
303,Online Restless Bandits with Unobserved States.pdf,False,False,False,2023,icml,icml_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
304,Learning Belief Representations for Partially Observable Deep RL.pdf,True,False,False,2023,icml,icml_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
305,Provably Efficient Offline Reinforcement Learning with Perturbed Data Sources.pdf,False,False,False,2023,icml,icml_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
306,CLUTR Curriculum Learning via Unsupervised Task Representation Learning.pdf,True,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
307,Correcting discount-factor mismatch in on-policy policy gradient methods.pdf,False,True,False,2023,icml,icml_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,,,,
308,STEERING  Stein Information Directed Exploration for Model-Based Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
309,Complementary Attention for Multi-Agent Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,,,,
310,A Near-Optimal Algorithm for Safe Reinforcement Learning Under Instantaneous Hard Constraints.pdf,False,False,False,2023,icml,icml_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
311,Learning for Edge-Weighted Online Bipartite Matching with Robustness Guarantees.pdf,False,False,False,2023,icml,icml_2023,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
312,Active Policy Improvement from Multiple Black-box Oracles.pdf,False,True,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
313,Adversarial Learning of Distributional Reinforcement Learning.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
314,Stochastic Policy Gradient Methods Improved Sample Complexity for Fisher-non-degenerate Policies.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
315,Social learning spontaneously emerges by searching optimal heuristics with deep reinforcement learni.pdf,True,True,False,2023,icml,icml_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
316,The Statistical Benefits of Quantile Temporal-Difference Learning for Value Estimation.pdf,False,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
317,Multi-Objective GFlowNets.pdf,True,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,a2c,,,,,
318,A Reinforcement Learning Framework for Dynamic Mediation Analysis.pdf,True,False,False,2023,icml,icml_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
319,A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems.pdf,True,False,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
320,The Benefits of Model-Based Generalization in Reinforcement Learning.pdf,True,True,False,2023,icml,icml_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,dreamer,ppo,dqn,sac,,,
321,Cooperative Multi-Agent Reinforcement Learning Asynchronous Communication and Linear Function Approx.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
322,Identifiability and Generalizability in Constrained Inverse Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,sac,,,,,
323,Investigating the Role of Model-Based Learning in Exploration and Transfer.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,ppo,dqn,,,,
324,Nearly Minimax Optimal Regret for Learning Linear Mixture Stochastic Shortest Path.pdf,False,False,False,2023,icml,icml_2023,0,value\s+function\s+approximation,,,,,,,ppo,dqn,,,,,
325,Local Optimization Achieves Global Optimality in Multi-Agent Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,trpo,ppo,dqn,,,,
326,Cell-Free Latent Go-Explore.pdf,True,True,False,2023,icml,icml_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,sac,,,
327,Tuning Computer Vision Models With Task Rewards.pdf,True,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
328,Exploring Chemical Space with Score-based Out-of-distribution Generation.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
329,Optimistic Planning by Regularized Dynamic Programming.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
330,Learning to Maximize Mutual Information for Dynamic Feature Selection.pdf,True,True,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
331,K-SHAP Policy Clustering Algorithm for Anonymous Multi-Agent State-Action Pairs.pdf,True,False,False,2023,icml,icml_2023,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
332,Understanding Plasticity in Neural Networks.pdf,True,True,False,2023,icml,icml_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
333,Horizon-free Learning for Markov Decision Processes and Games Stochastically Bounded Rewards and Imp.pdf,False,False,False,2023,icml,icml_2023,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
334,The Ideal Continual Learner An Agent That Never Forgets.pdf,True,False,False,2023,icml,icml_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
335,GFlowNet-EM for Learning Compositional Latent Variable Models.pdf,True,False,False,2023,icml,icml_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
336,Context-Aware Bayesian Network Actor-Critic Methods for Cooperative Multi-Agent Reinforcement Learni.pdf,False,False,False,2023,icml,icml_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
337,Bandit Multi-linear DR-Submodular Maximization and Its Applications on Adversarial Submodular Bandit.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
338,Controlling Type Confounding in Ad Hoc Teamwork with Instance-wise Teammate Feedback Rectification.pdf,False,False,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
339,Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning.pdf,True,False,False,2023,icml,icml_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
340,Abstracting Imperfect Information Away from Two-Player Zero-Sum Games.pdf,False,False,False,2023,icml,icml_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
341,The Dormant Neuron Phenomenon in Deep Reinforcement Learning.pdf,True,True,False,2023,icml,icml_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
342,Variance Control for Distributional Reinforcement Learning.pdf,True,True,False,2023,icml,icml_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
343,Hierarchical Imitation Learning with Vector Quantized Models.pdf,False,False,False,2023,icml,icml_2023,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
344,Training-Free Neural Active Learning with Initialization-Robustness Guarantees.pdf,True,True,False,2023,icml,icml_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
0,Remembering to Be Fair Non-Markovian Fairness in Sequential Decision Making.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
1,Rethinking Decision Transformer via Hierarchical Reinforcement Learning.pdf,False,True,False,2024,icml,icml_2024,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,,,,
2,Transforming and Combining Rewards for Aligning Large Language Models.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
3,Self-Composing Policies for Scalable Continual Reinforcement Learning.pdf,True,True,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
4,RL-CFR Improving Action Abstraction for Imperfect Information Extensive-Form Games with Reinforcemen.pdf,False,False,False,2024,icml,icml_2024,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
5,Learning Iterative Reasoning through Energy Diffusion.pdf,False,True,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
6,EvoRainbow Combining Improvements in Evolutionary Reinforcement Learning for Policy Search.pdf,True,False,False,2024,icml,icml_2024,1-5,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
7,Rethinking Transformers in Solving POMDPs.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,dqn,sac,td3,ppo,dreamer,,
8,Understanding and Diagnosing Deep Reinforcement Learning.pdf,False,False,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,dqn,,,,,,
9,SHINE Shielding Backdoors in Deep Reinforcement Learning.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,,,,,
10,Efficient Denoising Diffusion via Probabilistic Masking.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
11,Pragmatic Feature Preferences Learning Reward-Relevant Preferences from Human Input.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
12,On the Unexpected Effectiveness of Reinforcement Learning for Sequential Recommendation.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,a2c,,,,,
13,Zero-Sum Positional Differential Games as a Framework for Robust Reinforcement Learning Deep Q-Learn.pdf,False,True,False,2024,icml,icml_2024,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,sac,,,
14,Q-Star Meets Scalable Posterior Sampling Bridging Theory and Practice via HyperAgent.pdf,True,False,False,2024,icml,icml_2024,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,,,ppo,dqn,,,,,
15,Training Greedy Policy for Proposal Batch Selection in Expensive Multi-Objective Combinatorial Optim.pdf,True,True,False,2024,icml,icml_2024,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,sac,,,,,
16,Deep Demonstration Tracing Learning Generalizable Imitator Policy for Runtime Imitation from a Singl.pdf,False,True,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
17,DecisionNCE Embodied Multimodal Representations via Implicit Preference Learning.pdf,False,True,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
18,Efficient World Models with Context-Aware Tokenization.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dreamer,,,,,
19,Open Ad Hoc Teamwork with Cooperative Game Theory.pdf,False,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,sac,,,
20,Position Automatic Environment Shaping is the Next Frontier in RL.pdf,False,True,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
21,High-dimensional Linear Bandits with Knapsacks.pdf,False,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
22,Learning to Explore in POMDPs with Informational Rewards.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
23,Learning to Play Atari in a World of Tokens.pdf,False,False,False,2024,icml,icml_2024,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,,,,,,
24,SiT Symmetry-invariant Transformers for Generalisation in Reinforcement Learning.pdf,False,True,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
25,Information-Directed Pessimism for Offline Reinforcement Learning.pdf,True,True,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,,,,,ppo,dqn,sac,,,,
26,Bridging Environments and Language with Rendering Functions and Vision-Language Models.pdf,False,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
27,Generalized Smooth Variational Inequalities Methods with Adaptive Stepsizes.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
28,WARM On the Benefits of Weight Averaged Reward Models.pdf,False,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
29,Position Open-Endedness is Essential for Artificial Superhuman Intelligence.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
30,Sample-Efficient Multiagent Reinforcement Learning with Reset Replay.pdf,False,False,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,dqn,ddpg,sac,,,,
31,How to Leverage Diverse Demonstrations in Offline Imitation Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
32,Enhancing Value Function Estimation through First-Order State-Action Dynamics in Offline Reinforceme.pdf,False,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,dqn,sac,,,
33,Trust the Model Where It Trusts Itself - Model-Based Actor-Critic with Uncertainty-Aware Rollout Ada.pdf,True,True,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
34,No-Regret Reinforcement Learning in Smooth MDPs.pdf,False,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
35,Position Data-driven Discovery with Large Generative Models.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
36,A Unified Linear Programming Framework for Offline Reward Learning from Human Demonstrations and Fee.pdf,False,False,False,2024,icml,icml_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
37,Averaging n-step Returns Reduces Variance in Reinforcement Learning.pdf,True,True,False,2024,icml,icml_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
38,Fast and Sample Efficient Multi-Task Representation Learning in Stochastic Contextual Bandits.pdf,False,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
39,Acquiring Diverse Skills using Curriculum Reinforcement Learning with Mixture of Experts.pdf,False,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
40,Model-based Reinforcement Learning for Confounded POMDPs.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
41,Efficient Policy Evaluation with Offline Data Informed Behavior Policy Design.pdf,True,True,False,2024,icml,icml_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
42,Provably Efficient Partially Observable Risk-sensitive Reinforcement Learning with Hindsight Observa.pdf,False,False,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
43,HGAP Boosting Permutation Invariant and Permutation Equivariant in Multi-Agent Reinforcement Learnin.pdf,False,False,False,2024,icml,icml_2024,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
44,Learning Causal Dynamics Models in Object-Oriented Environments.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
45,Locally Interdependent Multi-Agent MDP Theoretical Framework for Decentralized Agents with Dynamic D.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
46,Uncertainty-Aware Reward-Free Exploration with General Function Approximation.pdf,True,False,False,2024,icml,icml_2024,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
47,SF-DQN Provable Knowledge Transfer using Successor Feature for Deep Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
48,Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
49,Configurable Mirror Descent Towards a Unification of Decision Making.pdf,True,True,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
50,Confidence Aware Inverse Constrained Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
51,Learning Latent Dynamic Robust Representations for World Models.pdf,True,True,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,td-mpc,dreamer,ppo,sac,,,
52,Sequential Asynchronous Action Coordination in Multi-Agent Systems A Stackelberg Decision Transforme.pdf,False,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
53,Token-level Direct Preference Optimization.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
54,Why Do Animals Need Shaping A Theory of Task Composition and Curriculum Learning.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
55,Limited Preference Aided Imitation Learning from Imperfect Demonstrations.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
56,BAGEL Bootstrapping Agents by Guiding Exploration with Language.pdf,False,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
57,Behavior Generation with Latent Actions.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
58,Q-Probe A Lightweight Approach to Reward Maximization for Language Models.pdf,True,True,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
59,Multi-Agent Reinforcement Learning with Hierarchical Coordination for Emergency Responder Stationing.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,ddpg,,,,
60,OptiMUS Scalable Optimization Modeling with MILP Solvers and Large Language Models.pdf,True,False,False,2024,icml,icml_2024,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,,,,,,,ppo,sac,,,,,
61,Projecting Molecules into Synthesizable Chemical Spaces.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
62,DRED Zero-Shot Transfer in Reinforcement Learning via Data-Regularised Environment Design.pdf,True,True,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,a3c,ppo,,,,,
63,Constrained Ensemble Exploration for Unsupervised Skill Discovery.pdf,True,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,dqn,sac,,,
64,Bring Your Own Non-Robust Algorithm to Solve Robust MDPs by Estimating The Worst Kernel.pdf,True,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
65,Offline Transition Modeling via Contrastive Energy Learning.pdf,True,True,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
66,Learning Temporal Distances Contrastive Successor Features Can Provide a Metric Structure for Decisi.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
67,Probabilistic Subgoal Representations for Hierarchical Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,td3,ppo,sac,,,,
68,Feasibility Consistent Representation Learning for Safe Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,td3,dreamer,ppo,sac,,,
69,Agnostic Interactive Imitation Learning New Theory and Practical Algorithms.pdf,True,False,False,2024,icml,icml_2024,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
70,Position TrustLLM Trustworthiness in Large Language Models.pdf,True,True,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
71,FuRL Visual-Language Models as Fuzzy Rewards for Reinforcement Learning.pdf,True,True,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,sac,,,,,,
72,Sample Average Approximation for Conditional Stochastic Optimization with Dependent Data.pdf,False,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
73,Improving Prototypical Visual Explanations with Reward Reweighing Reselection and Retraining.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
74,Run-Time Task Composition with Safety Semantics.pdf,False,False,False,2024,icml,icml_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td3,ppo,,
75,SAM-E Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation.pdf,False,True,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
76,Improving Token-Based World Models with Parallel Observation Prediction.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dreamer,ppo,sac,,,,
77,Reprompting Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,sac,,,,,,
78,Linguistic Calibration of Long-Form Generations.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
79,Non-Asymptotic Analysis for Single-Loop Natural Actor-Critic with Compatible Function Approximation.pdf,False,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
80,Reason for Future Act for Now A Principled Architecture for Autonomous LLM Agents.pdf,True,False,False,2024,icml,icml_2024,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
81,Drug Discovery with Dynamic Goal-aware Fragments.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
82,A Dense Reward View on Aligning Text-to-Image Diffusion with Preference.pdf,True,True,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
83,Multi-Agent Reinforcement Learning Meets Leaf Sequencing in Radiotherapy.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
84,RLVF Learning from Verbal Feedback without Overgeneralization.pdf,False,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,a3c,ppo,,,,,
85,Offline-Boosted Actor-Critic Adaptively Blending Optimal Historical Behaviors in Deep Off-Policy RL.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,sac,td3,td-mpc,ppo,,
86,Principled Preferential Bayesian Optimization.pdf,True,True,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
87,A Neural-Guided Dynamic Symbolic Network for Exploring Mathematical Expressions from Data.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
88,Overestimation Overfitting and Plasticity in Actor-Critic the Bitter Lesson of Reinforcement Learnin.pdf,False,False,False,2024,icml,icml_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,sac,,,,
89,Fundamental Limitations of Alignment in Large Language Models.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
90,Advancing DRL Agents in Commercial Fighting Games Training Integration and Agent-Human Alignment.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
91,Building Socially-Equitable Public Models.pdf,True,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
92,Principled Penalty-based Methods for Bilevel Reinforcement Learning and RLHF.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,a3c,ppo,a2c,,,,
93,Fourier Controller Networks for Real-Time Decision-Making in Embodied Learning.pdf,False,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
94,Chain-of-Thought Predictive Control.pdf,False,True,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
95,Nash Learning from Human Feedback.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
96,QORA Zero-Shot Transfer via Interpretable Object-Relational Model Learning.pdf,True,True,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
97,A Distributional Analogue to the Successor Representation.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
98,Eluder-based Regret for Stochastic Contextual MDPs.pdf,False,False,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,,,,,,
99,Learning Reward for Robot Skills Using Large Language Models via Self-Alignment.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
100,Fine-tuning Reinforcement Learning Models is Secretly a Forgetting Mitigation Problem.pdf,True,True,False,2024,icml,icml_2024,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
101,DiffStitch Boosting Offline Reinforcement Learning with Diffusion-based Trajectory Stitching.pdf,True,False,False,2024,icml,icml_2024,6-10,state-action\s+pairs,,,,,,,td3,ppo,dqn,sac,,,
102,Intersectional Unfairness Discovery.pdf,True,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
103,Stealthy Imitation Reward-guided Environment-free Policy Stealing.pdf,True,False,False,2024,icml,icml_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
104,SceneCraft An LLM Agent for Synthesizing 3D Scenes as Blender Code.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
105,Exploration-Driven Policy Optimization in RLHF Theoretical Insights on Efficient Data Utilization.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
106,rm E3-Equivariant Actor-Critic Methods for Cooperative Multi-Agent Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,ddpg,,,,,
107,PEARL Zero-shot Cross-task Preference Alignment and Robust Reward Learning for Robotic Manipulation.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
108,Implicit Bias of Policy Gradient in Linear Quadratic Control Extrapolation to Unseen Initial States.pdf,True,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
109,More Benefits of Being Distributional Second-Order Bounds for Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
110,Sample-Efficient Robust Multi-Agent Reinforcement Learning in the Face of Environmental Uncertainty.pdf,False,False,False,2024,icml,icml_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
111,Augmenting Decision with Hypothesis in Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,ppo,ddpg,,,,
112,Efficient Value Iteration for s-rectangular Robust Markov Decision Processes.pdf,True,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
113,HarmoDT Harmony Multi-Task Decision Transformer for Offline Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
114,Distributional Bellman Operators over Mean Embeddings.pdf,True,True,False,2024,icml,icml_2024,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
115,OLLIE Imitation Learning from Offline Pretraining to Online Finetuning.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
116,Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
117,PIPER Primitive-Informed Preference-based Hierarchical Reinforcement Learning via Hindsight Relabeli.pdf,False,True,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
118,Causal Action Influence Aware Counterfactual Data Augmentation.pdf,True,True,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,,,,
119,Nesting Particle Filters for Experimental Design in Dynamical Systems.pdf,True,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
120,Investigating Pre-Training Objectives for Generalization in Vision-Based Reinforcement Learning.pdf,False,False,False,2024,icml,icml_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
121,Towards Efficient Exact Optimization of Language Model Alignment.pdf,True,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,a2c,,,,
122,RIME Robust Preference-based Reinforcement Learning with Noisy Preferences.pdf,True,False,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
123,Factored-Reward Bandits with Intermediate Observations.pdf,True,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
124,End-to-End Neuro-Symbolic Reinforcement Learning with Textual Explanations.pdf,False,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a3c,ppo,,,,,
125,When Do Skills Help Reinforcement Learning A Theoretical Analysis of Temporal Abstractions.pdf,True,True,False,2024,icml,icml_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
126,Position Opportunities Exist for Machine Learning in Magnetic Fusion Energy.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
127,Trustworthy Alignment of Retrieval-Augmented Large Language Models via Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
128,On the Hardness of Probabilistic Neurosymbolic Learning.pdf,True,False,False,2024,icml,icml_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
129,SAPG Split and Aggregate Policy Gradients.pdf,False,False,False,2024,icml,icml_2024,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,,,,
130,Online Learning under Budget and ROI Constraints via Weak Adaptivity.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
131,Improving Generalization in Offline Reinforcement Learning via Adversarial Data Splitting.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,dqn,sac,td3,ppo,,
132,Dr Strategy Model-Based Generalist Agents with Strategic Dreaming.pdf,False,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dreamer,,,,,
133,Global Reinforcement Learning  Beyond Linear and Convex Rewards via Submodular Semi-gradient Methods.pdf,False,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
134,Local Feature Selection without Label or Feature Leakage for Interpretable Machine Learning Predicti.pdf,True,False,False,2024,icml,icml_2024,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
135,Preference Fine-Tuning of LLMs Should Leverage Suboptimal On-Policy Data.pdf,True,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
136,Provably Efficient Long-Horizon Exploration in Monte Carlo Tree Search through State Occupancy Regul.pdf,True,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
137,Activation-Descent Regularization for Input Optimization of ReLU Networks.pdf,True,False,False,2024,icml,icml_2024,0,state-action\s+pairs,,,,,,,td3,ppo,sac,ddpg,,,
138,Confronting Reward Overoptimization for Diffusion Models A Perspective of Inductive and Primacy Bias.pdf,True,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
139,EfficientZero V2 Mastering Discrete and Continuous Control with Limited Data.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,td-mpc,dreamer,ppo,sac,,,
140,Planning Fast and Slow Online Reinforcement Learning with Action-Free Offline Data via Multiscale Pl.pdf,True,True,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
141,FESSNC Fast Exponentially Stable and Safe Neural Controller.pdf,True,False,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
142,Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,ddpg,,,,
143,The Max-Min Formulation of Multi-Objective Reinforcement Learning From Theory to a Model-Free Algori.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
144,Stability and Multigroup Fairness in Ranking with Uncertain Predictions.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
145,Agent Instructs Large Language Models to be General Zero-Shot Reasoners.pdf,True,True,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,dreamer,ppo,sac,,,,
146,How Does Goal Relabeling Improve Sample Efficiency.pdf,False,False,False,2024,icml,icml_2024,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
147,Truly No-Regret Learning in Constrained MDPs.pdf,False,False,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
148,Risk-Sensitive Reward-Free Reinforcement Learning with CVaR.pdf,False,False,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
149,Learning Solution-Aware Transformers for Efficiently Solving Quadratic Assignment Problem.pdf,True,False,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,sac,,,,,,
150,EvIL Evolution Strategies for Generalisable Imitation Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
151,Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo.pdf,True,True,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
152,Provably Efficient Reinforcement Learning for Adversarial Restless Multi-Armed Bandits with Unknown .pdf,False,False,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
153,A Minimaximalist Approach to Reinforcement Learning from Human Feedback.pdf,False,False,False,2024,icml,icml_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
154,Embarrassingly Parallel GFlowNets.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
155,Reinformer Max-Return Sequence Modeling for Offline RL.pdf,True,True,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,,,,,,
156,Is Inverse Reinforcement Learning Harder than Standard Reinforcement Learning A Theoretical Perspect.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
157,Position Intent-aligned AI Systems Must Optimize for Agency Preservation.pdf,False,False,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
158,Scalable Safe Policy Improvement for Factored Multi-Agent MDPs.pdf,True,True,False,2024,icml,icml_2024,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
159,Language Models with Conformal Factuality Guarantees.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
160,Learning a Diffusion Model Policy from Rewards via Q-Score Matching.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
161,A Statistical Framework for Data-dependent Retrieval-Augmented Models.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
162,Skill Set Optimization Reinforcing Language Model Behavior via Transferable Skills.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
163,Major-Minor Mean Field Multi-Agent Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,a2c,,,,,
164,On the Second-Order Convergence of Biased Policy Gradient Algorithms.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,ppo,,,,,,
165,Energy-Guided Diffusion Sampling for Offline-to-Online Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
166,Learning Optimal Deterministic Policies with Stochastic Policy Gradients.pdf,True,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
167,Matroid Semi-Bandits in Sublinear Time.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
168,Feedback Efficient Online Fine-Tuning of Diffusion Models.pdf,True,True,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
169,RVI-SAC Average Reward Off-Policy Deep Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,ppo,,
170,Geometric Active Exploration in Markov Decision Processes the Benefit of Abstraction.pdf,False,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
171,Latent Logic Tree Extraction for Event Sequence Explanation from LLMs.pdf,False,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
172,Learning Coverage Paths in Unknown Environments with Deep Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
173,Neural-Kernel Conditional Mean Embeddings.pdf,True,True,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,,,,,,
174,A Primal-Dual Algorithm for Offline Constrained Reinforcement Learning with Linear MDPs.pdf,False,False,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
175,To the Max Reinventing Reward in Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,td3,ppo,sac,,,
176,Policy-conditioned Environment Models are More Generalizable.pdf,True,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
177,Roping in Uncertainty Robustness and Regularization in Markov Games.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
178,Adversarial Attacks on Combinatorial Multi-Armed Bandits.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
179,Reinforcement Learning and Regret Bounds for Admission Control.pdf,True,False,False,2024,icml,icml_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
180,Iterative Data Smoothing Mitigating Reward Overfitting and Overoptimization in RLHF.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
181,Position Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination.pdf,True,True,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
182,Near-Optimal Regret in Linear MDPs with Aggregate Bandit Feedback.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
183,AlphaZero-Like Tree-Search can Guide Large Language Model Decoding and Training.pdf,True,False,False,2024,icml,icml_2024,1-5,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
184,Closing the Gap Achieving Global Convergence Last Iterate of Actor-Critic under Markovian Sampling w.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,ddpg,sac,td3,ppo,,
185,ArCHer Training Language Model Agents via Hierarchical Multi-Turn RL.pdf,True,True,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
186,Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
187,Improving Sample Efficiency of Model-Free Algorithms for Zero-Sum Markov Games.pdf,False,False,False,2024,icml,icml_2024,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
188,Stop Regressing Training Value Functions via Classification for Scalable Deep RL.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,ppo,dqn,,,,,
189,Human Alignment of Large Language Models through Online Preference Optimisation.pdf,False,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
190,Model Alignment as Prospect Theoretic Optimization.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
191,Learning to Reach Goals via Diffusion.pdf,True,False,False,2024,icml,icml_2024,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
192,Provable Risk-Sensitive Distributional Reinforcement Learning with General Function Approximation.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,,,,,ppo,dqn,sac,,,,
193,Failures Are Fated But Can Be Faded Characterizing and Mitigating Unwanted Behaviors in Large-Scale .pdf,True,True,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
194,Zero-Shot Reinforcement Learning via Function Encoders.pdf,True,True,False,2024,icml,icml_2024,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
195,Reward-Free Kernel-Based Reinforcement Learning.pdf,False,False,False,2024,icml,icml_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
196,Understanding Stochastic Natural Gradient Variational Inference.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
197,Detecting Influence Structures in Multi-Agent Reinforcement Learning.pdf,False,True,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
198,Cross-Domain Policy Adaptation by Capturing Representation Mismatch.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
199,How do Large Language Models Navigate Conflicts between Honesty and Helpfulness.pdf,False,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
200,Individual Contributions as Intrinsic Exploration Scaffolds for Multi-agent Reinforcement Learning.pdf,True,True,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
201,Adapting Static Fairness to Sequential Decision-Making Bias Mitigation Strategies towards Equal Long.pdf,True,True,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
202,Safe Reinforcement Learning using Finite-Horizon Gradient-based Estimation.pdf,False,False,False,2024,icml,icml_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
203,Diffusion Model-Augmented Behavioral Cloning.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,a2c,,,,
204,Rate-Optimal Policy Optimization for Linear Markov Decision Processes.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,,,,,,
205,Safe Exploration in Dose Finding Clinical Trials with Heterogeneous Participants.pdf,False,True,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
206,Bayesian Design Principles for Offline-to-Online Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,dqn,,,,,
207,A Hierarchical Adaptive Multi-Task Reinforcement Learning Framework for Multiplier Circuit Design.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
208,From Words to Actions Unveiling the Theoretical Underpinnings of LLM-Driven Autonomous Systems.pdf,False,False,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
209,PlanDQ Hierarchical Plan Orchestration via D-Conductor and Q-Performer.pdf,True,False,False,2024,icml,icml_2024,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
210,Optimistic Multi-Agent Policy Gradient.pdf,True,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,trpo,dqn,ddpg,sac,a2c,ppo,
211,Sequence Compression Speeds Up Credit Assignment in Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,6-10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
212,Model-Free Robust Ï-Divergence Reinforcement Learning Using Both Offline and Online Data.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
213,CHEMREASONER Heuristic Search over a Large Language Models Knowledge Space using Quantum-Chemical Fe.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
214,From Inverse Optimization to Feasibility to ERM.pdf,False,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
215,Online bipartite matching with imperfect advice.pdf,True,True,False,2024,icml,icml_2024,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
216,MusicRL Aligning Music Generation to Human Preferences.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,pets,ppo,sac,,,,
217,PcLast Discovering Plannable Continuous Latent States.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
218,LAGMA LAtent Goal-guided Multi-Agent Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
219,Smooth Tchebycheff Scalarization for Multi-Objective Optimization.pdf,True,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
220,RL-VLM-F Reinforcement Learning from Vision Language Foundation Model Feedback.pdf,False,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
221,Preference Optimization for Molecule Synthesis with Conditional Residual Energy-based Models.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
222,Improving Instruction Following in Language Models through Proxy-Based Uncertainty Estimation.pdf,True,True,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
223,Bayesian Regret Minimization in Offline Bandits.pdf,False,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
224,Compact Optimality Verification for Optimization Proxies.pdf,False,False,False,2024,icml,icml_2024,0,value\s+function\s+approximation,,,,,,,ppo,sac,,,,,
225,ELTA An Enhancer against Long-Tail for Aesthetics-oriented Models.pdf,False,True,False,2024,icml,icml_2024,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
226,Imitation Learning from Purified Demonstrations.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
227,Combining Experimental and Historical Data for Policy Evaluation.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
228,Linear Alignment A Closed-form Solution for Aligning Human Preferences without Tuning and Feedback.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
229,Position Social Environment Design Should be Further Developed for AI-based Policy-Making.pdf,False,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
230,Boosting Reinforcement Learning with Strongly Delayed Feedback Through Auxiliary Short Delays.pdf,True,False,False,2024,icml,icml_2024,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
231,Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption.pdf,False,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
232,Efficient Exploration for LLMs.pdf,False,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
233,In value-based deep reinforcement learning a pruned network is a good network.pdf,True,False,False,2024,icml,icml_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
234,Dealing With Unbounded Gradients in Stochastic Saddle-point Optimization.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
235,Towards General Algorithm Discovery for Combinatorial Optimization Learning Symbolic Branching Polic.pdf,True,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
236,AI Alignment with Changing and Influenceable Reward Functions.pdf,False,False,False,2024,icml,icml_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
237,Is DPO Superior to PPO for LLM Alignment A Comprehensive Study.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
238,Feedback Loops With Language Models Drive In-Context Reward Hacking.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
239,Emergence of In-Context Reinforcement Learning from Noise Distillation.pdf,True,True,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
240,Successor Features for Efficient Multi-Subject Controlled Text Generation.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
241,Constrained Reinforcement Learning Under Model Mismatch.pdf,False,False,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,sac,,,,,,
242,Target Networks and Over-parameterization Stabilize Off-policy Bootstrapping with Function Approxima.pdf,False,True,False,2024,icml,icml_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
243,Position Benchmarking is Limited in Reinforcement Learning Research.pdf,False,False,False,2024,icml,icml_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,,,,,,
244,ReMax A Simple Effective and Efficient Reinforcement Learning Method for Aligning Large Language Mod.pdf,True,True,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
245,Generalization to New Sequential Decision Making Tasks with In-Context Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,dqn,sac,,,
246,Dense Reward for Free in Reinforcement Learning from Human Feedback.pdf,True,False,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
247,Switchable Decision Dynamic Neural Generation Networks.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
248,Tackling Prevalent Conditions in Unsupervised Combinatorial Optimization Cardinality Minimum Coverin.pdf,True,True,False,2024,icml,icml_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
249,Accelerated Policy Gradient for s-rectangular Robust MDPs with Large State Spaces.pdf,True,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
250,Scalable Online Exploration via Coverability.pdf,True,True,False,2024,icml,icml_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
251,Offline Actor-Critic Reinforcement Learning Scales to Large Models.pdf,False,True,False,2024,icml,icml_2024,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
252,RoboGen Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
253,HGCN2SP Hierarchical Graph Convolutional Network for Two-Stage Stochastic Programming.pdf,True,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
254,A General Framework for Sequential Decision-Making under Adaptivity Constraints.pdf,False,False,False,2024,icml,icml_2024,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
255,Expert Proximity as Surrogate Rewards for Single Demonstration Imitation Learning.pdf,True,True,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
256,Incentivized Learning in Principal-Agent Bandit Games.pdf,False,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
257,RICE Breaking Through the Training Bottlenecks of Reinforcement Learning with Explanation.pdf,True,False,False,2024,icml,icml_2024,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
258,Learning Constraints from Offline Demonstrations via Superior Distribution Correction Estimation.pdf,True,False,False,2024,icml,icml_2024,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
259,Fine-Grained Causal Dynamics Learning with Quantization for Improving Robustness in Reinforcement Le.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
260,Revisiting Scalable Hessian Diagonal Approximations for Applications in Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,a2c,,,,,
261,Language-guided Skill Learning with Temporal Variational Inference.pdf,False,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td-mpc,ppo,sac,,,,
262,Multi-View Clustering by Inter-cluster Connectivity Guided Reward.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
263,Quality-Diversity Actor-Critic Learning High-Performing and Diverse Behaviors via Value and Successo.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dreamer,ppo,dqn,sac,,,
264,Quality-Diversity with Limited Resources.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,td3,ppo,dqn,sac,,,
265,Exploration and Anti-Exploration with Distributional Random Network Distillation.pdf,True,False,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
266,Debiased Offline Representation Learning for Fast Online Adaptation in Non-stationary Dynamics.pdf,True,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
267,Learning from Integral Losses in Physics Informed Neural Networks.pdf,True,True,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
268,Single-Trajectory Distributionally Robust Reinforcement Learning.pdf,False,False,False,2024,icml,icml_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
269,An Information Theoretic Approach to Interaction-Grounded Learning.pdf,False,False,False,2024,icml,icml_2024,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
270,Decoding-time Realignment of Language Models.pdf,True,True,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
271,Stochastic Q-learning for Large Discrete Action Spaces.pdf,True,False,False,2024,icml,icml_2024,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
272,Feasible Reachable Policy Iteration.pdf,False,False,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
273,Switching the Loss Reduces the Cost in Batch Reinforcement Learning.pdf,False,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
274,Understanding the Learning Dynamics of Alignment with Human Feedback.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
275,See More Details Efficient Image Super-Resolution by Experts Mining.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
276,How to Explore with Belief State Entropy Maximization in POMDPs.pdf,False,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
277,Best Arm Identification for Stochastic Rising Bandits.pdf,True,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
278,On PI Controllers for Updating Lagrange Multipliers in Constrained Optimization.pdf,True,True,False,2024,icml,icml_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
279,Position Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
280,Random Latent Exploration for Deep Reinforcement Learning.pdf,False,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
281,A Unified Adaptive Testing System Enabled by Hierarchical Structure Search.pdf,True,False,False,2024,icml,icml_2024,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
282,Hybrid Inverse Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,ppo,sac,,,,
283,Active Preference Learning for Large Language Models.pdf,False,True,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
284,Iterative Regularized Policy Optimization with Imperfect Demonstrations.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
285,Pausing Policy Learning in Non-stationary Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
286,Robust Inverse Constrained Reinforcement Learning under Model Misspecification.pdf,True,False,False,2024,icml,icml_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
287,Adaptive Sampling of k-Space in Magnetic Resonance for Rapid Pathology Prediction.pdf,False,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
288,Towards Optimal Adversarial Robust Q-learning with Bellman Infinity-error.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,trpo,ppo,dqn,sac,,,
289,FightLadder A Benchmark for Competitive Multi-Agent Reinforcement Learning.pdf,False,True,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
290,Graphon Mean Field Games with a Representative Player Analysis and Learning Algorithm.pdf,False,False,False,2024,icml,icml_2024,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
291,Combinatorial Multivariant Multi-Armed Bandits with Applications to Episodic Reinforcement Learning .pdf,False,False,False,2024,icml,icml_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
292,Tackling Non-Stationarity in Reinforcement Learning via Causal-Origin Representation.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
293,Momentum for the Win Collaborative Federated Reinforcement Learning across Heterogeneous Environment.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
294,Position Foundation Agents as the Paradigm Shift for Decision Making.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
295,Stochastic Bandits with ReLU Neural Networks.pdf,True,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
296,Graph-Triggered Rising Bandits.pdf,False,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
297,Code as Reward Empowering Reinforcement Learning with VLMs.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
298,Learning Useful Representations of Recurrent Neural Network Weight Matrices.pdf,True,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
299,A Single-Loop Robust Policy Gradient Method for Robust Markov Decision Processes.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,,,,,
300,Accelerated Policy Gradient On the Convergence Rates of the Nesterov Momentum for Reinforcement Lear.pdf,True,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,a2c,,,,
301,From Self-Attention to Markov Models Unveiling the Dynamics of Generative Transformers.pdf,False,False,False,2024,icml,icml_2024,0,value\s+function\s+approximation,,,,,,,ppo,sac,,,,,
302,A Bayesian Approach to Online Planning.pdf,True,True,False,2024,icml,icml_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,sac,,,,,,
303,Resisting Stochastic Risks in Diffusion Planners with the Trajectory Aggregation Tree.pdf,True,False,False,2024,icml,icml_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,sac,,,,,,
304,Towards Global Optimality for Practical Average Reward Reinforcement Learning without Mixing Time Or.pdf,False,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
305,Knowledge-aware Reinforced Language Models for Protein Directed Evolution.pdf,True,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
306,Entropy-Reinforced Planning with Large Language Models for Drug Discovery.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
307,On the Complexity of Finite-Sum Smooth Optimization under the PolyakÅojasiewicz Condition.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
308,Q-value Regularized Transformer for Offline Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,dqn,sac,,,
309,DIDI Diffusion-Guided Diversity for Offline Behavioral Generation.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
310,Ranking-based Client Imitation Selection for Efficient Federated Learning.pdf,False,False,False,2024,icml,icml_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
311,Federated Offline Reinforcement Learning Collaborative Single-Policy Coverage Suffices.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,,,,
312,Imitation Learning in Discounted Linear MDPs without exploration assumptions.pdf,True,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
313,ACPO A Policy Optimization Algorithm for Average MDPs with Constraints.pdf,True,False,False,2024,icml,icml_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
314,Self-Infilling Code Generation.pdf,True,False,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,pets,sac,,,,,
315,Finite-Time Convergence and Sample Complexity of Actor-Critic Multi-Objective Reinforcement Learning.pdf,False,False,False,2024,icml,icml_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,,,ppo,sac,,,,,
316,Adaptive-Gradient Policy Optimization Enhancing Policy Learning in Non-Smooth Differentiable Simulat.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,ppo,sac,,,,
317,ACE Off-Policy Actor-Critic with Causality-Aware Entropy Regularization.pdf,False,True,False,2024,icml,icml_2024,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,td3,ppo,
318,Generalized Preference Optimization A Unified Approach to Offline Alignment.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
319,Model-based Reinforcement Learning for Parameterized Action Spaces.pdf,True,True,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,td3,ppo,,
320,Bayesian Exploration Networks.pdf,False,False,False,2024,icml,icml_2024,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
321,Adaptively Learning to Select-Rank in Online Platforms.pdf,True,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
322,Reward Model Learning vs Direct Policy Optimization A Comparative Analysis of Learning from Human Pr.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
323,Iterative Preference Learning from Human Feedback Bridging Theory and Practice for RLHF under KL-con.pdf,True,True,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
324,Position Scaling Simulation is Neither Necessary Nor Sufficient for In-the-Wild Robot Manipulation.pdf,False,False,False,2024,icml,icml_2024,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,sac,,,,,,
325,DISCRET Synthesizing Faithful Explanations For Treatment Effect Estimation.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
326,Absolute Policy Optimization Enhancing Lower Probability Bound of Performance with High Confidence.pdf,True,True,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,trpo,ppo,sac,a2c,,,
327,GFlowNet Training by Policy Gradients.pdf,True,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,,,,
328,Model-Based RL for Mean-Field Games is not Statistically Harder than Single-Agent RL.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
329,Discovering Multiple Solutions from a Single Task in Offline Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,dqn,,,,,
330,A Contextual Combinatorial Bandit Approach to Negotiation.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
331,Listwise Reward Estimation for Offline Preference-based Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
332,MaxMin-RLHF Alignment with Diverse Human Preferences.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
333,Protein Conformation Generation via Force-Guided SE3 Diffusion Models.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
334,Robust Optimization in Protein Fitness Landscapes Using Reinforcement Learning in Latent Space.pdf,True,True,False,2024,icml,icml_2024,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
335,Position Video as the New Language for Real-World Decision Making.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
336,DistiLLM Towards Streamlined Distillation for Large Language Models.pdf,True,True,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
337,Fair Off-Policy Learning from Observational Data.pdf,True,True,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
338,Reinforcement Learning from Reachability Specifications PAC Guarantees with Expected Conditional Dis.pdf,False,False,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
339,Prompt-based Visual Alignment for Zero-shot Policy Transfer.pdf,False,False,False,2024,icml,icml_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
340,Coactive Learning for Large Language Models using Implicit User Feedback.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
341,Quality Diversity through Human Feedback Towards Open-Ended Diversity-Driven Optimization.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
342,Environment Design for Inverse Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
343,Learning to Scale Logits for Temperature-Conditional GFlowNets.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,sac,,,
344,Simple Ingredients for Offline Reinforcement Learning.pdf,False,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,dqn,sac,,,
345,Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning.pdf,False,False,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,a3c,ppo,sac,ddpg,,,
346,AD3 Implicit Action is the Key for World Models to Distinguish the Diverse Visual Distractors.pdf,False,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dreamer,,,,,
347,Risk-Sensitive Policy Optimization via Predictive CVaR Policy Gradient.pdf,False,False,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,other,,,,,,
348,ReLU to the Rescue Improve Your On-Policy Actor-Critic with Positive Advantages.pdf,True,True,False,2024,icml,icml_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,a3c,dqn,sac,td3,ppo,,
349,Distilling Morphology-Conditioned Hypernetworks for Efficient Universal Morphology Control.pdf,True,True,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
350,Pricing with Contextual Elasticity and Heteroscedastic Valuation.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
351,Reflective Policy Optimization.pdf,True,False,False,2024,icml,icml_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,,,,,
352,DynSyn Dynamical Synergistic Representation for Efficient Learning and Control in Overactuated Embod.pdf,False,False,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
353,Accelerating Look-ahead in Bayesian Optimization Multilevel Monte Carlo is All you Need.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
354,Regularized Q-learning through Robust Averaging.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
355,BRAIn Bayesian Reward-conditioned Amortized Inference for natural language generation from feedback.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
356,ODIN Disentangled Reward Mitigates Hacking in RLHF.pdf,True,True,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,ppo,,,,,
357,Meta-Reinforcement Learning Robust to Distributional Shift Via Performing Lifelong In-Context Learni.pdf,True,True,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
358,Breadth-First Exploration on Adaptive Grid for Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
359,Symmetric Replay Training Enhancing Sample Efficiency in Deep Reinforcement Learning for Combinatori.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,a2c,,,,
360,On The Statistical Complexity of Offline Decision-Making.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,ppo,,,,,,
361,Embodied CoT Distillation From LLM To Off-the-shelf Agents.pdf,True,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
362,Coprocessor Actor Critic A Model-Based Reinforcement Learning Approach For Adaptive Brain Stimulatio.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
363,Revisiting Inexact Fixed-Point Iterations for Min-Max Problems Stochasticity and Structured Nonconve.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
364,Efficient Exploration in Average-Reward Constrained Reinforcement Learning Achieving Near-Optimal Re.pdf,True,False,False,2024,icml,icml_2024,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
365,Learning the Target Network in Function Space.pdf,False,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,,,,,trpo,ppo,dqn,sac,,,
366,NExT Teaching Large Language Models to Reason about Code Execution.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
367,Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe Reinforcement Learnin.pdf,True,False,False,2024,icml,icml_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
368,RLAIF vs RLHF Scaling Reinforcement Learning from Human Feedback with AI Feedback.pdf,False,False,False,2024,icml,icml_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
369,Inferring the Long-Term Causal Effects of Long-Term Treatments from Short-Term Experiments.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
370,Contrastive Representation for Data Filtering in Cross-Domain Offline Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
371,Highway Value Iteration Networks.pdf,True,False,False,2024,icml,icml_2024,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,sac,,,,,,
372,Solving Hierarchical Information-Sharing Dec-POMDPs An Extensive-Form Game Approach.pdf,False,False,False,2024,icml,icml_2024,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,a2c,sac,,,
373,Provable Interactive Learning with Hindsight Instruction Feedback.pdf,False,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
374,Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich Differentiable Simulation.pdf,False,True,False,2024,icml,icml_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
375,Hard Tasks First Multi-Task Reinforcement Learning Through Task Scheduling.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
376,Slow and Steady Wins the Race Maintaining Plasticity with Hare and Tortoise Networks.pdf,True,True,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,td-mpc,ppo,sac,a2c,,,
377,Mean Field Langevin Actor-Critic Faster Convergence and Global Optimality beyond Lazy Learning.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
378,Learning to Stabilize Online Reinforcement Learning in Unbounded State Spaces.pdf,True,True,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
379,BeigeMaps Behavioral Eigenmaps for Reinforcement Learning from Images.pdf,False,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
380,DeepPolar Inventing Nonlinear Large-Kernel Polar Codes via Deep Learning.pdf,True,False,False,2024,icml,icml_2024,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
381,Refining Minimax Regret for Unsupervised Environment Design.pdf,True,True,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
382,Test-Time Regret Minimization in Meta Reinforcement Learning.pdf,False,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,dqn,,,,,
383,HarmonyDream Task Harmonization Inside World Models.pdf,True,True,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,td-mpc,ppo,dreamer,,,,
384,Reward Shaping for Reinforcement Learning with An Assistant Reward Agent.pdf,True,False,False,2024,icml,icml_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,ddpg,sac,td3,ppo,,
385,LLM-Empowered State Representation for Reinforcement Learning.pdf,True,True,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
386,Controlled Decoding from Language Models.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
387,Align Your Steps Optimizing Sampling Schedules in Diffusion Models.pdf,True,False,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
388,Value-Evolutionary-Based Reinforcement Learning.pdf,True,True,False,2024,icml,icml_2024,1-5,value\s+function\s+approximation,,,,,,,td3,ppo,dqn,,,,
389,Provable Representation with Efficient Planning for Partially Observable Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dreamer,ppo,sac,,,,
390,Probabilistic Constrained Reinforcement Learning with Formal Interpretability.pdf,True,True,False,2024,icml,icml_2024,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
391,Fast Peer Adaptation with Context-aware Exploration.pdf,True,False,False,2024,icml,icml_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
392,Stabilizing Policy Gradients for Stochastic Differential Equations via Consistency with Perturbation.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
393,Rich-Observation Reinforcement Learning with Continuous Latent Dynamics.pdf,False,False,False,2024,icml,icml_2024,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,td3,ppo,,,,,
394,Hybrid Reinforcement Learning from Offline Observation Alone.pdf,False,True,False,2024,icml,icml_2024,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
395,Pessimism Meets Risk Risk-Sensitive Offline Reinforcement Learning.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
396,Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching.pdf,True,False,False,2024,icml,icml_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
397,In-Context Decision Transformer Reinforcement Learning via Hierarchical Chain-of-Thought.pdf,False,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,,,,,
398,ReDiffuser Reliable Decision-Making Using a Diffuser with Confidence Estimation.pdf,True,False,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
399,Two-sided Competing Matching Recommendation Markets With Quota and Complementary Preferences Constra.pdf,True,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
400,SeMOPO Learning High-quality Model and Policy from Low-quality Offline Visual Datasets.pdf,False,False,False,2024,icml,icml_2024,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,ppo,dqn,,,,
401,Mixtures of Experts Unlock Parameter Scaling for Deep RL.pdf,True,False,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
402,Generative Marginalization Models.pdf,True,True,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
403,Mimicking Better by Matching the Approximate Action Distribution.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
404,Mollification Effects of Policy Gradient Methods.pdf,False,False,False,2024,icml,icml_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
405,Do Transformer World Models Give Better Policy Gradients.pdf,True,True,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
406,Provably Efficient Exploration in Quantum Reinforcement Learning with Logarithmic Worst-Case Regret.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
407,Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
408,Mastering Zero-Shot Interactions in Cooperative and Competitive Simultaneous Games.pdf,True,True,False,2024,icml,icml_2024,1-5,value\s+function\s+approximation,,,,,,,ppo,sac,,,,,
409,Federated Combinatorial Multi-Agent Multi-Armed Bandits.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
410,Langevin Policy for Safe Reinforcement Learning.pdf,True,True,False,2024,icml,icml_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,,,,,trpo,td3,ppo,dqn,,,
411,OMPO A Unified Framework for RL under Policy and Dynamics Shifts.pdf,True,True,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,td3,ppo,sac,,,
412,Unlock the Cognitive Generalization of Deep Reinforcement Learning via Granular Ball Representation.pdf,True,True,False,2024,icml,icml_2024,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td3,ppo,,
413,An Improved Finite-time Analysis of Temporal Difference Learning with Deep Neural Networks.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,dqn,sac,,,
414,Provably Robust DPO Aligning Language Models with Noisy Feedback.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
415,Seizing Serendipity Exploiting the Value of Past Success in Off-Policy Actor-Critic.pdf,True,True,False,2024,icml,icml_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,dqn,ddpg,sac,td3,ppo,,
416,ATraDiff Accelerating Online Reinforcement Learning with Imaginary Trajectories.pdf,False,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
417,A General Online Algorithm for Optimizing Complex Performance Metrics.pdf,True,False,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
418,Use Your INSTINCT INSTruction optimization for LLMs usIng Neural bandits Coupled with Transformers.pdf,True,True,False,2024,icml,icml_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
419,Offline Inverse RL New Solution Concepts and Provably Efficient Algorithms.pdf,True,False,False,2024,icml,icml_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
420,Near-Optimal Reinforcement Learning with Self-Play under Adaptivity Constraints.pdf,False,False,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
421,A Language Models Guide Through Latent Space.pdf,False,False,False,2024,icml,icml_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
422,Feel-Good Thompson Sampling for Contextual Dueling Bandits.pdf,False,False,False,2024,icml,icml_2024,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
423,Foundation Policies with Hilbert Representations.pdf,True,False,False,2024,icml,icml_2024,6-10,(?:discount|reward)\s+function,,,,,,,td3,,,,,,
424,Risk Estimation in a Markov Cost Process Lower and Upper Bounds.pdf,False,False,False,2024,icml,icml_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
425,SaVeR Optimal Data Collection Strategy for Safe Policy Evaluation in Tabular MDP.pdf,False,False,False,2024,icml,icml_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
426,Subequivariant Reinforcement Learning in 3D Multi-Entity Physical Environments.pdf,True,True,False,2024,icml,icml_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
427,Degeneration-free Policy Optimization RL Fine-Tuning for Language Models without Degeneration.pdf,False,True,False,2024,icml,icml_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,,,,,
428,Adaptive Advantage-Guided Policy Regularization for Offline Reinforcement Learning.pdf,True,False,False,2024,icml,icml_2024,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,dqn,sac,td3,ppo,,
0,Regret bounds for meta Bayesian optimization with an unknown Gaussian process prior.pdf,True,True,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
1,Teaching Inverse Reinforcement Learners via Features and Demonstrations.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
2,Learning Abstract Options.pdf,False,False,False,2018,neurips,neurips_2018,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,a3c,ppo,dqn,sac,,,
3,Non-delusional Q-learning and value-iteration.pdf,False,True,False,2018,neurips,neurips_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
4,Constrained Graph Variational Autoencoders for Molecule Design.pdf,True,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
5,A Lyapunov-based Approach to Safe Reinforcement Learning.pdf,False,True,False,2018,neurips,neurips_2018,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,,,,
6,From Stochastic Planning to Marginal MAP.pdf,False,False,False,2018,neurips,neurips_2018,over 10,action-value\s+function,,,,,,,other,,,,,,
7,On Oracle-Efficient PAC RL with Rich Observations.pdf,True,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
8,Monte-Carlo Tree Search for Constrained POMDPs.pdf,False,False,False,2018,neurips,neurips_2018,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
9,Multi-Agent Generative Adversarial Imitation Learning.pdf,True,False,False,2018,neurips,neurips_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
10,A Bayesian Approach to Generative Adversarial Imitation Learning.pdf,True,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
11,Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
12,Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
13,Learning to Navigate in Cities Without a Map.pdf,True,False,False,2018,neurips,neurips_2018,1-5,(?:discount|reward)\s+function,,,,,,,a3c,ppo,,,,,
14,Contextual Combinatorial Multi-armed Bandits with Volatile Arms and Submodular Reward.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
15,Long short-term memory and Learning-to-learn in networks of spiking neurons.pdf,False,False,False,2018,neurips,neurips_2018,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
16,Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing.pdf,False,False,False,2018,neurips,neurips_2018,over 10,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,,,,,,
17,Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models.pdf,True,False,False,2018,neurips,neurips_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,pets,dqn,ddpg,sac,ppo,,
18,Bayesian Inference of Temporal Task Specifications from Demonstrations.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
19,Playing hard exploration games by watching YouTube.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
20,Online convex optimization for cumulative constraints.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,other,,,,,,
21,Actor-Critic Policy Optimization in Partially Observable Multiagent Environments.pdf,False,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,,,,,,trpo,dqn,a2c,sac,ppo,,
22,Breaking the Curse of Horizon Infinite-Horizon Off-Policy Estimation.pdf,False,False,False,2018,neurips,neurips_2018,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
23,Learning Attentional Communication for Multi-Agent Cooperation.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,dqn,ddpg,,,,,
24,Hierarchical Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies.pdf,False,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
25,Bayesian Control of Large MDPs with Unknown Dynamics in Data-Poor Environments.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
26,Exploration in Structured Reinforcement Learning.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
27,KDGAN Knowledge Distillation with Generative Adversarial Networks.pdf,True,False,False,2018,neurips,neurips_2018,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
28,M-Walk Learning to Walk over Graphs using Monte Carlo Tree Search.pdf,True,True,False,2018,neurips,neurips_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,dqn,,,,,,
29,Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization.pdf,False,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
30,Exponentially Weighted Imitation Learning for Batched Historical Data.pdf,True,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,ddpg,,,
31,Constrained Cross-Entropy Method for Safe Reinforcement Learning.pdf,False,False,False,2018,neurips,neurips_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,trpo,ppo,dqn,sac,,,
32,Learning Safe Policies with Expert Guidance.pdf,False,False,False,2018,neurips,neurips_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
33,Dialog-based Interactive Image Retrieval.pdf,False,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
34,Bandit Learning in Concave N-Person Games.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
35,Occams razor is insufficient to infer the preferences of irrational agents.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
36,Learning Temporal Point Processes via Reinforcement Learning.pdf,True,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
37,Q-learning with Nearest Neighbors.pdf,False,False,False,2018,neurips,neurips_2018,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
38,Online Learning with an Unknown Fairness Metric.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
39,Recurrent World Models Facilitate Policy Evolution.pdf,False,True,False,2018,neurips,neurips_2018,over 10,(?:discount|reward)\s+function,,,,,,,a3c,sac,ddpg,,,,
40,Learning Task Specifications from Demonstrations.pdf,False,False,False,2018,neurips,neurips_2018,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
41,Variational Inference with Tail-adaptive f-Divergence.pdf,True,False,False,2018,neurips,neurips_2018,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,dqn,sac,,,,,
42,Maximum Causal Tsallis Entropy Imitation Learning.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
43,Post Device Placement with Cross-Entropy Minimization and Proximal Policy Optimization.pdf,True,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
44,An Information-Theoretic Analysis for Thompson Sampling with Many Actions.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
45,Re-evaluating evaluation.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
46,Object-Oriented Dynamics Predictor.pdf,True,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
47,A Block Coordinate Ascent Algorithm for Mean-Variance Optimization.pdf,False,True,False,2018,neurips,neurips_2018,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
48,Learning to Teach with Dynamic Loss Functions.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
49,Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of No.pdf,True,False,False,2018,neurips,neurips_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,a3c,ppo,dqn,sac,,,
50,Sequence-to-Segment Networks for Segment Detection.pdf,True,False,False,2018,neurips,neurips_2018,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,sac,,,,,,
51,Learning Others Intentional Models in Multi-Agent Settings Using Interactive POMDPs.pdf,False,False,False,2018,neurips,neurips_2018,1-5,(?:discount|reward)\s+function,,,,,,,other,,,,,,
52,Reinforcement Learning with Multiple Experts A Bayesian Model Combination Approach.pdf,False,False,False,2018,neurips,neurips_2018,over 10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
53,Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion.pdf,True,True,False,2018,neurips,neurips_2018,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,ppo,,
54,Policy Optimization via Importance Sampling.pdf,True,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,trpo,ppo,dqn,ddpg,,,
55,Reward learning from human preferences and demonstrations in Atari.pdf,False,False,False,2018,neurips,neurips_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,a3c,dqn,ddpg,,,,
56,Multiple-Step Greedy Policies in Approximate and Online Reinforcement Learning.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
57,Credit Assignment For Collective Multiagent RL With Global Rewards.pdf,False,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,other,,,,,,
58,Genetic-Gated Networks for Deep Reinforcement Learning.pdf,False,False,False,2018,neurips,neurips_2018,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,a3c,ppo,dqn,a2c,,,
59,Multi-Task Learning as Multi-Objective Optimization.pdf,False,True,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
60,Loss Functions for Multiset Prediction.pdf,False,False,False,2018,neurips,neurips_2018,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,,,,,,
61,DeepExposure Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning.pdf,False,False,False,2018,neurips,neurips_2018,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,sac,a2c,,,,,
62,Unsupervised Video Object Segmentation for Deep Reinforcement Learning.pdf,True,False,False,2018,neurips,neurips_2018,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,a2c,,,,,
63,Online Robust Policy Learning in the Presence of Unknown Adversaries.pdf,True,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
64,Visual Reinforcement Learning with Imagined Goals.pdf,False,False,False,2018,neurips,neurips_2018,1-5,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),(?:discount|reward)\s+function,,,,,,td3,dqn,ddpg,,,,
65,Generalisation of structural knowledge in the hippocampal-entorhinal system.pdf,False,False,False,2018,neurips,neurips_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
66,Fast deep reinforcement learning using online adjustments from the past.pdf,True,False,False,2018,neurips,neurips_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,,,,,ppo,dqn,,,,,
67,Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes.pdf,False,False,False,2018,neurips,neurips_2018,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
68,Active Matting.pdf,False,False,False,2018,neurips,neurips_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
69,Learn What Not to Learn Action Elimination with Deep Reinforcement Learning.pdf,True,True,False,2018,neurips,neurips_2018,1-5,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,dqn,,,,,,
70,Deep Generative Models with Learnable Knowledge Constraints.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
71,Data-Efficient Hierarchical Reinforcement Learning.pdf,True,False,False,2018,neurips,neurips_2018,6-10,(?:discount|reward)\s+function,,,,,,,td3,ddpg,,,,,
72,Verifiable Reinforcement Learning via Policy Extraction.pdf,False,False,False,2018,neurips,neurips_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,dqn,sac,,,,
73,Community Exploration From Offline Optimization to Online Learning.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
74,Total stochastic gradient algorithms and applications in reinforcement learning.pdf,False,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
75,Bandit Learning with Implicit Feedback.pdf,True,False,False,2018,neurips,neurips_2018,over 10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
76,Inequity aversion improves cooperation in intertemporal social dilemmas.pdf,False,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,a3c,ppo,a2c,,,,
77,Diversity-Driven Exploration Strategy for Deep Reinforcement Learning.pdf,True,False,False,2018,neurips,neurips_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,dqn,ddpg,a2c,,,,
78,Context-dependent upper-confidence bounds for directed exploration.pdf,False,False,False,2018,neurips,neurips_2018,over 10,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,other,,,,,,
79,Differentiable MPC for End-to-end Planning and Control.pdf,True,False,False,2018,neurips,neurips_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,ppo,dqn,sac,,,
80,Evolved Policy Gradients.pdf,True,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,,,,
81,Evolution-Guided Policy Gradient in Reinforcement Learning.pdf,True,False,False,2018,neurips,neurips_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,ddpg,,,,
82,An Off-policy Policy Gradient Theorem Using Emphatic Weightings.pdf,False,False,False,2018,neurips,neurips_2018,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,sac,,,,,
83,Geometry-Aware Recurrent Neural Networks for Active Visual Recognition.pdf,False,False,False,2018,neurips,neurips_2018,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
84,Speaker-Follower Models for Vision-and-Language Navigation.pdf,False,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
85,On Learning Intrinsic Rewards for Policy Gradient Methods.pdf,True,False,False,2018,neurips,neurips_2018,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,a2c,,,,,
86,Fighting Boredom in Recommender Systems with Linear Reinforcement Learning.pdf,False,False,False,2018,neurips,neurips_2018,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
87,Scalable Coordinated Exploration in Concurrent Reinforcement Learning.pdf,False,False,False,2018,neurips,neurips_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,value\s+function\s+approximation,,,,,,ppo,,,,,,
88,Synthesized Policies for Transfer and Adaptation across Tasks and Environments.pdf,True,False,False,2018,neurips,neurips_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
89,How Does Batch Normalization Help Optimization.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
90,Reinforcement Learning for Solving the Vehicle Routing Problem.pdf,True,False,False,2018,neurips,neurips_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,ppo,dqn,,,,,
91,Lifelong Inverse Reinforcement Learning.pdf,False,False,False,2018,neurips,neurips_2018,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
92,Faster Online Learning of Optimal Threshold for Consistent F-measure Optimization.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
93,Deep Reinforcement Learning of Marked Temporal Point Processes.pdf,True,False,False,2018,neurips,neurips_2018,0,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,other,,,,,,
94,Continuous-time Value Function Approximation in Reproducing Kernel Hilbert Spaces.pdf,True,False,False,2018,neurips,neurips_2018,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
95,Learning to Share and Hide Intentions using Information Regularization.pdf,True,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
96,Temporal Regularization for Markov Decision Process.pdf,True,False,False,2018,neurips,neurips_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
97,Iterative Value-Aware Model Learning.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
98,Scalar Posterior Sampling with Applications.pdf,False,False,False,2018,neurips,neurips_2018,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
99,Data center cooling using model-predictive control.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
100,Meta-Reinforcement Learning of Structured Exploration Strategies.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,trpo,,,,,,
101,Learning to Play With Intrinsically-Motivated Self-Aware Agents.pdf,False,False,False,2018,neurips,neurips_2018,0,action-value\s+function,,,,,,,ppo,,,,,,
102,Learning in Games with Lossy Feedback.pdf,False,False,False,2018,neurips,neurips_2018,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
103,Pipe-SGD A Decentralized Pipelined SGD Framework for Distributed Deep Net Training.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
104,Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation.pdf,True,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
105,Variational Inverse Control with Events A General Framework for Data-Driven Reward Definition.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
106,Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation.pdf,True,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
107,Learning Loop Invariants for Program Verification.pdf,True,False,False,2018,neurips,neurips_2018,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
108,Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization.pdf,False,False,False,2018,neurips,neurips_2018,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
109,Hardware Conditioned Policies for Multi-Robot Transfer Learning.pdf,False,False,False,2018,neurips,neurips_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,ddpg,,,,
110,Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator.pdf,False,False,False,2018,neurips,neurips_2018,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
111,Transfer of Deep Reactive Policies for MDP Planning.pdf,True,False,False,2018,neurips,neurips_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,a3c,a2c,,,,,
112,Is Q-Learning Provably Efficient.pdf,False,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,a3c,ppo,dqn,,,
113,Randomized Prior Functions for Deep Reinforcement Learning.pdf,False,True,False,2018,neurips,neurips_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
114,Simple random search of static linear policies is competitive for reinforcement learning.pdf,False,True,False,2018,neurips,neurips_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,a2c,ppo,
115,Adversarially Robust Optimization with Gaussian Processes.pdf,True,True,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
116,Near Optimal Exploration-Exploitation in Non-Communicating Markov Decision Processes.pdf,False,False,False,2018,neurips,neurips_2018,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,,,,,,
117,A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
118,Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies.pdf,True,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
119,Distributed Multitask Reinforcement Learning with Quadratic Convergence.pdf,False,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
120,Where Do You Think Youre Going Inferring Beliefs about Dynamics from Behavior.pdf,False,False,False,2018,neurips,neurips_2018,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
121,End-to-End Differentiable Physics for Learning and Control.pdf,True,False,False,2018,neurips,neurips_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
122,REFUEL Exploring Sparse Features in Deep Reinforcement Learning for Fast Disease Diagnosis.pdf,False,False,False,2018,neurips,neurips_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
123,Geometrically Coupled Monte Carlo Sampling.pdf,False,True,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
124,Learning convex bounds for linear quadratic control policy synthesis.pdf,False,False,False,2018,neurips,neurips_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
125,Reinforced Continual Learning.pdf,False,True,False,2018,neurips,neurips_2018,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,other,,,,,,
126,Learning to Optimize Tensor Programs.pdf,False,True,False,2018,neurips,neurips_2018,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
127,Learning Plannable Representations with Causal InfoGAN.pdf,True,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
128,Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing.pdf,False,True,False,2018,neurips,neurips_2018,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
129,Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search.pdf,False,False,False,2018,neurips,neurips_2018,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,sac,,,,,
130,Training Neural Networks Using Features Replay.pdf,True,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
131,Meta-Gradient Reinforcement Learning.pdf,False,True,False,2018,neurips,neurips_2018,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,a3c,dqn,a2c,,,,
132,Transfer Learning with Neural AutoML.pdf,False,True,False,2018,neurips,neurips_2018,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,,,,,
133,The Importance of Sampling inMeta-Reinforcement Learning.pdf,True,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,,,,
134,Transfer of Value Functions via Variational Methods.pdf,False,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
135,Factored Bandits.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
136,LF-Net Learning Local Features from Images.pdf,True,False,False,2018,neurips,neurips_2018,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
137,rho-POMDPs have Lipschitz-Continuous epsilon-Optimal Value Functions.pdf,True,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
138,Negotiable Reinforcement Learning for Pareto Optimal Sequential Decision-Making.pdf,False,False,False,2018,neurips,neurips_2018,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
139,Unsupervised Text Style Transfer using Language Models as Discriminators.pdf,True,False,False,2018,neurips,neurips_2018,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
0,No-Regret Learning in Unknown Games with Correlated Payoffs.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
1,Variance Reduced Policy Evaluation with Smooth Function Approximation.pdf,False,False,False,2019,neurips,neurips_2019,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
2,Importance Resampling for Off-policy Prediction.pdf,False,False,False,2019,neurips,neurips_2019,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,ppo,sac,,,,,
3,A Structured Prediction Approach for Generalization in Cooperative Multi-Agent Reinforcement Learnin.pdf,False,False,False,2019,neurips,neurips_2019,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
4,Learning Local Search Heuristics for Boolean Satisfiability.pdf,True,True,False,2019,neurips,neurips_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,,,,,,
5,Privacy-Preserving Q-Learning with Functional Noise in Continuous Spaces.pdf,False,False,False,2019,neurips,neurips_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
6,Policy Learning for Fairness in Ranking.pdf,False,True,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
7,Approximation Ratios of Graph Neural Networks for Combinatorial Problems.pdf,False,False,False,2019,neurips,neurips_2019,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,,,,,,,ppo,,,,,,
8,LiteEval A Coarse-to-Fine Framework for Resource Efficient Video Recognition.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,pets,,,,,,
9,Modeling Conceptual Understanding in Image Reference Games.pdf,True,False,False,2019,neurips,neurips_2019,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
10,Real-Time Reinforcement Learning.pdf,True,False,False,2019,neurips,neurips_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,sac,,,,,,
11,A Unified Bellman Optimality Principle Combining Reward Maximization and Empowerment.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
12,A Bayesian Theory of Conformity in Collective Decision Making.pdf,False,True,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
13,Multi-View Reinforcement Learning.pdf,True,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
14,The Option Keyboard Combining Skills in Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,dqn,,,,,
15,Unsupervised learning of object structure and dynamics from videos.pdf,False,True,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
16,Imitation-Projected Programmatic Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,ddpg,,,,
17,Solving a Class of Non-Convex Min-Max Games Using Iterative First Order Methods.pdf,False,False,False,2019,neurips,neurips_2019,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
18,Sampling Networks and Aggregate Simulation for Online POMDP Planning.pdf,True,False,False,2019,neurips,neurips_2019,over 10,action-value\s+function,,,,,,,ppo,,,,,,
19,PHYRE A New Benchmark for Physical Reasoning.pdf,True,True,False,2019,neurips,neurips_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,,,,,,
20,On the Utility of Learning about Humans for Human-AI Coordination.pdf,True,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
21,From Complexity to Simplicity Adaptive ES-Active Subspaces for Blackbox Optimization.pdf,True,True,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,,,,,
22,Planning in entropy-regularized Markov decision processes and games.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,a3c,ppo,sac,,,
23,Unsupervised Learning of Object Keypoints for Perception and Control.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
24,Policy Poisoning in Batch Reinforcement Learning and Control.pdf,True,False,False,2019,neurips,neurips_2019,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,other,,,,,,
25,Trust Region-Guided Proximal Policy Optimization.pdf,True,False,False,2019,neurips,neurips_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
26,Unsupervised Meta-Learning for Few-Shot Image Classification.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
27,A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,ppo,dqn,,,,
28,Value Function in Frequency Domain and the Characteristic Value Iteration Algorithm.pdf,False,False,False,2019,neurips,neurips_2019,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
29,Limiting Extrapolation in Linear Approximate Value Iteration.pdf,False,False,False,2019,neurips,neurips_2019,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,,,,,ppo,dqn,,,,,
30,Near-Optimal Reinforcement Learning in Dynamic Treatment Regimes.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
31,Saccader Improving Accuracy of Hard Attention Models for Vision.pdf,True,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,sac,,,,,,
32,Exploration Bonus for Regret Minimization in Discrete and Continuous Average Reward MDPs.pdf,False,False,False,2019,neurips,neurips_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
33,Mo States Mo Problems Emergency Stop Mechanisms from Observation.pdf,True,False,False,2019,neurips,neurips_2019,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,,,,
34,Recovering Bandits.pdf,True,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
35,Learning to Predict Without Looking Ahead World Models Without Forward Prediction.pdf,True,False,False,2019,neurips,neurips_2019,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,,,,,,
36,DetNAS Backbone Search for Object Detection.pdf,True,True,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
37,Game Design for Eliciting Distinguishable Behavior.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
38,Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction.pdf,False,False,False,2019,neurips,neurips_2019,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,,,,
39,Learning Generalizable Device Placement Algorithms for Distributed Machine Learning.pdf,True,False,False,2019,neurips,neurips_2019,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
40,Learning to Confuse Generating Training Time Adversarial Data with Auto-Encoder.pdf,False,False,False,2019,neurips,neurips_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,,,,,,
41,Addressing Sample Complexity in Visual Tasks Using HER and Hallucinatory GANs.pdf,True,True,False,2019,neurips,neurips_2019,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,pets,dqn,ddpg,,,,
42,Compiler Auto-Vectorization with Imitation Learning.pdf,False,False,False,2019,neurips,neurips_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
43,Exploration via Hindsight Goal Generation.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,,,,
44,Using a Logarithmic Mapping to Enable Lower Discount Factors in Reinforcement Learning.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
45,Information-Theoretic Confidence Bounds for Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
46,Beyond Confidence Regions Tight Bayesian Ambiguity Sets for Robust MDPs.pdf,False,False,False,2019,neurips,neurips_2019,0,value\s+function\s+approximation,,,,,,,ppo,,,,,,
47,XNAS Neural Architecture Search with Expert Advice.pdf,True,True,False,2019,neurips,neurips_2019,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
48,Polynomial Cost of Adaptation for X-Armed Bandits.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
49,Learning low-dimensional state embeddings and metastable clusters from time series data.pdf,False,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
50,Robust Multi-agent Counterfactual Prediction.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
51,Two Time-scale Off-Policy TD Learning Non-asymptotic Analysis over Markovian Samples.pdf,False,True,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
52,Learning from Trajectories via Subgoal Discovery.pdf,False,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,a3c,ppo,,,,,
53,Certainty Equivalence is Efficient for Linear Quadratic Control.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
54,Distributional Reward Decomposition for Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
55,Finite-Sample Analysis for SARSA with Linear Function Approximation.pdf,False,False,False,2019,neurips,neurips_2019,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
56,Reinforcement Learning with Convex Constraints.pdf,False,False,False,2019,neurips,neurips_2019,over 10,(?:discount|reward)\s+function,,,,,,,ppo,a2c,,,,,
57,Provably Global Convergence of Actor-Critic A Case for Linear Quadratic Regulator with Ergodic Cost.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,,,,,other,,,,,,
58,Linear Stochastic Bandits Under Safety Constraints.pdf,False,True,False,2019,neurips,neurips_2019,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
59,Write Execute Assess Program Synthesis with a REPL.pdf,False,False,False,2019,neurips,neurips_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
60,Machine Teaching of Active Sequential Learners.pdf,True,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
61,Combinatorial Inference against Label Noise.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
62,Discovery of Useful Questions as Auxiliary Tasks.pdf,False,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
63,Towards Interpretable Reinforcement Learning Using Attention Augmented Agents.pdf,False,False,False,2019,neurips,neurips_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,other,,,,,,
64,Learning Data Manipulation for Augmentation and Weighting.pdf,True,False,False,2019,neurips,neurips_2019,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
65,Fully Parameterized Quantile Function for Distributional Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
66,Towards Optimal Off-Policy Evaluation for Reinforcement Learning with Marginalized Importance Sampli.pdf,False,False,False,2019,neurips,neurips_2019,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
67,Exact Combinatorial Optimization with Graph Convolutional Neural Networks.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
68,Policy Optimization Provably Converges to Nash Equilibria in Zero-Sum Linear Quadratic Games.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,,,,,,ppo,dqn,,,,,
69,DAC The Double Actor-Critic Architecture for Learning Options.pdf,True,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,a2c,sac,,,
70,Regularized Anderson Acceleration for Off-Policy Deep Reinforcement Learning.pdf,True,True,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,td3,dqn,sac,,,,
71,Large Scale Markov Decision Processes with Changing Rewards.pdf,False,False,False,2019,neurips,neurips_2019,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
72,Selecting Optimal Decisions via Distributionally Robust Nearest-Neighbor Regression.pdf,False,True,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
73,Almost Horizon-Free Structure-Aware Best Policy Identification with a Generative Model.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,,,,,ppo,sac,,,,,
74,MaxGap Bandit Adaptive Algorithms for Approximate Ranking.pdf,True,False,False,2019,neurips,neurips_2019,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
75,A Model-Based Reinforcement Learning with Adversarial Training for Online Recommendation.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,dqn,,,,,
76,Stochastic Bandits with Context Distributions.pdf,False,True,False,2019,neurips,neurips_2019,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
77,Correlation Priors for Reinforcement Learning.pdf,False,True,False,2019,neurips,neurips_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
78,Goal-conditioned Imitation Learning.pdf,False,False,False,2019,neurips,neurips_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ddpg,,,,,
79,Multi-Agent Common Knowledge Reinforcement Learning.pdf,True,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,dqn,sac,,,,
80,Imitation Learning from Observations by Minimizing Inverse Dynamics Disagreement.pdf,False,True,False,2019,neurips,neurips_2019,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
81,Code Generation as a Dual Task of Code Summarization.pdf,True,False,False,2019,neurips,neurips_2019,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,sac,,,,,,
82,Park An Open Platform for Learning-Augmented Computer Systems.pdf,True,True,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,other,,,,,,
83,Learner-aware Teaching Inverse Reinforcement Learning with Preferences and Constraints.pdf,False,False,False,2019,neurips,neurips_2019,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
84,Differentiable Cloth Simulation for Inverse Problems.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
85,Censored Semi-Bandits A Framework for Resource Allocation with Censored Feedback.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
86,Better Exploration with Optimistic Actor Critic.pdf,False,True,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,,,,dqn,ddpg,sac,td3,ppo,,
87,Learning dynamic polynomial proofs.pdf,False,False,False,2019,neurips,neurips_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,ppo,dqn,sac,,,,
88,Offline Contextual Bandits with High Probability Fairness Guarantees.pdf,True,False,False,2019,neurips,neurips_2019,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
89,Planning with Goal-Conditioned Policies.pdf,True,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,pets,ppo,dqn,,,,
90,Neural Shuffle-Exchange Networks - Sequence Processing in On log n Time.pdf,True,False,False,2019,neurips,neurips_2019,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
91,Experience Replay for Continual Learning.pdf,False,False,False,2019,neurips,neurips_2019,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,dqn,sac,,,,
92,Non-Cooperative Inverse Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
93,Offline Contextual Bayesian Optimization.pdf,True,True,False,2019,neurips,neurips_2019,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
94,Logarithmic Regret for Online Control.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
95,Learning-In-The-Loop Optimization End-To-End Control And Co-Design Of Soft Robots Through Learned De.pdf,False,True,False,2019,neurips,neurips_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
96,Guided Meta-Policy Search.pdf,False,False,False,2019,neurips,neurips_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
97,Personalizing Many Decisions with High-Dimensional Covariates.pdf,False,False,False,2019,neurips,neurips_2019,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
98,A Kernel Loss for Solving the Bellman Equation.pdf,False,True,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,,,,,,ppo,dqn,,,,,
99,Explicit Explore-Exploit Algorithms in Continuous State Spaces.pdf,True,False,False,2019,neurips,neurips_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
100,Neural Trust RegionProximal Policy Optimization Attains Globally Optimal Policy.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
101,LIIR Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning.pdf,True,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
102,Generalization in Reinforcement Learning with Selective Noise Injection and Information Bottleneck.pdf,True,False,False,2019,neurips,neurips_2019,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,a2c,,,,
103,Learning to Perform Local Rewriting for Combinatorial Optimization.pdf,True,False,False,2019,neurips,neurips_2019,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,a2c,,,,,
104,Generalized Off-Policy Actor-Critic.pdf,True,False,False,2019,neurips,neurips_2019,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,dqn,ddpg,a2c,sac,td3,,
105,Online Markov Decoding Lower Bounds and Near-Optimal Approximation Algorithms.pdf,False,True,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
106,Better Transfer Learning with Inferred Successor Maps.pdf,False,False,False,2019,neurips,neurips_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
107,Convergent Policy Optimization for Safe Reinforcement Learning.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,trpo,,,,,,
108,No Pressure Addressing the Problem of Local Minima in Manifold Learning Algorithms.pdf,False,False,False,2019,neurips,neurips_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
109,Propagating Uncertainty in Reinforcement Learning via Wasserstein Barycenters.pdf,True,False,False,2019,neurips,neurips_2019,6-10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
110,No-Press Diplomacy Modeling Multi-Agent Gameplay.pdf,True,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,a2c,,,,,
111,Hierarchical Reinforcement Learning with Advantage-Based Auxiliary Rewards.pdf,True,False,False,2019,neurips,neurips_2019,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,trpo,,,,,,
112,A Family of Robust Stochastic Operators for Reinforcement Learning.pdf,True,False,False,2019,neurips,neurips_2019,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
113,Meta-Inverse Reinforcement Learning with Probabilistic Context Variables.pdf,True,False,False,2019,neurips,neurips_2019,1-5,(?:discount|reward)\s+function,,,,,,,trpo,,,,,,
114,Adaptive Temporal-Difference Learning for Policy Evaluation with Per-State Uncertainty Estimates.pdf,False,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,,,,,,ppo,dqn,,,,,
115,A Meta-MDP Approach to Exploration for Lifelong Reinforcement Learning.pdf,True,False,False,2019,neurips,neurips_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
116,Nonparametric Contextual Bandits in Metric Spaces with Unknown Metric.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
117,Distributional Policy Optimization An Alternative Approach for Continuous Control.pdf,True,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
118,Search on the Replay Buffer Bridging Planning and Reinforcement Learning.pdf,False,True,False,2019,neurips,neurips_2019,1-5,(?:discount|reward)\s+function,,,,,,,trpo,dqn,sac,,,,
119,Non-Asymptotic Gap-Dependent Regret Bounds for Tabular MDPs.pdf,False,False,False,2019,neurips,neurips_2019,0,state-action\s+pairs,,,,,,,other,,,,,,
120,RUDDER Return Decomposition for Delayed Rewards.pdf,True,False,False,2019,neurips,neurips_2019,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,,,,ppo,dqn,,,,,
121,A Regularized Approach to Sparse Optimal Policy in Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
122,Divergence-Augmented Policy Optimization.pdf,False,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
123,Drill-down Interactive Retrieval of Complex Scenes using Natural Language Queries.pdf,True,False,False,2019,neurips,neurips_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
124,Text-Based Interactive Recommendation via Constraint-Augmented Reinforcement Learning.pdf,True,False,False,2019,neurips,neurips_2019,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
125,When to Trust Your Model Model-Based Policy Optimization.pdf,False,True,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
126,Implicit Posterior Variational Inference for Deep Gaussian Processes.pdf,True,True,False,2019,neurips,neurips_2019,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
127,Fast Efficient Hyperparameter Tuning for Policy Gradient Methods.pdf,True,True,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,a2c,,,,,
128,Unsupervised Curricula for Visual Meta-Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
129,Multiagent Evaluation under Incomplete Information.pdf,False,False,False,2019,neurips,neurips_2019,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,sac,,,,,,
130,Random deep neural networks are biased towards simple functions.pdf,False,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
131,Keeping Your Distance Solving Sparse Reward Tasks Using Self-Balancing Shaped Rewards.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,ddpg,a2c,,,,
132,Likelihood Ratios for Out-of-Distribution Detection.pdf,True,True,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
133,Hindsight Credit Assignment.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
134,SMILe Scalable Meta Inverse Reinforcement Learning through Context-Conditional Policies.pdf,True,False,False,2019,neurips,neurips_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,sac,,,,,,
135,Search-Guided Lightly-Supervised Training of Structured Prediction Energy Networks.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,sac,,,,,,
136,Regret Minimization for Reinforcement Learning by Evaluating the Optimal Bias Function.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
137,Mapping State Space using Landmarks for Universal Goal Reaching.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,,,,
138,Gossip-based Actor-Learner Architectures for Deep Reinforcement Learning.pdf,True,False,False,2019,neurips,neurips_2019,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,a3c,ppo,a2c,,,,
139,Maximum Entropy Monte-Carlo Planning.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
140,Reconciling Î»-Returns with Experience Replay.pdf,False,False,False,2019,neurips,neurips_2019,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
141,Approximating Interactive Human Evaluation with Self-Play for Open-Domain Dialog Systems.pdf,True,True,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
142,MCP Learning Composable Hierarchical Control with Multiplicative Compositional Policies.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
143,Budgeted Reinforcement Learning in Continuous State Space.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,,,,,,
144,Robust exploration in linear quadratic reinforcement learning.pdf,False,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,other,,,,,,
145,A neurally plausible model learns successor representations in partially observable environments.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
146,Sample-Efficient Deep Reinforcement Learning via Episodic Backward Update.pdf,True,True,False,2019,neurips,neurips_2019,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
147,Regularizing Trajectory Optimization with Denoising Autoencoders.pdf,False,True,False,2019,neurips,neurips_2019,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,pets,,,,
148,Non-Stationary Markov Decision Processes a Worst-Case Approach using Model-Based Reinforcement Learn.pdf,True,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
149,Learning Transferable Graph Exploration.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,dqn,a2c,,,,,
150,NAT Neural Architecture Transformer for Accurate and Compact Architectures.pdf,True,True,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
151,Reducing the variance in online optimization by transporting past gradients.pdf,True,False,False,2019,neurips,neurips_2019,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
152,Bayesian Optimization under Heavy-tailed Payoffs.pdf,False,True,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
153,Third-Person Visual Imitation Learning via Decoupled Hierarchical Controller.pdf,False,False,False,2019,neurips,neurips_2019,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
154,Adaptive Auxiliary Task Weighting for Reinforcement Learning.pdf,False,True,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ddpg,a2c,,,,,
155,VIREL A Variational Inference Framework for Reinforcement Learning.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,a3c,dqn,ddpg,sac,ppo,,
156,Levenshtein Transformer.pdf,True,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
157,A Geometric Perspective on Optimal Representations for Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,a3c,ppo,dqn,a2c,,,
158,Learning to Control Self-Assembling Morphologies A Study of Generalization via Modularity.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
159,Provably Efficient Q-learning with Function Approximation via Distribution Shift Error Checking Orac.pdf,False,False,False,2019,neurips,neurips_2019,0,state-action\s+pairs,,,,,,,dqn,,,,,,
160,Unsupervised State Representation Learning in Atari.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
161,Neural Lyapunov Control.pdf,False,True,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
162,When to use parametric models in reinforcement learning.pdf,False,False,False,2019,neurips,neurips_2019,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,,,,ppo,dqn,sac,,,,
163,Low-Rank Bandit Methods for High-Dimensional Dynamic Pricing.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
164,Learning Compositional Neural Programs with Recursive Tree Search and Planning.pdf,True,False,False,2019,neurips,neurips_2019,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,action-value\s+function,,,,,,other,,,,,,
165,Finite-Time Performance Bounds and Adaptive Learning Rate Selection for Two Time-Scale Reinforcement.pdf,False,True,False,2019,neurips,neurips_2019,over 10,value\s+function\s+approximation,,,,,,,ppo,,,,,,
166,Deep Signature Transforms.pdf,True,False,False,2019,neurips,neurips_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
167,Optimal Best Markovian Arm Identification with Fixed Confidence.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
168,Convolution with even-sized kernels and symmetric padding.pdf,True,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
169,Explicit Planning for Efficient Exploration in Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
170,Regret Minimization for Reinforcement Learning with Vectorial Feedback and Complex Objectives.pdf,False,False,False,2019,neurips,neurips_2019,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
171,Learning Mean-Field Games.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,a2c,,,,
172,Neural Temporal-Difference Learning Converges to Global Optima.pdf,False,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,,,,,dqn,,,,,,
173,Policy Continuation with Hindsight Inverse Dynamics.pdf,True,True,False,2019,neurips,neurips_2019,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
174,Learning Robust Options by Conditional Value at Risk Optimization.pdf,True,False,False,2019,neurips,neurips_2019,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
175,Learning Latent Process from High-Dimensional Event Sequences via Efficient Sampling.pdf,True,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
176,Maximum Expected Hitting Cost of a Markov Decision Process and Informativeness of Rewards.pdf,False,False,False,2019,neurips,neurips_2019,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
177,Bias Correction of Learned Generative Models using Likelihood-Free Importance Weighting.pdf,False,False,False,2019,neurips,neurips_2019,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
178,MAVEN Multi-Agent Variational Exploration.pdf,False,True,False,2019,neurips,neurips_2019,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
179,Value Propagation for Decentralized Networked Deep Multi-agent  Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
180,Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy Policies.pdf,False,False,False,2019,neurips,neurips_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,,,,,,
181,Curriculum-guided Hindsight Experience Replay.pdf,True,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ddpg,,,,,,
182,Constrained Reinforcement Learning Has Zero Duality Gap.pdf,False,True,False,2019,neurips,neurips_2019,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
183,DualDICE Behavior-Agnostic Estimation of Discounted Stationary Distribution Corrections.pdf,True,False,False,2019,neurips,neurips_2019,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
184,Successor Uncertainties Exploration and Uncertainty in Temporal Difference Learning.pdf,False,False,False,2019,neurips,neurips_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,,,,,ppo,dqn,sac,,,,
185,Finite-time Analysis of Approximate Policy Iteration for the Linear Quadratic Regulator.pdf,False,True,False,2019,neurips,neurips_2019,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,,,,,
186,Learning by Abstraction The Neural State Machine.pdf,False,False,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
187,Compositional Plan Vectors.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
188,On the Correctness and Sample Complexity of Inverse Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
189,Causal Confusion in Imitation Learning.pdf,False,False,False,2019,neurips,neurips_2019,1-5,state-action\s+pairs,,,,,,,other,,,,,,
190,Weight Agnostic Neural Networks.pdf,True,True,False,2019,neurips,neurips_2019,over 10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
191,Meta-Learning Representations for Continual Learning.pdf,True,True,False,2019,neurips,neurips_2019,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,sac,,,,,
192,Off-Policy Evaluation via Off-Policy Classification.pdf,True,True,False,2019,neurips,neurips_2019,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
193,Language as an Abstraction for Hierarchical Deep Reinforcement Learning.pdf,False,False,False,2019,neurips,neurips_2019,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
0,On Reward-Free Reinforcement Learning with Linear Function Approximation.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
1,Autofocused oracles for model-based design.pdf,True,False,False,2020,neurips,neurips_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
2,Learning to Decode Reinforcement Learning for Decoding of Sparse Graph-Based Channel Codes.pdf,False,False,False,2020,neurips,neurips_2020,0,action-value\s+function,,,,,,,ppo,dqn,sac,,,,
3,Influence-Augmented Online Planning for Complex Environments.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
4,Differentiable Meta-Learning of Bandit Policies.pdf,True,False,False,2020,neurips,neurips_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
5,Sample Efficient Reinforcement Learning via Low-Rank Matrix Estimation.pdf,False,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
6,Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model.pdf,False,False,False,2020,neurips,neurips_2020,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
7,TaylorGAN Neighbor-Augmented Policy Update Towards Sample-Efficient Natural Language Generation.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
8,The MAGICAL Benchmark for Robust Imitation.pdf,True,False,False,2020,neurips,neurips_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
9,Learning Multi-Agent Coordination for Enhancing Target Coverage in Directional Sensor Networks.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
10,Robust-Adaptive Control of Linear Systems beyond Quadratic Costs.pdf,True,False,False,2020,neurips,neurips_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
11,Learning to Prove Theorems by Learning to Generate Theorems.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
12,A General Large Neighborhood Search Framework for Solving Integer Linear Programs.pdf,False,True,False,2020,neurips,neurips_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,other,,,,,,
13,Language as a Cognitive Tool to Imagine Goals in Curiosity Driven Exploration.pdf,True,False,False,2020,neurips,neurips_2020,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,ddpg,,,,,
14,Gradient Surgery for Multi-Task Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
15,Stateful Posted Pricing with Vanishing Regret via Dynamic Deterministic Markov Decision Processes.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
16,Marginal Utility for Planning in Continuous or Large Discrete Action Spaces.pdf,False,False,False,2020,neurips,neurips_2020,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
17,Improving Sample Complexity Bounds for Natural Actor-Critic Algorithms.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,a2c,,,,
18,MOReL Model-Based Offline Reinforcement Learning.pdf,False,True,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
19,Promoting Coordination through Policy Regularization in Multi-Agent Deep Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
20,Simultaneously Learning Stochastic and Adversarial Episodic MDPs with Known Transition.pdf,False,False,False,2020,neurips,neurips_2020,0,state-action\s+pairs,,,,,,,ppo,,,,,,
21,The Mean-Squared Error of Double Q-Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
22,Deep Reinforcement and InfoMax Learning.pdf,False,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,,,,
23,Counterfactual Data Augmentation using Locally Factored Dynamics.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,,,,
24,First Order Constrained Optimization in Policy Space.pdf,False,False,False,2020,neurips,neurips_2020,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,,,,,
25,Softmax Deep Double Deterministic Policy Gradients.pdf,True,True,False,2020,neurips,neurips_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,dqn,ddpg,sac,,,
26,Non-Stochastic Control with Bandit Feedback.pdf,True,False,False,2020,neurips,neurips_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
27,Reinforcement Learning with Combinatorial Actions An Application to Vehicle Routing.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,sac,,,,,,
28,Consequences of Misaligned AI.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
29,Cooperative Heterogeneous Deep Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,a3c,dqn,a2c,sac,ppo,,
30,The NetHack Learning Environment.pdf,True,True,False,2020,neurips,neurips_2020,over 10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
31,Stage-wise Conservative Linear Bandits.pdf,False,False,False,2020,neurips,neurips_2020,over 10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
32,Contextual Reserve Price Optimization in Auctions via Mixed Integer Programming.pdf,True,True,False,2020,neurips,neurips_2020,1-5,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
33,Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based Games.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,sac,,,
34,Knowledge Transfer in Multi-Task Deep Reinforcement Learning for Continuous Control.pdf,False,False,False,2020,neurips,neurips_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,dqn,ddpg,sac,a2c,td3,ppo,
35,Trust the Model When It Is Confident Masked Model-based Actor-Critic.pdf,True,False,False,2020,neurips,neurips_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,pets,sac,,,,
36,An Imitation from Observation Approach to Transfer Learning with Dynamics Mismatch.pdf,True,True,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
37,Forethought and Hindsight in Credit Assignment.pdf,False,False,False,2020,neurips,neurips_2020,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
38,Learning Graph Structure With A Finite-State Automaton Layer.pdf,True,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
39,Glance and Focus a Dynamic Approach to Reducing Spatial Redundancy in Image Classification.pdf,True,True,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,a3c,dqn,sac,td3,ppo,,
40,Meta-Learning through Hebbian Plasticity in Random Networks.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
41,Automatic Curriculum Learning through Value Disagreement.pdf,True,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ddpg,,,,,,
42,Online Meta-Critic Learning for Off-Policy Actor-Critic Methods.pdf,True,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,dqn,ddpg,sac,a2c,td3,ppo,
43,Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
44,Refactoring Policy for Compositional Generalizability using Self-Supervised Object Proposals.pdf,True,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
45,Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,other,,,,,,
46,Steady State Analysis of Episodic Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,a3c,dqn,sac,ppo,,
47,Task-agnostic Exploration in Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
48,Fictitious Play for Mean Field Games Continuous Time Analysis and Applications.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,sac,,,,
49,Continual Learning of Control Primitives  Skill Discovery via Reset-Games.pdf,True,False,False,2020,neurips,neurips_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
50,An Efficient Asynchronous Method for Integrating Evolutionary and Gradient-based Policy Search.pdf,True,False,False,2020,neurips,neurips_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,td3,ppo,sac,ddpg,,,
51,Interferobot aligning an optical interferometer by a reinforcement learning agent.pdf,True,False,False,2020,neurips,neurips_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
52,Deep Inverse Q-learning with Constraints.pdf,False,False,False,2020,neurips,neurips_2020,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
53,Confounding-Robust Policy Evaluation in Infinite-Horizon Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
54,Adversarial Bandits with Corruptions Regret Lower Bound and No-regret Algorithm.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
55,Self-supervised Co-Training for Video Representation Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
56,Near-Optimal Reinforcement Learning with Self-Play.pdf,False,False,False,2020,neurips,neurips_2020,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
57,Value-driven Hindsight Modelling.pdf,False,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
58,Escaping the Gravitational Pull of Softmax.pdf,False,False,False,2020,neurips,neurips_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
59,What Did You Think Would Happen Explaining Agent Behaviour through Intended Outcomes.pdf,True,False,False,2020,neurips,neurips_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
60,Natural Policy Gradient Primal-Dual Method for Constrained Markov Decision Processes.pdf,False,True,False,2020,neurips,neurips_2020,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,trpo,ppo,,,,,
61,Bridging Imagination and Reality for Model-Based Deep Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,ppo,sac,,,,
62,Bootstrap Your Own Latent - A New Approach to Self-Supervised Learning.pdf,True,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
63,Self-Imitation Learning via Generalized Lower Bound Q-learning.pdf,True,False,False,2020,neurips,neurips_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
64,CoinDICE Off-Policy Confidence Interval Estimation.pdf,True,False,False,2020,neurips,neurips_2020,over 10,action-value\s+function,,,,,,,ppo,,,,,,
65,MDP Homomorphic Networks Group Symmetries in Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
66,The Value Equivalence Principle for Model-Based Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,,,,,ppo,,,,,,
67,Learning Affordance Landscapes for Interaction Exploration in 3D Environments.pdf,False,False,False,2020,neurips,neurips_2020,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,,,,,,
68,An Equivalence between Loss Functions and Non-Uniform Sampling in Experience Replay.pdf,True,False,False,2020,neurips,neurips_2020,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,td3,ppo,dqn,sac,,,
69,Unreasonable Effectiveness of Greedy Algorithms in Multi-Armed Bandit with Many Arms.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
70,Learning Object-Centric Representations of Multi-Object Scenes from Multiple Views.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
71,High-Throughput Synchronous Deep RL.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,a3c,ppo,a2c,,,,
72,A Novel Automated Curriculum Strategy to Solve Hard Sokoban Planning Instances.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
73,How to Learn a Useful Critic Model-based Action-Gradient-Estimator Policy Optimization.pdf,True,True,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,td3,dqn,ddpg,,,,
74,Model Selection for Production System via Automated Online Experiments.pdf,False,False,False,2020,neurips,neurips_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
75,Learning Individually Inferred Communication for Multi-Agent Cooperation.pdf,False,False,False,2020,neurips,neurips_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,ppo,ddpg,,,,,
76,Generalized Hindsight for Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
77,A Maximum-Entropy Approach to Off-Policy Evaluation in Average-Reward MDPs.pdf,False,False,False,2020,neurips,neurips_2020,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
78,Decentralized TD Tracking with Linear Function Approximation and its Finite-Time Analysis.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
79,MOPO Model-based Offline Policy Optimization.pdf,True,True,False,2020,neurips,neurips_2020,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
80,Safe Reinforcement Learning via Curriculum Induction.pdf,True,False,False,2020,neurips,neurips_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
81,Provably Efficient Reward-Agnostic Navigation with Linear Value Iteration.pdf,False,False,False,2020,neurips,neurips_2020,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
82,Variational Policy Gradient Method for Reinforcement Learning with General Utilities.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,other,,,,,,
83,Gamma-Models Generative Temporal Difference Learning for Infinite-Horizon Prediction.pdf,False,True,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
84,Learning to summarize with human feedback.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
85,Improving GAN Training with Probability Ratio Clipping and Sample Reweighting.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
86,Improving Generalization in Reinforcement Learning with Mixture Regularization.pdf,True,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
87,Modeling and Optimization Trade-off in Meta-learning.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
88,PC-PG Policy Cover Directed Exploration for Provable Policy Gradient Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
89,ColdGANs Taming Language GANs with Cautious Sampling Strategies.pdf,True,False,False,2020,neurips,neurips_2020,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,other,,,,,,
90,EcoLight Intersection Control in Developing Regions Under Extreme Budget and Network Constraints.pdf,False,False,False,2020,neurips,neurips_2020,0,action-value\s+function,,,,,,,ppo,sac,,,,,
91,Preference-based Reinforcement Learning with Finite-Time Guarantees.pdf,False,True,False,2020,neurips,neurips_2020,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
92,Efficient Model-Based Reinforcement Learning through Optimistic Policy Search and Planning.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,dqn,sac,,,
93,DisCor Corrective Feedback in Reinforcement Learning via Distribution Correction.pdf,False,True,False,2020,neurips,neurips_2020,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,ddpg,sac,,,
94,A Unifying View of Optimism in Episodic Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,other,,,,,,
95,See Hear Explore Curiosity via Audio-Visual Association.pdf,False,False,False,2020,neurips,neurips_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
96,Latent World Models For Intrinsically Motivated Exploration.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
97,CogMol Target-Specific and Selective Drug Design for COVID-19 Using Deep Generative Models.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
98,Emergent Complexity and Zero-shot Transfer via Unsupervised Environment Design.pdf,True,True,False,2020,neurips,neurips_2020,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
99,Linear Disentangled Representations and Unsupervised Action Estimation.pdf,True,False,False,2020,neurips,neurips_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
100,Graph Policy Network for Transferable Active Learning on Graphs.pdf,True,True,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,dqn,,,,,,
101,A Local Temporal Difference Code for Distributional Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
102,Effective Diversity in Population Based Reinforcement Learning.pdf,True,True,False,2020,neurips,neurips_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,ppo,sac,,,,
103,Learning Guidance Rewards with Trajectory-space Smoothing.pdf,True,False,False,2020,neurips,neurips_2020,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,td3,ppo,dqn,sac,,,
104,Global Convergence and Variance Reduction for a Class of Nonconvex-Nonconcave Minimax Problems.pdf,False,True,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
105,On the Convergence of Smooth Regularized Approximate Value Iteration Schemes.pdf,False,False,False,2020,neurips,neurips_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
106,Learning efficient task-dependent representations with synaptic plasticity.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
107,Robust Multi-Agent Reinforcement Learning with Model Uncertainty.pdf,False,False,False,2020,neurips,neurips_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,,,,
108,Multi-task Batch Reinforcement Learning with Metric Learning.pdf,False,True,False,2020,neurips,neurips_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
109,Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors.pdf,False,True,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
110,Predictive Information Accelerates Learning in RL.pdf,True,False,False,2020,neurips,neurips_2020,6-10,(?:discount|reward)\s+function,,,,,,,dreamer,dqn,sac,,,,
111,Provably Efficient Exploration for Reinforcement Learning Using Unsupervised Learning.pdf,True,True,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
112,Agnostic Q-learning with Function Approximation in Deterministic Systems Near-Optimal Bounds on Appr.pdf,False,False,False,2020,neurips,neurips_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
113,FLAMBE Structural Complexity and Representation Learning of Low Rank MDPs.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
114,Continuous Meta-Learning without Tasks.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
115,BoTorch A Framework for Efficient Monte-Carlo Bayesian Optimization.pdf,True,True,False,2020,neurips,neurips_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
116,Online Decision Based Visual Tracking via Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
117,Convolutional Generation of Textured 3D Meshes.pdf,True,False,False,2020,neurips,neurips_2020,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,,,,,,,ppo,,,,,,
118,Optimal Best-arm Identification in Linear Bandits.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
119,Provably Efficient Neural Estimation of Structural Equation Models An Adversarial Approach.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,,,,,
120,POMDPs in Continuous Time and Discrete Spaces.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
121,Memory Based Trajectory-conditioned Policies for Learning from Sparse Rewards.pdf,False,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,,,,
122,Expert-Supervised Reinforcement Learning for Offline Policy Learning and Evaluation.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
123,Object Goal Navigation using Goal-Oriented Semantic Exploration.pdf,True,True,False,2020,neurips,neurips_2020,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,a2c,,,,,
124,Accelerating Reinforcement Learning through GPU Atari Emulation.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,a2c,,,,
125,An operator view of policy gradient methods.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
126,Training Stronger Baselines for Learning to Optimize.pdf,True,True,False,2020,neurips,neurips_2020,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,sac,,,,,,
127,Adaptive Sampling for Stochastic Risk-Averse Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,sac,,,,,,
128,A Unified Switching System Perspective and Convergence Analysis of Q-Learning Algorithms.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
129,Hybrid Variance-Reduced SGD Algorithms For Minimax Problems with Nonconvex-Linear Function.pdf,False,True,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
130,Deep Imitation Learning for Bimanual Robotic Manipulation.pdf,True,True,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
131,Compositional Generalization by Learning Analytical Expressions.pdf,True,False,False,2020,neurips,neurips_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
132,Reinforcement Learning for Control with Multiple Frequencies.pdf,True,True,False,2020,neurips,neurips_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,sac,,,,,,
133,Pontryagin Differentiable Programming An End-to-End Learning and Control Framework.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
134,Meta-trained agents implement Bayes-optimal agents.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
135,Does Unsupervised Architecture Representation Learning Help Neural Architecture Search.pdf,True,True,False,2020,neurips,neurips_2020,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
136,Finite-Time Analysis of Round-Robin Kullback-Leibler Upper Confidence Bounds for Optimal Adaptive Al.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
137,Sample-Efficient Reinforcement Learning of Undercomplete POMDPs.pdf,False,False,False,2020,neurips,neurips_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
138,Learning Multi-Agent Communication through Structured Attentive Reasoning.pdf,True,False,False,2020,neurips,neurips_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,td3,ppo,ddpg,,,,
139,An Improved Analysis of  Variance-Reduced Policy Gradient and Natural Policy Gradient Methods.pdf,True,True,False,2020,neurips,neurips_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,other,,,,,,
140,When Counterpoint Meets Chinese Folk Melodies.pdf,False,False,False,2020,neurips,neurips_2020,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,pets,sac,,,,,
141,Inferring learning rules from animal decision-making.pdf,True,False,False,2020,neurips,neurips_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
142,PyGlove Symbolic Programming for Automated Machine Learning.pdf,True,True,False,2020,neurips,neurips_2020,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
143,Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations.pdf,True,True,False,2020,neurips,neurips_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,trpo,ppo,dqn,ddpg,,,
144,POMO Policy Optimization with Multiple Optima for Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,sac,,,,,,
145,Hitting the High Notes Subset Selection for Maximizing Expected Order Statistics.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
146,Robust Reinforcement Learning via Adversarial training with Langevin Dynamics.pdf,True,True,False,2020,neurips,neurips_2020,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,,,,,,
147,Probably Approximately Correct Constrained Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,sac,,,,,,
148,Non-Crossing Quantile Regression for Distributional Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
149,Weighted QMIX Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Le.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,sac,,,
150,Sample Complexity of Asynchronous Q-Learning Sharper Analysis and Variance Reduction.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,,,,,,
151,Reward-rational implicit choice A unifying formalism for reward learning.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
152,Off-Policy Interval Estimation with Lipschitz Value Iteration.pdf,False,False,False,2020,neurips,neurips_2020,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
153,f-GAIL Learning f-Divergence for Generative Adversarial Imitation Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
154,Self-Paced Deep Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,over 10,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
155,Learning to search efficiently for causally near-optimal treatments.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
156,Cooperative Multi-player Bandit Optimization.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
157,Stochastic Optimization for Performative Prediction.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,pets,ppo,,,,,
158,Towards Safe Policy Improvement for Non-Stationary MDPs.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
159,Towards Minimax Optimal Reinforcement Learning in Factored Markov Decision Processes.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
160,Beyond Individualized Recourse Interpretable and Interactive Summaries of Actionable Recourses.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
161,Learning Differentiable Programs with Admissible Neural Heuristics.pdf,True,True,False,2020,neurips,neurips_2020,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
162,Weakly-Supervised Reinforcement Learning for Controllable Behavior.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
163,Provably Efficient Neural GTD for Off-Policy Learning.pdf,False,False,False,2020,neurips,neurips_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,,,,,,
164,Adversarial Soft Advantage Fitting Imitation Learning without Policy Optimization.pdf,False,True,False,2020,neurips,neurips_2020,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
165,Experimental design for MRI by greedy policy search.pdf,True,False,False,2020,neurips,neurips_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,sac,,,,,,
166,Revisiting Parameter Sharing for Automatic Neural Channel Number Search.pdf,True,False,False,2020,neurips,neurips_2020,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
167,Emergent Reciprocity and Team Formation from Randomized Uncertain Social Preferences.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
168,Adaptive Experimental Design with Temporal Interference A Maximum Likelihood Approach.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
169,Implicit Distributional Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,dqn,ddpg,sac,td3,ppo,,
170,Policy Improvement via Imitation of Multiple Oracles.pdf,True,True,False,2020,neurips,neurips_2020,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
171,Learning to Incentivize Other Learning Agents.pdf,True,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
172,Goal-directed Generation of Discrete Structures with Conditional Generative Models.pdf,False,False,False,2020,neurips,neurips_2020,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
173,Trajectory-wise Multiple Choice Learning for Dynamics Generalization in Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,pets,,,
174,Curriculum learning for multilevel budgeted combinatorial problems.pdf,True,False,False,2020,neurips,neurips_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
175,Barking up the right tree an approach to search over molecule synthesis DAGs.pdf,True,True,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
176,A Boolean Task Algebra for Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
177,Towards Playing Full MOBA Games with Deep Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,,,,,,
178,A new convergent variant of Q-learning with linear function approximation.pdf,False,False,False,2020,neurips,neurips_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,,,,,,
179,Inverse Rational Control with Partially Observable Continuous Nonlinear Dynamics.pdf,False,True,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,ddpg,,,,,
180,Munchausen Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
181,Statistical Efficiency of Thompson Sampling for Combinatorial Semi-Bandits.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
182,Online Bayesian Goal Inference for Boundedly Rational Planning Agents.pdf,True,False,False,2020,neurips,neurips_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
183,Adaptive Discretization for Model-Based Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,,,,,,
184,Promoting Stochasticity for Expressive Policies via a Simple and Efficient Regularization Method.pdf,False,False,False,2020,neurips,neurips_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,td3,ppo,
185,Contextual Games Multi-Agent Learning with Side Information.pdf,False,False,False,2020,neurips,neurips_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
186,Reinforcement Learning with Augmented Data.pdf,True,True,False,2020,neurips,neurips_2020,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,trpo,td3,ppo,sac,,,
187,Upper Confidence Primal-Dual Reinforcement Learning for CMDP with Adversarial Loss.pdf,False,False,False,2020,neurips,neurips_2020,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,ppo,sac,,,,
188,A Finite-Time Analysis of Two Time-Scale Actor-Critic Methods.pdf,False,True,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,a3c,a2c,,,,,
189,Learning Composable Energy Surrogates for PDE Order Reduction.pdf,False,False,False,2020,neurips,neurips_2020,0,state-action\s+pairs,,,,,,,ppo,,,,,,
190,RL Unplugged A Suite of Benchmarks for Offline Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
191,Risk-Sensitive Reinforcement Learning Near-Optimal Risk-Sample Tradeoff in Regret.pdf,False,False,False,2020,neurips,neurips_2020,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,dqn,,,,,,
192,R-learning in actor-critic model offers a biologically relevant mechanism for sequential decision-ma.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
193,A Bandit Learning Algorithm and Applications to Auction Design.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
194,One Solution is Not All You Need Few-Shot Extrapolation via Structured MaxEnt RL.pdf,False,False,False,2020,neurips,neurips_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
195,Belief-Dependent Macro-Action Discovery in POMDPs using the Value of Information.pdf,False,False,False,2020,neurips,neurips_2020,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
196,Discovering Reinforcement Learning Algorithms.pdf,False,False,False,2020,neurips,neurips_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ddpg,,,,,,
197,Model-based Adversarial Meta-Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
198,Finite-Sample Analysis of Contractive Stochastic Approximation Using Smooth Convex Envelopes.pdf,False,False,False,2020,neurips,neurips_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
199,Is Plug-in Solver Sample-Efficient for Feature-based Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
200,VAEM a Deep Generative Model for Heterogeneous Mixed Type Data.pdf,True,True,False,2020,neurips,neurips_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
201,Theoretical Insights Into Multiclass Classification A High-dimensional Asymptotic View.pdf,False,True,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
202,Multi-agent active perception with prediction rewards.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
203,Preference learning along multiple criteria A game-theoretic perspective.pdf,False,False,False,2020,neurips,neurips_2020,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
204,Adversarial Attacks on Deep Graph Matching.pdf,False,False,False,2020,neurips,neurips_2020,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
205,Model Inversion Networks for Model-Based Optimization.pdf,True,True,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
206,A Self-Tuning Actor-Critic Algorithm.pdf,True,True,False,2020,neurips,neurips_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,a3c,ppo,,,,,
207,AdaShare Learning What To Share For Efficient Deep Multi-Task Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
208,Information-theoretic Task Selection for Meta-Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,6-10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
209,Toward the Fundamental Limits of Imitation Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
210,Information Theoretic Regret Bounds for Online Nonlinear Control.pdf,False,True,False,2020,neurips,neurips_2020,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,pets,,,,,,
211,Almost Optimal Model-Free Reinforcement Learningvia Reference-Advantage Decomposition.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
212,The LoCA Regret A Consistent Metric to Evaluate Model-Based Behavior in Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,pets,ppo,dreamer,,,,
213,Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning.pdf,True,True,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
214,Gaussian Process Bandit Optimization of the Thermodynamic Variational Objective.pdf,True,True,False,2020,neurips,neurips_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
215,Minimax Value Interval for Off-Policy Evaluation and Policy Optimization.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
216,Model-based Reinforcement Learning for Semi-Markov Decision Processes with Neural ODEs.pdf,False,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
217,Strictly Batch Imitation Learning by Energy-based Distribution Matching.pdf,True,False,False,2020,neurips,neurips_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
218,Federated Bayesian Optimization via Thompson Sampling.pdf,False,True,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
219,Learning Strategic Network Emergence Games.pdf,False,False,False,2020,neurips,neurips_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
220,Inverse Reinforcement Learning from a Gradient-based Learner.pdf,False,False,False,2020,neurips,neurips_2020,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
221,Collapsing Bandits and Their Application to Public Health Intervention.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
222,Semantic Visual Navigation by Watching YouTube Videos.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
223,Least Squares Regression with Markovian Data Fundamental Limits and Algorithms.pdf,False,False,False,2020,neurips,neurips_2020,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
224,Reinforcement Learning in Factored MDPs Oracle-Efficient Algorithms and Tighter Regret Bounds for th.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
225,Provably Efficient Online Hyperparameter Optimization with Population-Based Bandits.pdf,True,True,False,2020,neurips,neurips_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
226,Reward Propagation Using Graph Convolutional Networks.pdf,True,True,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,a2c,sac,,,
227,Avoiding Side Effects in Complex Environments.pdf,False,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
228,Critic Regularized Regression.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
229,Ridge Rider Finding Diverse Solutions by Following Eigenvectors of the Hessian.pdf,True,True,False,2020,neurips,neurips_2020,over 10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
230,On the Stability and Convergence of Robust Adversarial Reinforcement Learning A Case Study on Linear.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
231,Constrained episodic reinforcement learning in concave-convex and knapsack settings.pdf,True,False,False,2020,neurips,neurips_2020,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,sac,a2c,,,,
232,Optimal Variance Control of the Score-Function Gradient Estimator for Importance-Weighted Bounds.pdf,True,False,False,2020,neurips,neurips_2020,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
233,A game-theoretic analysis of networked system control for common-pool resource management using mult.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,ddpg,a2c,,,,
234,Learning to Utilize Shaping Rewards A New Approach of Reward Shaping.pdf,False,False,False,2020,neurips,neurips_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
235,Locally Differentially Private Contextual Bandits Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
236,Can Q-Learning with Graph Networks Learn a Generalizable Branching Heuristic for a SAT Solver.pdf,True,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
237,Lifelong Policy Gradient Learning of Factored Policies for Faster Training Without Forgetting.pdf,True,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
238,Provably Efficient Reinforcement Learning with Kernel and Neural Function Approximations.pdf,False,False,False,2020,neurips,neurips_2020,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,other,,,,,,
239,Offline Imitation Learning with a Misspecified Simulator.pdf,False,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
240,Bayesian Robust Optimization for Imitation Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,sac,,,,,,
241,Rewriting History with Inverse RL Hindsight Inference for Policy Improvement.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
242,From Finite to Countable-Armed Bandits.pdf,False,False,False,2020,neurips,neurips_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
243,Causal Imitation Learning With Unobserved Confounders.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
244,AttendLight Universal Attention-Based Reinforcement Learning Model for Traffic Signal Control.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
245,Provably Good Batch Off-Policy Reinforcement Learning Without Great Exploration.pdf,False,False,False,2020,neurips,neurips_2020,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,ppo,dqn,sac,,,,
246,Direct Policy Gradients Direct Optimization of Policies in Discrete Action Spaces.pdf,False,False,False,2020,neurips,neurips_2020,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
247,Finite-Time Analysis for Double Q-learning.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
248,Erdos Goes Neural an Unsupervised Learning Framework for Combinatorial Optimization on Graphs.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
249,Learning Implicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
250,Dynamic Regret of Policy Optimization in Non-Stationary Environments.pdf,False,False,False,2020,neurips,neurips_2020,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
251,Doubly Robust Off-Policy Value and Gradient Estimation for Deterministic Policies.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
252,Pointer Graph Networks.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
253,Independent Policy Gradient Methods for Competitive Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,other,,,,,,
254,AvE Assistance via Empowerment.pdf,True,False,False,2020,neurips,neurips_2020,over 10,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
255,Mitigating Forgetting in Online Continual Learning via Instance-Aware Parameterization.pdf,False,True,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
256,Novelty Search in Representational Space for Sample Efficient Exploration.pdf,True,False,False,2020,neurips,neurips_2020,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
257,Error Bounds of Imitating Policies and Environments.pdf,False,False,False,2020,neurips,neurips_2020,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
258,Off-Policy Imitation Learning from Observations.pdf,False,False,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
259,Efficient Exploration of Reward Functions in Inverse Reinforcement Learning via Bayesian Optimizatio.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
260,Finite Continuum-Armed Bandits.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
261,Calibration of Shared Equilibria in General Sum Partially Observable Markov Games.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
262,Deep active inference agents using Monte-Carlo methods.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
263,Multi-Task Reinforcement Learning with Soft Modularization.pdf,False,False,False,2020,neurips,neurips_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
264,PlanGAN Model-based Planning With Sparse Rewards and Multiple Goals.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,,,
265,Off-Policy Evaluation via the Regularized Lagrangian.pdf,False,False,False,2020,neurips,neurips_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
266,Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal Sample Complexity.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
267,TorsionNet A Reinforcement Learning Approach to Sequential Conformer Search.pdf,True,True,False,2020,neurips,neurips_2020,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
268,Residual Force Control for Agile Human Behavior Imitation and Extended Motion Synthesis.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
269,Can Temporal-Diï¬erence and Q-Learning Learn Representation A Mean-Field Theory.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,dqn,,,,,,
270,Bayesian Multi-type Mean Field Multi-agent Imitation Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
271,Neural Bridge Sampling for Evaluating Safety-Critical Autonomous Systems.pdf,False,False,False,2020,neurips,neurips_2020,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
272,Myersonian Regression.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
273,Probabilistic Time Series Forecasting with Shape and Temporal Diversity.pdf,True,False,False,2020,neurips,neurips_2020,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
274,Stochastic Latent Actor-Critic Deep Reinforcement Learning with a Latent Variable Model.pdf,False,True,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
275,Learning Retrospective Knowledge with Reverse Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,td3,ppo,,,,,
276,Provably adaptive reinforcement learning in metric spaces.pdf,False,False,False,2020,neurips,neurips_2020,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,sac,,,,,,
277,Neurosymbolic Transformers for Multi-Agent Communication.pdf,True,False,False,2020,neurips,neurips_2020,over 10,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,,,,,,
278,Improved Sample Complexity for Incremental Autonomous Exploration in MDPs.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
279,Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
280,POLY-HOOT Monte-Carlo Planning in Continuous Space MDPs with Non-Asymptotic Analysis.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
281,Planning with General Objective Functions Going Beyond Total Rewards.pdf,False,False,False,2020,neurips,neurips_2020,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
282,Is Long Horizon RL More Difficult Than Short Horizon RL.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
283,Reinforcement Learning with General Value Function Approximation Provably Efficient Approach via Bou.pdf,False,False,False,2020,neurips,neurips_2020,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
284,Online Planning with Lookahead Policies.pdf,False,False,False,2020,neurips,neurips_2020,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,other,,,,,,
285,Conservative Q-Learning for Offline Reinforcement Learning.pdf,True,False,False,2020,neurips,neurips_2020,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
286,Avoiding Side Effects By Considering Future Tasks.pdf,True,True,False,2020,neurips,neurips_2020,over 10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
287,Reinforced Molecular Optimization with Neighborhood-Controlled Grammars.pdf,True,True,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
288,RD2 Reward Decomposition with Representation Decomposition.pdf,True,False,False,2020,neurips,neurips_2020,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
289,Learning to Play Sequential Games versus Unknown Opponents.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
290,Guiding Deep Molecular Optimization with Genetic Exploration.pdf,True,False,False,2020,neurips,neurips_2020,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,,,,,,
291,Model Selection in Contextual Stochastic Bandit Problems.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
292,A Single Recipe for Online Submodular Maximization with Adversarial or Stochastic Constraints.pdf,False,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
293,Learning Agent Representations for Ice Hockey.pdf,True,False,False,2020,neurips,neurips_2020,0,action-value\s+function,,,,,,,ppo,,,,,,
294,Neurosymbolic Reinforcement Learning with Formally Verified Exploration.pdf,True,True,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
295,GCOMB Learning Budget-constrained Combinatorial Algorithms over Billion-sized Graphs.pdf,True,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,,,,,,
296,SAC Accelerating and Structuring Self-Attention via Sparse Adaptive Connection.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,sac,,,,,
297,Security Analysis of Safe and Seldonian Reinforcement Learning Algorithms.pdf,True,False,False,2020,neurips,neurips_2020,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
298,BAIL Best-Action Imitation Learning for Batch Deep Reinforcement Learning.pdf,True,True,False,2020,neurips,neurips_2020,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
299,Sample-Efficient Optimization in the Latent Space of Deep Generative Models via Weighted Retraining.pdf,True,True,False,2020,neurips,neurips_2020,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
300,Model-based Policy Optimization with Unsupervised Model Adaptation.pdf,True,True,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,pets,ppo,sac,,,,
301,Leverage the Average an Analysis of KL Regularization in Reinforcement Learning.pdf,False,False,False,2020,neurips,neurips_2020,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,dqn,sac,,,,
302,Interpretable and Personalized Apprenticeship Scheduling Learning Interpretable Scheduling Policies .pdf,False,False,False,2020,neurips,neurips_2020,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
303,Scalable Multi-Agent Reinforcement Learning for Networked Systems with Average Reward.pdf,False,False,False,2020,neurips,neurips_2020,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
304,Zap Q-Learning With Nonlinear Function Approximation.pdf,True,False,False,2020,neurips,neurips_2020,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
305,Planning in Markov Decision Processes with Gap-Dependent Sample Complexity.pdf,True,False,False,2020,neurips,neurips_2020,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
306,The Power of Predictions in Online Control.pdf,False,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
307,Reinforcement Learning with Feedback Graphs.pdf,True,False,False,2020,neurips,neurips_2020,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,ppo,,,,,,
0,Nearly Minimax Optimal Reinforcement Learning for Discounted MDPs.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
1,Plan Your Target and Learn Your Skills State-Only Imitation Learning via Decoupled Policy Optimizati.pdf,True,False,False,2021,neurips,neurips_2021,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
2,Fast Algorithms for L_infty-constrained S-rectangular Robust MDPs.pdf,False,False,False,2021,neurips,neurips_2021,0,value\s+function\s+approximation,,,,,,,ppo,,,,,,
3,Outcome-Driven Reinforcement Learning via Variational Inference.pdf,False,False,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
4,Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation.pdf,True,False,False,2021,neurips,neurips_2021,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
5,Uncertain Decisions Facilitate Better Preference Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
6,Improved Variance-Aware Confidence Sets for Linear Bandits and Linear Mixture MDP.pdf,False,False,False,2021,neurips,neurips_2021,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
7,Regularized Softmax Deep Multi-Agent Q-Learning.pdf,True,True,False,2021,neurips,neurips_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td3,ppo,,
8,Planning from Pixels in Environments with Combinatorially Hard Search Spaces.pdf,True,False,False,2021,neurips,neurips_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
9,Self-Consistent Models and Values.pdf,True,False,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
10,Medical Dead-ends and Learning to Identify High-Risk States and Treatments.pdf,True,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
11,Minimax Regret for Stochastic Shortest Path.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,,,,,,,other,,,,,,
12,Meta Reinforcement Learning for Fast Adaptation of Hierarchical Policies.pdf,True,True,False,2021,neurips,neurips_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
13,Safe Reinforcement Learning by Imagining the Near Future.pdf,True,True,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
14,Offline Model-based Adaptable Policy Learning.pdf,True,True,False,2021,neurips,neurips_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
15,Contrastive Reinforcement Learning of Symbolic Reasoning Domains.pdf,True,False,False,2021,neurips,neurips_2021,1-5,state-action\s+pairs,,,,,,,ppo,dqn,,,,,
16,Why Generalization in RL is Difficult Epistemic POMDPs and Implicit Partial Observability.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
17,PlayVirtual Augmenting Cycle-Consistent Virtual Trajectories for Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
18,Curriculum Offline Imitating Learning.pdf,True,True,False,2021,neurips,neurips_2021,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
19,NeurWIN Neural Whittle Index Network For Restless Bandits Via Deep RL.pdf,True,False,False,2021,neurips,neurips_2021,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,sac,,,
20,Analytically Tractable Bayesian Deep Q-Learning.pdf,True,True,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,dqn,,,,,,
21,Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble.pdf,True,True,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,dqn,sac,,,,
22,Offline Constrained Multi-Objective Reinforcement Learning via Pessimistic Dual Value Iteration.pdf,False,False,False,2021,neurips,neurips_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,,,,,,ppo,dqn,sac,,,,
23,Unifying Gradient Estimators for Meta-Reinforcement Learning  via Off-Policy Evaluation.pdf,True,True,False,2021,neurips,neurips_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
24,Hierarchical Skills for Efficient Exploration.pdf,False,False,False,2021,neurips,neurips_2021,6-10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
25,A Hierarchical Reinforcement Learning Based Optimization Framework for Large-scale Dynamic Pickup an.pdf,False,True,False,2021,neurips,neurips_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,dqn,,,,,,
26,Multi-Agent Reinforcement Learning for Active Voltage Control on Power Distribution Networks.pdf,True,False,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,td3,ppo,sac,ddpg,,,
27,Habitat 20 Training Home Assistants to Rearrange their Habitat.pdf,True,False,False,2021,neurips,neurips_2021,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
28,No RL No Simulation Learning to Navigate without Navigating.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
29,Temporally Abstract Partial Models.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
30,Dr Jekyll  Mr Hyde the strange case of off-policy policy updates.pdf,True,False,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
31,Entropic Desired Dynamics for Intrinsic Control.pdf,False,False,False,2021,neurips,neurips_2021,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,other,,,,,,
32,Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust Control Design Implicit Reg.pdf,False,True,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,sac,,,,
33,MICo Improved representations via sampling-based state similarity for Markov decision processes.pdf,False,False,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
34,Provable Benefits of Actor-Critic Methods for Offline Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
35,FACMAC Factored Multi-Agent Centralised Policy Gradients.pdf,True,False,False,2021,neurips,neurips_2021,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,ddpg,,,,
36,Learning Diverse Policies in MOBA Games via Macro-Goals.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
37,Asymptotically Exact Error Characterization of Offline Policy Evaluation with Misspecified Linear Mo.pdf,False,False,False,2021,neurips,neurips_2021,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
38,Widening the Pipeline in Human-Guided Reinforcement Learning with Explanation and Context-Aware Data.pdf,False,True,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
39,Improve Agents without Retraining Parallel Tree Search with Off-Policy Correction.pdf,False,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
40,Pessimism Meets Invariance Provably Efficient Offline Mean-Field Multi-Agent RL.pdf,False,True,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
41,Beyond Fine-Tuning Transferring Behavior in Reinforcement Learning.pdf,False,True,False,2021,neurips,neurips_2021,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
42, Online learning in MDPs with linear function approximation and bandit feedback.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
43,Learning to Execute Efficient Learning of Universal Plan-Conditioned Policies in Robotics.pdf,True,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
44,RL for Latent MDPs Regret Guarantees and a Lower Bound.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,,,,,,,ppo,,,,,,
45,Cross-modal Domain Adaptation for Cost-Efficient Visual Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,,,,,,
46,Learning Large Neighborhood Search Policy for Integer Programming.pdf,True,False,False,2021,neurips,neurips_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,ppo,sac,,,,,
47,TAAC Temporally Abstract Actor-Critic for Continuous Control.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
48,Environment Generation for Zero-Shot Compositional Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,a2c,,,,,,
49,K-level Reasoning for Zero-Shot Coordination in Hanabi.pdf,False,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
50,Going Beyond Linear RL Sample Efficient Neural Function Approximation.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
51,Goal-Aware Cross-Entropy for Multi-Target Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,a3c,ppo,sac,a2c,,,
52,Parametrized Quantum Policies for Reinforcement Learning.pdf,True,True,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,sac,,,,
53,Online Robust Reinforcement Learning with Model Uncertainty.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,dqn,sac,,,,
54,Program Synthesis Guided Reinforcement Learning for Partially Observed Environments.pdf,True,False,False,2021,neurips,neurips_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,sac,,,,,
55,Reinforcement Learning in Linear MDPs Constant Regret and Representation Selection.pdf,True,False,False,2021,neurips,neurips_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,other,,,,,,
56,Local policy search with Bayesian optimization.pdf,True,True,False,2021,neurips,neurips_2021,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
57,On Effective Scheduling of Model-based Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
58,Distributionally Robust Imitation Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
59,A Provably Efficient Model-Free Posterior Sampling Method for Episodic Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,value\s+function\s+approximation,state-action\s+pairs,,,,,,dqn,,,,,,
60,Learning Domain Invariant Representations in Goal-conditioned Block MDPs.pdf,True,False,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
61,Decentralized Q-learning in Zero-sum Markov Games.pdf,False,False,False,2021,neurips,neurips_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
62,Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings.pdf,False,True,False,2021,neurips,neurips_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,ppo,dqn,sac,,,,
63,Oracle-Efficient Regret Minimization in Factored MDPs with Unknown Structure.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
64,Information is Power Intrinsic Control via Information Capture.pdf,True,False,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
65,On the Theory of Reinforcement Learning with Once-per-Episode Feedback.pdf,False,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,sac,,,,,,
66,Model-Based Episodic Memory Induces Dynamic Hybrid Controls.pdf,False,True,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
67,Collaborating with Humans without Human Data.pdf,False,True,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
68,TacticZero Learning to Prove Theorems from Scratch with Deep Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
69,EDGE Explaining Deep Reinforcement Learning Policies.pdf,True,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
70,RMIX Learning Risk-Sensitive Policies for Cooperative Reinforcement Learning Agents.pdf,True,True,False,2021,neurips,neurips_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
71,Sample-Efficient Reinforcement Learning for Linearly-Parameterized MDPs with a Generative Model.pdf,False,False,False,2021,neurips,neurips_2021,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
72,Replacing Rewards with Examples Example-Based Policy Search via Recursive Classification.pdf,True,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
73,Reinforcement Learning in Newcomblike Environments.pdf,False,False,False,2021,neurips,neurips_2021,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
74,Agent Modelling under Partial Observability for Deep Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,a2c,,,,,
75,Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
76,On the Convergence Theory of Debiased Model-Agnostic Meta-Reinforcement Learning.pdf,True,True,False,2021,neurips,neurips_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
77,BooVI Provably Efficient Bootstrapped Value Iteration.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
78,Brick-by-Brick Combinatorial Construction with Deep Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
79,BCORLElambda An Offline Reinforcement Learning and Evaluation Framework for Coupons Allocation in E-.pdf,False,False,False,2021,neurips,neurips_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,other,,,,,,
80,Model-Based Reinforcement Learning via Imagination with Derived Memory.pdf,False,False,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,ddpg,,,
81,Bayesian Bellman Operators.pdf,False,False,False,2021,neurips,neurips_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
82,Landmark-Guided Subgoal Generation in Hierarchical Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,ppo,,,,,
83,Understanding the Effect of Stochasticity in Policy Optimization.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
84,Learning in Non-Cooperative Configurable Markov Decision Processes.pdf,False,False,False,2021,neurips,neurips_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
85,Play to Grade Testing Coding Games as Classifying Markov Decision Process.pdf,True,False,False,2021,neurips,neurips_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
86,Bridging the Imitation Gap by Adaptive Insubordination.pdf,True,True,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,a2c,ppo,,
87,The Difficulty of Passive Learning in Deep Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,dqn,,,,,,
88,There Is No Turning Back A Self-Supervised Approach for Reversibility-Aware Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
89,Sequential Causal Imitation Learning with Unobserved Confounders.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
90,CO-PILOT COllaborative Planning and reInforcement Learning On sub-Task curriculum.pdf,True,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
91,Ranking Policy Decisions.pdf,True,True,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
92,Variance-Aware Off-Policy Evaluation with Linear Function Approximation.pdf,False,False,False,2021,neurips,neurips_2021,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
93,Behavior From the Void Unsupervised Active Pre-Training.pdf,True,False,False,2021,neurips,neurips_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
94,Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,dqn,sac,,,,
95,IQ-Learn Inverse soft-Q Learning for Imitation.pdf,True,True,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
96,SOPE Spectrum of Off-Policy Estimators.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
97,When should agents explore.pdf,True,True,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
98,Tactical Optimism and Pessimism for Deep Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,dqn,sac,td3,ppo,dreamer,,
99,Continual Auxiliary Task Learning.pdf,False,False,False,2021,neurips,neurips_2021,over 10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
100,Revisiting Design Choices in Offline Model Based Reinforcement Learning.pdf,False,True,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
101,MADE Exploration via Maximizing Deviation from Explored Regions.pdf,True,True,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,dreamer,dqn,,,,,
102,Automatic Data Augmentation for Generalization in Reinforcement Learning.pdf,True,True,False,2021,neurips,neurips_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
103,PerSim Data-Efficient Offline Reinforcement Learning with Heterogeneous Agents via Personalized Simu.pdf,True,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,td3,ppo,dqn,,,,
104,Regret Minimization Experience Replay in Off-Policy Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
105,On the Value of Interaction and Function Approximation in Imitation Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
106,No-Press Diplomacy from Scratch.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
107,On Joint Learning for Solving Placement and Routing in Chip Design.pdf,True,False,False,2021,neurips,neurips_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
108,Learning Tree Interpretation from Object Representation for Deep Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,ppo,dqn,sac,,,,
109,VAST Value Function Factorization with Variable Agent Sub-Teams.pdf,True,True,False,2021,neurips,neurips_2021,over 10,value\s+function\s+approximation,,,,,,,ppo,,,,,,
110,Counterexample Guided RL Policy Refinement Using Bayesian Optimization.pdf,True,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
111,Adversarial Intrinsic Motivation for Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
112,Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
113,Time Discretization-Invariant Safe Action Repetition for Policy Gradient Methods.pdf,True,False,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,a2c,ppo,,
114,Causal Influence Detection for Improving Efficiency in Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,ddpg,,,,,
115,Finite Sample Analysis of Average-Reward TD Learning and Q-Learning.pdf,True,False,False,2021,neurips,neurips_2021,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
116,Direct then Diffuse Incremental Unsupervised Skill Discovery for State Covering and Goal Reaching.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
117,Universal Off-Policy Evaluation.pdf,True,False,False,2021,neurips,neurips_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
118,Scalable Online Planning via Reinforcement Learning Fine-Tuning.pdf,False,False,False,2021,neurips,neurips_2021,1-5,state-action\s+pairs,,,,,,,ppo,dqn,,,,,
119,Beyond Value-Function Gaps Improved Instance-Dependent Regret Bounds for Episodic Reinforcement Lear.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,,,,,,,ppo,,,,,,
120,Provable Model-based Nonlinear Bandit and Reinforcement Learning Shelve Optimism Embrace Virtual Cur.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,,,,,,
121,Structural Credit Assignment in Neural Networks using Reinforcement Learning.pdf,False,True,False,2021,neurips,neurips_2021,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,sac,,,,
122,Monte Carlo Tree Search With Iteratively Refining State Abstractions.pdf,False,True,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
123,Proper Value Equivalence.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
124,Average-Reward Learning and Planning with Options.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
125,When Is Generalizable Reinforcement Learning Tractable.pdf,False,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
126,Snowflake Scaling GNNs to high-dimensional continuous control via parameter freezing.pdf,False,True,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,ppo,,,,,,
127,PettingZoo Gym for Multi-Agent Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
128,An Efficient Transfer Learning Framework for Multiagent Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
129,Decision Transformer Reinforcement Learning via Sequence Modeling.pdf,True,False,False,2021,neurips,neurips_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,dqn,,,,,,
130,Robust Predictable Control.pdf,True,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
131,An Exponential Lower Bound for Linearly Realizable MDP with Constant Suboptimality Gap.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,state-action\s+pairs,,,,,,dqn,,,,,,
132,Coordinated Proximal Policy Optimization.pdf,False,False,False,2021,neurips,neurips_2021,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,trpo,ppo,sac,,,,
133,Pretraining Representations for Data-Efficient Reinforcement Learning.pdf,True,True,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
134,Deep Reinforcement Learning at the Edge of the Statistical Precipice.pdf,True,True,False,2021,neurips,neurips_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dreamer,ppo,dqn,sac,,,
135,Active Offline Policy Selection.pdf,True,False,False,2021,neurips,neurips_2021,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
136,Teachable Reinforcement Learning via Advice Distillation.pdf,False,False,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,pets,,,,,,
137,Mastering Atari Games with Limited Data.pdf,True,False,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
138,Variational Bayesian Reinforcement Learning with Regret Bounds.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,,,,,,
139,Conservative Data Sharing for Multi-Task Offline Reinforcement Learning.pdf,False,True,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
140,Learning Barrier Certificates Towards Safe Reinforcement Learning with Zero Training-time Violations.pdf,False,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
141,Learning MDPs from Features Predict-Then-Optimize for Sequential Decision Making by Reinforcement Le.pdf,True,False,False,2021,neurips,neurips_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
142,On Pathologies in KL-Regularized Reinforcement Learning from Expert Demonstrations.pdf,False,False,False,2021,neurips,neurips_2021,6-10,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
143,Dynamic population-based meta-learning for multi-agent communication with natural language.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
144, Taming Communication and Sample Complexities in Decentralized Policy Evaluation for Cooperative Mul.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
145,Multi-Objective SPIBB Seldonian Offline Policy Improvement with Safety Constraints in Finite MDPs.pdf,True,False,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
146,Near-Optimal Offline Reinforcement Learning via Double Variance Reduction.pdf,False,True,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
147,A CramÃ©r Distance perspective on Non-crossing Quantile Regression in Distributional Reinforcement Le.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
148,Provably Efficient Black-Box Action Poisoning Attacks Against Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,a2c,,,,
149,Episodic Multi-agent Reinforcement Learning with Curiosity-driven Exploration.pdf,False,False,False,2021,neurips,neurips_2021,6-10,action-value\s+function,,,,,,,ppo,dqn,sac,,,,
150,Continual World A Robotic Benchmark For Continual Reinforcement Learning.pdf,True,True,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
151,Risk-Averse Bayes-Adaptive Reinforcement Learning.pdf,False,True,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
152,The best of both worlds stochastic and adversarial episodic MDPs with unknown transition.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,,,,,,,other,,,,,,
153,Hit and Lead Discovery with Explorative RL and Fragment-based Molecule Generation.pdf,True,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
154,Conservative Offline Distributional Reinforcement Learning.pdf,True,True,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,ppo,dqn,sac,,,,
155,Twice regularized MDPs and the equivalence between robustness and regularization.pdf,True,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
156,Wasserstein Flow Meets Replicator Dynamics A Mean-Field Analysis of Representation Learning in Actor.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
157,Evolution Gym A Large-Scale Benchmark for Evolving Soft Robots.pdf,True,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
158,Reinforcement Learning with State Observation Costs in Action-Contingent Noiselessly Observable Mark.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,sac,,,
159,Inverse Reinforcement Learning in a Continuous State Space with Formal Guarantees.pdf,False,False,False,2021,neurips,neurips_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
160,Discovery of Options via Meta-Learned Subgoals.pdf,False,True,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
161,Offline Meta Reinforcement Learning -- Identifiability Challenges and Effective Data Collection Stra.pdf,True,False,False,2021,neurips,neurips_2021,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
162,Learning Markov State Abstractions for Deep Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
163,Breaking the Sample Complexity Barrier to Regret-Optimal Model-Free Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
164,Represent Your Own Policies Reinforcement Learning with Policy-extended Value Function Approximator.pdf,False,False,False,2021,neurips,neurips_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,trpo,ppo,,,,,
165,Offline RL Without Off-Policy Evaluation.pdf,True,True,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,,,,,,
166,Risk-Aware Transfer in Reinforcement Learning using Successor Features.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
167,Curriculum Design for Teaching via Demonstrations Theory and Applications.pdf,True,False,False,2021,neurips,neurips_2021,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,sac,,,,,,
168,Iterative Amortized Policy Optimization.pdf,True,True,False,2021,neurips,neurips_2021,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,dqn,a2c,sac,ppo,,
169,Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement .pdf,True,False,False,2021,neurips,neurips_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,td3,ppo,
170,ELLA Exploration through Learned Language Abstraction.pdf,True,False,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
171,Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding.pdf,True,True,False,2021,neurips,neurips_2021,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,ddpg,,,,
172,Provable Representation Learning for Imitation with Contrastive Fourier Features.pdf,True,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
173,Explicable Reward Design for Reinforcement Learning Agents.pdf,True,False,False,2021,neurips,neurips_2021,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
174,Learning to Ground Multi-Agent Communication with Autoencoders.pdf,True,True,False,2021,neurips,neurips_2021,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,a3c,a2c,,,,,
175,Uniform-PAC Bounds for Reinforcement Learning with Linear Function Approximation.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
176,Learning Policies with Zero or Bounded Constraint Violation for Constrained MDPs.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
177,Provably efficient multi-task reinforcement learning with model transfer.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
178,Provably Efficient Causal Reinforcement Learning with Confounded Observational Data.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
179,Learning in two-player zero-sum partially observable Markov games with perfect recall.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
180,Interesting Object Curious Agent Learning Task-Agnostic Exploration.pdf,True,False,False,2021,neurips,neurips_2021,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
181,Generalized Proximal Policy Optimization with Sample Reuse.pdf,True,True,False,2021,neurips,neurips_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
182,Weighted model estimation for offline model-based reinforcement learning.pdf,True,False,False,2021,neurips,neurips_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
183,Safe Policy Optimization with Local Generalized Linear Function Approximations.pdf,True,False,False,2021,neurips,neurips_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
184,Accelerating Robotic Reinforcement Learning via Parameterized Action Primitives.pdf,False,True,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
185,Information Directed Reward Learning for Reinforcement Learning.pdf,True,True,False,2021,neurips,neurips_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
186,Multi-Agent Reinforcement Learning in Stochastic Networked Systems.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
187,Robust Deep Reinforcement Learning through Adversarial Loss.pdf,True,True,False,2021,neurips,neurips_2021,over 10,action-value\s+function,(?:discount|reward)\s+function,,,,,,a3c,ppo,dqn,ddpg,,,
188,Variational Automatic Curriculum Learning for Sparse-Reward Cooperative Multi-Agent Problems.pdf,False,True,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
189,Visual Adversarial Imitation Learning using Variational Models.pdf,False,False,False,2021,neurips,neurips_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
190,Hindsight Task Relabelling Experience Replay for Sparse Reward Meta-RL.pdf,False,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
191,Reinforcement learning for instance segmentation with high-level priors.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
192,Reinforcement Learning in Reward-Mixing MDPs.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
193,Exponential Bellman Equation and Improved Regret Bounds for Risk-Sensitive Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
194,Reinforcement Learning based Disease Progression Model for Alzheimers Disease.pdf,True,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
195,Local Differential Privacy for Regret Minimization in Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
196,Towards Robust Bisimulation Metric Learning.pdf,False,False,False,2021,neurips,neurips_2021,6-10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
197,COMBO Conservative Offline Model-Based Policy Optimization.pdf,False,True,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
198,Fault-Tolerant Federated Reinforcement Learning with Theoretical Guarantee.pdf,True,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
199,Continuous Doubly Constrained Batch Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,,,,,dqn,sac,,,,,
200,Representation Learning for Event-based Visuomotor Policies.pdf,True,False,False,2021,neurips,neurips_2021,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,ppo,,,,,,
201,Policy Finetuning Bridging Sample-Efficient Offline and Online Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,,,,,,
202,Replay-Guided Adversarial Environment Design.pdf,True,True,False,2021,neurips,neurips_2021,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
203,Nearly Horizon-Free Offline Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,state-action\s+pairs,,,,,,ppo,dqn,,,,,
204,Towards Deeper Deep Reinforcement Learning with Spectral Normalization.pdf,False,True,False,2021,neurips,neurips_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,dqn,ddpg,sac,ppo,,
205,An Analysis of Abstracted Model-Based Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
206,Towards Hyperparameter-free Policy Selection for Offline Reinforcement Learning.pdf,False,True,False,2021,neurips,neurips_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
207,Distributional Reinforcement Learning for Multi-Dimensional Reward Functions.pdf,False,False,False,2021,neurips,neurips_2021,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
208,RLlib Flow Distributed Reinforcement Learning is a Dataflow Problem.pdf,True,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
209,Learning to Synthesize Programs as Interpretable and Generalizable Policies.pdf,False,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
210,Iterative Teaching by Label Synthesis.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,,,,,
211,Believe What You See Implicit Constraint Approach for Offline Multi-Agent Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
212,Two steps to risk sensitivity.pdf,False,False,False,2021,neurips,neurips_2021,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
213,Heuristic-Guided Reinforcement Learning.pdf,True,True,False,2021,neurips,neurips_2021,over 10,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
214,Damped Anderson Mixing for Deep Reinforcement Learning Acceleration Convergence and Stabilization.pdf,False,True,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,td3,dqn,ddpg,,,,
215,Sim and Real Better Together.pdf,True,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ddpg,,,,,,
216,Towards Understanding Cooperative Multi-Agent Q-Learning with Value Factorization.pdf,False,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,ppo,dqn,sac,,,,
217,Settling the Variance of Multi-Agent Policy Gradients.pdf,True,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
218,Learning Collaborative Policies to Solve NP-hard Routing Problems.pdf,True,False,False,2021,neurips,neurips_2021,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,,,,,
219,Celebrating Diversity in Shared Multi-Agent Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,sac,ddpg,,,,
220,Autonomous Reinforcement Learning via Subgoal Curricula.pdf,True,True,False,2021,neurips,neurips_2021,6-10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
221,Sample-Efficient Reinforcement Learning Is Feasible for Linearly Realizable MDPs with Limited Revisi.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
222,Identifiability in inverse reinforcement learning.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
223,Provably Efficient Reinforcement Learning with Linear Function Approximation under Adaptivity Constr.pdf,False,False,False,2021,neurips,neurips_2021,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
224,Learning State Representations from Random Deep Action-conditional Predictions.pdf,True,True,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a2c,,,,,,
225,A Law of Iterated Logarithm for Multi-Agent Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
226,Dynamic Bottleneck for Robust Self-Supervised Exploration.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
227,A Max-Min Entropy Framework for Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
228,Faster Non-asymptotic Convergence for Double Q-learning.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
229,MAP Propagation Algorithm Faster Learning with a Team of Reinforcement Learning Agents.pdf,False,False,False,2021,neurips,neurips_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
230,Factored Policy Gradients Leveraging Structure for Efficient Learning in MOMDPs.pdf,False,False,False,2021,neurips,neurips_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
231,Offline Reinforcement Learning with Reverse Model-based Imagination.pdf,False,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
232,Cooperative Multi-Agent Reinforcement Learning with Sequential Credit Assignment.pdf,True,True,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
233,The Value of Information When Deciding What to Learn.pdf,True,False,False,2021,neurips,neurips_2021,6-10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
234,Is Bang-Bang Control All You Need Solving Continuous Control with Bernoulli Policies.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
235,Online and Offline Reinforcement Learning by Planning with a Learned Model.pdf,True,False,False,2021,neurips,neurips_2021,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,dqn,,,,,,
236,Functional Regularization for Reinforcement Learning via Learned Fourier Features.pdf,True,False,False,2021,neurips,neurips_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
237,Flexible Option Learning.pdf,True,True,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,a3c,ppo,a2c,,,,
238,Tuning Mixed Input Hyperparameters on the Fly for Efficient Population Based AutoRL.pdf,True,True,False,2021,neurips,neurips_2021,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,,,,,
239,Safe Pontryagin Differentiable Programming.pdf,True,True,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,trpo,ppo,,,,,
240,On the Expressivity of Markov Reward.pdf,False,False,False,2021,neurips,neurips_2021,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
241,Towards Instance-Optimal Offline Reinforcement Learning with Pessimism.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
242,Accelerating Quadratic Optimization with Reinforcement Learning.pdf,False,True,False,2021,neurips,neurips_2021,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,td3,ddpg,,,,,
243,Implicit Finite-Horizon Approximation and Efficient Optimal Algorithms for Stochastic Shortest Path.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,state-action\s+pairs,,,,,,ppo,sac,,,,,
244,Mimicking Evolution with Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,dqn,,,,,,
245,Adaptable Agent Populations via a Generative Model of Policies.pdf,False,True,False,2021,neurips,neurips_2021,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,ppo,,,,,,
246,Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations.pdf,False,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,trpo,ppo,,,,,
247,Safe Reinforcement Learning with Natural Language Constraints.pdf,True,False,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
248,Imitation with Neural Density Models.pdf,True,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
249,Bellman Eluder Dimension New Rich Classes of RL Problems and Sample-Efficient Algorithms.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,,,,,,
250,Reward-Free Model-Based Reinforcement Learning with Linear Function Approximation.pdf,False,False,False,2021,neurips,neurips_2021,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
251,Which Mutual-Information Representation Learning Objectives are Sufficient for Control.pdf,True,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
252,A Provably Efficient Sample Collection Strategy for Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
253,Reinforcement Learning with Latent Flow.pdf,True,False,False,2021,neurips,neurips_2021,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
254,A Minimalist Approach to Offline Reinforcement Learning.pdf,True,True,False,2021,neurips,neurips_2021,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,,,,,
255,Robust Inverse Reinforcement Learning under Transition Dynamics Mismatch.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
256,Improving Generalization in Meta-RL with Imaginary Tasks from Latent Dynamics Mixture.pdf,False,False,False,2021,neurips,neurips_2021,6-10,(?:discount|reward)\s+function,,,,,,,ppo,a2c,,,,,
257,Bellman-consistent Pessimism for Offline Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,other,,,,,,
258,Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning.pdf,False,False,False,2021,neurips,neurips_2021,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
259,Machine versus Human Attention in Deep Reinforcement Learning Tasks.pdf,True,False,False,2021,neurips,neurips_2021,1-5,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,sac,,,
260,Hierarchical Reinforcement Learning with Timed Subgoals.pdf,True,False,False,2021,neurips,neurips_2021,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
261,Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi.pdf,True,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
262,Reinforced Few-Shot Acquisition Function Learning for Bayesian Optimization.pdf,True,True,False,2021,neurips,neurips_2021,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
263,Reinforcement learning for optimization of variational quantum circuit architectures.pdf,True,False,False,2021,neurips,neurips_2021,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,dqn,,,,,,
264,Learning to Simulate Self-driven Particles System with Coordinated Policy Optimization.pdf,True,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,ddpg,,,,,
265,Accommodating Picky Customers Regret Bound and Exploration Complexity for Multi-Objective Reinforcem.pdf,False,False,False,2021,neurips,neurips_2021,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
266,Successor Feature Landmarks for Long-Horizon Goal-Conditioned Reinforcement Learning.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
267,Optimal Uniform OPE and Model-based Offline Reinforcement Learning in Time-Homogeneous Reward-Free a.pdf,False,False,False,2021,neurips,neurips_2021,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
268,On the Convergence and Sample Efficiency of Variance-Reduced Policy Gradient Method.pdf,False,True,False,2021,neurips,neurips_2021,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
269,Reward is enough for convex MDPs.pdf,False,False,False,2021,neurips,neurips_2021,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,dqn,,,,,
270,NovelD A Simple yet Effective Exploration Criterion.pdf,True,False,False,2021,neurips,neurips_2021,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
0,Near-Optimal Regret Bounds for Multi-batch Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
1,Redeeming intrinsic rewards via constrained optimization.pdf,True,True,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
2,A Unified Diversity Measure for Multiagent Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
3,Regret Bounds for Risk-Sensitive Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,other,,,,,,
4,On Efficient Online Imitation Learning via Classification.pdf,False,False,False,2022,neurips,neurips_2022,0,action-value\s+function,,,,,,,ppo,,,,,,
5,DOPE Doubly Optimistic and Pessimistic Exploration for Safe Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,ppo,,,,,,
6,On the Complexity of Adversarial Decision Making.pdf,False,False,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
7,Minimax-Optimal Multi-Agent RL in Markov Games With a Generative Model.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
8,Towards Safe Reinforcement Learning with a Safety Editor Policy.pdf,True,False,False,2022,neurips,neurips_2022,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
9,SlateFree a Model-Free Decomposition for Reinforcement Learning with Slate Actions.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,dqn,,,,,,
10,Grounding Aleatoric Uncertainty for Unsupervised Environment Design.pdf,True,True,False,2022,neurips,neurips_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
11,Mingling Foresight with Imagination Model-Based Cooperative Multi-Agent Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
12,Teacher Forcing Recovers Reward Functions for Text Generation.pdf,True,False,False,2022,neurips,neurips_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,ppo,,,,,,
13,Multi-Agent Reinforcement Learning is a Sequence Modeling Problem.pdf,True,True,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,ddpg,,,,
14,LAPO Latent-Variable Advantage-Weighted Policy Optimization for Offline Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
15,The Impact of Task Underspecification in Evaluating Deep Reinforcement Learning.pdf,False,True,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
16,The Pitfalls of Regularization in Off-Policy TD Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,other,,,,,,
17,Meta-Reinforcement Learning with Self-Modifying Networks.pdf,True,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
18,GALOIS Boosting Deep Reinforcement Learning via Generalizable Logic Synthesis.pdf,True,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
19,Bootstrapped Transformer for Offline Reinforcement Learning.pdf,False,True,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
20,Multi-Game Decision Transformers.pdf,True,True,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
21,Regularized Gradient Descent Ascent for Two-Player Zero-Sum Markov Games.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
22,Curriculum Reinforcement Learning using Optimal Transport via Gradual Domain Adaptation.pdf,True,False,False,2022,neurips,neurips_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
23,A Simple Decentralized Cross-Entropy Method.pdf,True,True,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,pets,ppo,sac,,,,
24,Distributional Reinforcement Learning for Risk-Sensitive Policies.pdf,False,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
25,Receding Horizon Inverse Reinforcement Learning.pdf,False,True,False,2022,neurips,neurips_2022,0,state-action\s+pairs,,,,,,,ppo,sac,,,,,
26,IMED-RL Regret optimal learning of ergodic Markov decision processes.pdf,True,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
27,Exploit Reward Shifting in Value-Based Deep-RL Optimistic Curiosity-Based Exploration and Conservati.pdf,True,True,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,dqn,sac,,,,,
28,Offline Goal-Conditioned Reinforcement Learning via f-Advantage Regression.pdf,False,True,False,2022,neurips,neurips_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,,,,
29,Towards Effective and Interpretable Human-AI Collaboration in MOBA Games.pdf,False,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
30,Near-Optimal Randomized Exploration for Tabular Markov Decision Processes.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
31,Modeling Human Exploration Through Resource-Rational Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
32,DeepFoids Adaptive Bio-Inspired Fish Simulation with Deep Reinforcement Learning.pdf,False,True,False,2022,neurips,neurips_2022,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
33,The Policy-gradient Placement and Generative Routing Neural Networks for Chip Design.pdf,True,False,False,2022,neurips,neurips_2022,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
34,Instance-Dependent Near-Optimal Policy Identification in Linear MDPs via Online Experiment Design.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,other,,,,,,
35,Scalable Multi-agent Covering Option Discovery based on Kronecker Graphs.pdf,False,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
36,A Closer Look at Offline RL Agents.pdf,True,False,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,td3,dqn,sac,,,,
37,Markovian Interference in Experiments.pdf,False,False,False,2022,neurips,neurips_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,value\s+function\s+approximation,,,,,,ppo,,,,,,
38,MoCoDA Model-based Counterfactual Data Augmentation.pdf,True,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,sac,ddpg,,,
39,Causality-driven Hierarchical Structure Discovery for Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
40,Confident Approximate Policy Iteration for Efficient Local Planning in qpi-realizable MDPs.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,,,,,ppo,,,,,,
41,Learning NP-Hard Multi-Agent Assignment Planning using GNN Inference on a Random Graph and Provable .pdf,False,False,False,2022,neurips,neurips_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
42,On the Statistical Efficiency of Reward-Free Exploration in Non-Linear RL.pdf,False,False,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
43,Planning to the Information Horizon of BAMDPs via Epistemic State Abstraction.pdf,False,False,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
44,Bilinear Exponential Family of MDPs Frequentist Regret Bound with Tractable Exploration  Planning.pdf,False,False,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
45,E-MAPP Efficient Multi-Agent Reinforcement Learning with Parallel Program Guidance.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,ddpg,,,,
46,Provably Feedback-Efficient Reinforcement Learning via Active Reward Learning.pdf,False,False,False,2022,neurips,neurips_2022,over 10,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
47,Efficient Risk-Averse Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
48,Provably Efficient Model-Free Constrained RL with Linear Function Approximation.pdf,False,False,False,2022,neurips,neurips_2022,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
49,A Unified Framework for Alternating Offline Model Training and Policy Learning.pdf,True,True,False,2022,neurips,neurips_2022,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
50,Understanding the Eluder Dimension.pdf,False,False,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,,,,,,,ppo,,,,,,
51,Mask-based Latent Reconstruction for Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
52,Grounded Reinforcement Learning Learning to Win the Game under Human Commands.pdf,False,False,False,2022,neurips,neurips_2022,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
53,Unsupervised Reinforcement Learning with Contrastive Intrinsic Control.pdf,True,True,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ddpg,,,,,,
54,Bellman Residual Orthogonalization for Offline Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,,,,ppo,sac,,,,,
55,Monte Carlo Augmented Actor-Critic for Sparse Reward Deep Reinforcement Learning from Suboptimal Dem.pdf,True,False,False,2022,neurips,neurips_2022,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
56,Model-Based Offline Reinforcement Learning with Pessimism-Modulated Dynamics Belief.pdf,True,True,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
57,Large-Scale Retrieval for Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,,,,,,
58,Online Reinforcement Learning for Mixed Policy Scopes.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
59,Near-optimal Distributional Reinforcement Learning towards Risk-sensitive Control.pdf,False,False,False,2022,neurips,neurips_2022,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
60,Reinforcement Learning with a Terminator.pdf,True,False,False,2022,neurips,neurips_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,sac,,,,,
61,Robust On-Policy Sampling for Data-Efficient Policy Evaluation in Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
62,Near-Optimal Regret for Adversarial MDP with Delayed Bandit Feedback.pdf,False,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,,,,,,,ppo,,,,,,
63,LDSA Learning Dynamic Subtask Assignment in Cooperative Multi-Agent Reinforcement Learning.pdf,False,True,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
64,Spectrum Random Masking for Generalization in Image-based Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
65,Explainable Reinforcement Learning via Model Transforms.pdf,True,False,False,2022,neurips,neurips_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
66,DASCO Dual-Generator Adversarial Support Constrained Offline Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
67,Sym-NCO Leveraging Symmetricity for Neural Combinatorial Optimization.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
68,The Nature of Temporal Difference Errors in Multi-step Distributional Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
69,Policy Gradient With Serial Markov Chain Reasoning.pdf,False,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
70,TabNAS Rejection Sampling for Neural Architecture Search on Tabular Datasets.pdf,True,True,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
71,Learning Generalizable Risk-Sensitive Policies to Coordinate in Decentralized Multi-Agent General-Su.pdf,False,True,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,sac,,,,
72,A Mean-Field Game Approach to Cloud Resource Management with Function Approximation.pdf,True,False,False,2022,neurips,neurips_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
73,Distributional Reward Estimation for Effective Multi-agent Deep Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,,,,
74,You Only Live Once Single-Life Reinforcement Learning.pdf,False,True,False,2022,neurips,neurips_2022,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
75,Provable Defense against Backdoor Policies in Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
76,Distributionally Adaptive Meta Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
77,Stochastic Second-Order Methods Improve Best-Known Sample Complexity of SGD for Gradient-Dominated F.pdf,True,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
78,Inherently Explainable Reinforcement Learning in Natural Language.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
79,Bayesian Optimistic Optimization Optimistic Exploration for Model-based Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
80,Unsupervised Skill Discovery via Recurrent Skill Training.pdf,False,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
81,A Ranking Game for Imitation Learning.pdf,False,False,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
82,Deep Hierarchical Planning from Pixels.pdf,False,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dreamer,,,,,
83,Best of Both Worlds Model Selection.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
84,Finding Correlated Equilibrium of Constrained Markov Game A Primal-Dual Approach.pdf,False,False,False,2022,neurips,neurips_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
85,BYOL-Explore Exploration by Bootstrapped Prediction.pdf,False,True,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
86,Active Exploration for Inverse Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,other,,,,,,
87,Non-Markovian Reward Modelling from Trajectory Labels via Interpretable Multiple Instance Learning.pdf,True,True,False,2022,neurips,neurips_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
88,Learning to Branch with Tree MDPs.pdf,True,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
89,Contrastive Learning as Goal-Conditioned Reinforcement Learning.pdf,True,True,False,2022,neurips,neurips_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,,,,,,
90,Heterogeneous Skill Learning for Multi-agent Tasks.pdf,True,False,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
91,On Reinforcement Learning and Distribution Matching for Fine-Tuning Language Models with no Catastro.pdf,True,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
92,VRL3 A Data-Driven Framework for Visual Deep Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,other,,,,,,
93,Simulation-guided Beam Search for Neural Combinatorial Optimization.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
94,Uncertainty-Aware Reinforcement Learning for Risk-Sensitive Player Evaluation in Sports Game.pdf,False,False,False,2022,neurips,neurips_2022,1-5,action-value\s+function,state-action\s+pairs,,,,,,ppo,dqn,,,,,
95,Incrementality Bidding via Reinforcement Learning under Mixed and Delayed Rewards.pdf,False,False,False,2022,neurips,neurips_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
96,Offline Multi-Agent Reinforcement Learning with Knowledge Distillation.pdf,False,False,False,2022,neurips,neurips_2022,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,dqn,,,,,
97,Exponential Family Model-Based Reinforcement Learning via Score Matching.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
98,Relational Reasoning via Set Transformers Provable Efficiency and Applications to MARL.pdf,False,False,False,2022,neurips,neurips_2022,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
99,Enhanced Meta Reinforcement Learning via Demonstrations in Sparse Reward Environments.pdf,True,False,False,2022,neurips,neurips_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,dqn,,,,,
100,Identifiability and generalizability from multiple experts in Inverse Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
101,SHAQ Incorporating Shapley Value Theory into Multi-Agent Q-Learning.pdf,True,True,False,2022,neurips,neurips_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,ppo,dqn,ddpg,sac,,,
102,Plan To Predict Learning an Uncertainty-Foreseeing Model For Model-Based Reinforcement Learning.pdf,True,True,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
103,DNA Proximal Policy Optimization with a Dual Network Architecture.pdf,True,False,False,2022,neurips,neurips_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,,,,,
104,DMAP a Distributed Morphological Attention Policy for learning to locomote with a changing body.pdf,True,True,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
105,PaCo Parameter-Compositional Multi-task Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
106,Curious Exploration via Structured World Models Yields Zero-Shot Object Manipulation.pdf,True,False,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
107,Disentangling Transfer in Continual Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
108,A Mixture Of Surprises for Unsupervised Reinforcement Learning.pdf,True,True,False,2022,neurips,neurips_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,ddpg,,,,,
109,ResQ A Residual Q Function-based Approach for Multi-Agent Reinforcement Learning Value Factorization.pdf,True,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,,,,,,,ppo,dqn,,,,,
110,Interaction-Grounded Learning with Action-Inclusive Feedback.pdf,False,False,False,2022,neurips,neurips_2022,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
111,Proximal Learning With Opponent-Learning Awareness.pdf,True,True,False,2022,neurips,neurips_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
112,Challenging Common Assumptions in Convex Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,other,,,,,,
113,Enhancing Safe Exploration Using Safety State Augmentation.pdf,True,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,trpo,ppo,dqn,,,,
114,Learn what matters cross-domain imitation learning with task-relevant embeddings.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
115,Mismatched No More Joint Model-Policy Optimization for Model-Based RL.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
116,Distributional Reinforcement Learning via Sinkhorn Iterations.pdf,True,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
117,Optimistic Posterior Sampling for Reinforcement Learning with Few Samples and Tight Guarantees.pdf,True,False,False,2022,neurips,neurips_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,value\s+function\s+approximation,,,,,,ppo,dqn,,,,,
118,Why So Pessimistic Estimating Uncertainties for Offline RL through Ensembles and Why Their Independe.pdf,False,True,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
119,A Near-Optimal Primal-Dual Method for Off-Policy Learning in CMDP.pdf,False,False,False,2022,neurips,neurips_2022,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
120,Learn to Match with No Regret Reinforcement Learning in Markov Matching Markets.pdf,False,False,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
121,Sample-Efficient Reinforcement Learning of Partially Observable Markov Games.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
122,On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning.pdf,True,True,False,2022,neurips,neurips_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
123,Look where you look Saliency-guided Q-networks for generalization in visual Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,sac,,,,
124,Assistive Teaching of Motor Control Tasks to Humans.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
125,Learning Options via Compression.pdf,True,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
126,Follow-the-Perturbed-Leader for Adversarial Markov Decision Processes with Bandit Feedback.pdf,False,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,,,,,,,ppo,,,,,,
127,Quantile Constrained Reinforcement Learning A Reinforcement Learning Framework Constraining Outage P.pdf,True,False,False,2022,neurips,neurips_2022,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
128,Stationary Deep Reinforcement Learning with Quantum K-spin Hamiltonian Equation.pdf,False,False,False,2022,neurips,neurips_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
129,When are Offline Two-Player Zero-Sum Markov Games Solvable.pdf,False,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,,,,,,,ppo,,,,,,
130,Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs.pdf,False,False,False,2022,neurips,neurips_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,other,,,,,,
131,Rethinking Value Function Learning for Generalization in Reinforcement Learning.pdf,True,True,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
132,Towards Skill and Population Curriculum for MARL.pdf,False,False,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
133,The Role of Baselines in Policy Gradient Optimization.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
134,Multi-agent Dynamic Algorithm Configuration.pdf,True,True,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
135,Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees.pdf,True,True,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
136,Action-modulated midbrain dopamine activity arises from distributed control policies.pdf,True,False,False,2022,neurips,neurips_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,a2c,sac,,,
137,Efficient Adversarial Training without Attacking Worst-Case-Aware Robust Reinforcement Learning.pdf,True,True,False,2022,neurips,neurips_2022,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
138,Using natural language and program abstractions to instill human inductive biases in machines.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,a2c,,,,,
139,Truly Deterministic Policy Optimization.pdf,True,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,td3,ppo,ddpg,,,
140,A Non-asymptotic Analysis of Non-parametric Temporal-Difference Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
141,You Cant Count on Luck Why Decision Transformers and RvS Fail in Stochastic Environments.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
142,Learning to Attack Federated Learning A Model-based Reinforcement Learning Attack Framework.pdf,True,False,False,2022,neurips,neurips_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,other,,,,,,
143,CEIP Combining Explicit and Implicit Priors for Reinforcement Learning with Demonstrations.pdf,True,False,False,2022,neurips,neurips_2022,6-10,state-action\s+pairs,,,,,,,ppo,,,,,,
144,Recursive Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
145,Empirical Gateaux Derivatives for Causal Inference.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
146,Learning Infinite-Horizon Average-Reward Restless Multi-Action Bandits via Index Awareness.pdf,False,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
147,Learning General World Models in a Handful of Reward-Free Deployments.pdf,True,False,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dreamer,,,,,
148,Provable General Function Class Representation Learning in Multitask Bandits and MDP.pdf,False,False,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,other,,,,,,
149,Surprise-Guided Search for Learning Task Specifications From Demonstrations.pdf,False,False,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
150,Pessimism for Offline Linear Contextual Bandits using ell_p Confidence Sets.pdf,False,False,False,2022,neurips,neurips_2022,over 10,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
151,Open-Ended Reinforcement Learning with Neural Reward Functions.pdf,True,False,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,sac,a2c,,,,
152,First Contact Unsupervised Human-Machine Co-Adaptation via Mutual Information Maximization.pdf,True,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,other,,,,,,
153,Leveraging Factored Action Spaces for Efficient Offline Reinforcement Learning in Healthcare.pdf,True,False,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
154,A Deep Reinforcement Learning Framework for Column Generation.pdf,False,True,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
155,Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels.pdf,False,False,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,sac,,,,,
156,Improving Policy Learning via Language Dynamics Distillation.pdf,True,False,False,2022,neurips,neurips_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
157,When to Update Your Model Constrained Model-based Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,sac,,,,
158,A Theoretical Understanding of Gradient Bias in Meta-Reinforcement Learning.pdf,True,True,False,2022,neurips,neurips_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,a2c,,,,,
159,Operator Splitting Value Iteration.pdf,False,False,False,2022,neurips,neurips_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
160,Giving Feedback on Interactive Student Programs with Meta-Exploration.pdf,True,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
161,Reincarnating Reinforcement Learning Reusing Prior Computation to Accelerate Progress.pdf,True,False,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,,,,
162,Robust Reinforcement Learning using Offline Data.pdf,True,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,dqn,ddpg,,,,
163,Uniqueness and Complexity of Inverse MDP Models.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
164,Constrained GPI for Zero-Shot Transfer in Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
165,On the role of overparameterization in off-policy Temporal Difference learning with linear function .pdf,False,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,,,,,,,ppo,,,,,,
166,Oracle Inequalities for Model Selection in Offline Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
167,Learning Distributed and Fair Policies for Network Load Balancing as Markov Potential Game.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
168,Exploration-Guided Reward Shaping for Reinforcement Learning under Sparse Rewards.pdf,True,False,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,,,,,,
169,RAMBO-RL Robust Adversarial Model-Based Offline Reinforcement Learning.pdf,True,True,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,sac,,,,,,
170,Non-Linear Coordination Graphs.pdf,True,False,False,2022,neurips,neurips_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,,,,,ppo,dqn,ddpg,sac,,,
171,Globally Convergent Policy Search for Output Estimation.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
172,Faster Deep Reinforcement Learning with Slower Online Network.pdf,True,True,False,2022,neurips,neurips_2022,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,trpo,td3,ppo,dqn,,,
173,Learning to Find Proofs and Theorems by Learning to Refine Search Strategies The Case of Loop Invari.pdf,False,False,False,2022,neurips,neurips_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,,,,,,ppo,,,,,,
174,Near-Optimal Sample Complexity Bounds for Constrained MDPs.pdf,False,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
175,Asynchronous Actor-Critic for Multi-Agent Reinforcement Learning.pdf,True,True,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,sac,,,,,,
176,WebShop Towards Scalable Real-World Web Interaction with Grounded Language Agents.pdf,False,True,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
177,Multiagent Q-learning with Sub-Team Coordination.pdf,True,False,False,2022,neurips,neurips_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
178,An Adaptive Deep RL Method for Non-Stationary Environments with Piecewise Stable Context.pdf,True,False,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
179,Distributed Inverse Constrained Reinforcement Learning for Multi-agent Systems.pdf,False,False,False,2022,neurips,neurips_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
180,EAGER Asking and Answering Questions for Automatic Reward Shaping in Language-guided RL.pdf,True,False,False,2022,neurips,neurips_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
181,Anchor-Changing Regularized Natural Policy Gradient for Multi-Objective Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
182,Provably Efficient Offline Multi-agent Reinforcement Learning via Strategy-wise Bonus.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
183,Provably sample-efficient RL with side information about latent dynamics.pdf,True,True,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
184,TarGF Learning Target Gradient Field to Rearrange Objects without Explicit Goal Specification.pdf,True,True,False,2022,neurips,neurips_2022,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,sac,,,,,,
185,Exploration via Elliptical Episodic Bonuses.pdf,True,True,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
186,When to Ask for Help Proactive Interventions in Autonomous Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
187,Masked Autoencoding for Scalable and Generalizable Decision Making.pdf,True,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,,,,,,
188,PAC Assisted Value Factorization with Counterfactual Predictions in Multi-Agent Reinforcement Learni.pdf,True,True,False,2022,neurips,neurips_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,dqn,,,,,
189,Provably Efficient Reinforcement Learning in Partially Observable Dynamical Systems.pdf,False,False,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,,,,,,,ppo,,,,,,
190,Understanding Deep Neural Function Approximation in Reinforcement Learning via epsilon-Greedy Explor.pdf,False,False,False,2022,neurips,neurips_2022,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,ppo,dqn,sac,,,,
191,ALMA Hierarchical Learning for Composite Multi-Agent Tasks.pdf,True,True,False,2022,neurips,neurips_2022,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,ppo,sac,,,,,
192,Value Function Decomposition for Iterative Design of Reinforcement Learning Agents.pdf,False,False,False,2022,neurips,neurips_2022,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,dqn,sac,,,,,
193,Global Convergence of Direct Policy Search for State-Feedback mathcalH_infty Robust Control A Revisi.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
194,Integrating Symmetry into Differentiable Planning.pdf,True,False,False,2022,neurips,neurips_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
195,Meta Reinforcement Learning with Finite Training Tasks - a Density Estimation Approach.pdf,False,False,False,2022,neurips,neurips_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,,,,,,
196,A Policy-Guided Imitation Approach for Offline Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,,,,,,
197,Model-based Lifelong Reinforcement Learning with Bayesian Exploration.pdf,True,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,pets,dreamer,ppo,dqn,,,
198,Adaptive Interest for Emphatic Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
199,Robust Imitation via Mirror Descent Inverse Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
200,Continuous Deep Q-Learning in Optimal Control Problems Normalized Advantage Functions Analysis.pdf,False,False,False,2022,neurips,neurips_2022,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,,,,
201,Object-Category Aware Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,sac,,,,,,
202,On Gap-dependent Bounds for Offline Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
203,Multifidelity Reinforcement Learning with Control Variates.pdf,False,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
204,The Phenomenon of Policy Churn.pdf,False,False,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
205,Supported Policy Optimization for Offline Reinforcement Learning.pdf,True,True,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,td3,ppo,dqn,,,
206,CUP Critic-Guided Policy Reuse.pdf,True,False,False,2022,neurips,neurips_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
207,Sample-Efficient Learning of Correlated Equilibria in Extensive-Form Games.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
208,Reinforcement Learning with Logarithmic Regret and Policy Switches.pdf,False,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,other,,,,,,
209,Sustainable Online Reinforcement Learning for Auto-bidding.pdf,True,False,False,2022,neurips,neurips_2022,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,,,,,
210,Data-Efficient Pipeline for Offline Reinforcement Learning with Limited Data.pdf,False,True,False,2022,neurips,neurips_2022,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
211,Beyond Rewards a Hierarchical Perspective on Offline Multiagent Behavioral Analysis.pdf,True,True,False,2022,neurips,neurips_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,,,,
212,ProtoX Explaining a Reinforcement Learning Agent via Prototyping.pdf,True,True,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
213,TTOpt A Maximum Volume Quantized Tensor Train-based Optimization and its Application to Reinforcemen.pdf,True,True,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
214,S2P State-conditioned Image Synthesis for Data Augmentation in Offline Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
215,CodeRL Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,other,,,,,,
216,RORL Robust Offline Reinforcement Learning via Conservative Smoothing.pdf,True,False,False,2022,neurips,neurips_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
217,Batch size-invariance for policy optimization.pdf,True,True,False,2022,neurips,neurips_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,,,,,
218,Efficient Multi-agent Communication via Self-supervised Information Aggregation.pdf,True,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
219,Direct Advantage Estimation.pdf,True,True,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,,,,,,
220,Robust Option Learning for Adversarial Generalization.pdf,False,False,False,2022,neurips,neurips_2022,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,sac,,,
221,Deciding What to Model Value-Equivalent Sampling for Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
222,A Boosting Approach to Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
223,Self-Organized Group for Cooperative Multi-agent Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,,,,
224,MaskPlace Fast Chip Placement via Reinforced Visual Representation Learning.pdf,False,False,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
225,Mildly Conservative Q-Learning for Offline Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
226,Discrete Compositional Representations as an Abstraction for Goal Conditioned Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
227,Rethinking Individual Global Max in Cooperative Multi-Agent Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,ppo,sac,,,,,
228,Constrained Update Projection Approach to Safe Policy Optimization.pdf,True,True,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,,,,,trpo,ppo,,,,,
229,Reinforcement Learning in a Birth and Death Process Breaking the Dependence on the State Space.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
230,Learning Robust Dynamics through Variational Sparse Gating.pdf,True,True,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dqn,ddpg,sac,td3,ppo,dreamer,
231,On the Effect of Pre-training for Transformer in Different Modality on Offline Reinforcement Learnin.pdf,True,True,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
232,Trajectory balance Improved credit assignment in GFlowNets.pdf,True,False,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
233,Provable Benefit of Multitask Representation Learning in Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
234,Max-Min Off-Policy Actor-Critic Method Focusing on Worst-Case Robustness to Model Misspecification.pdf,True,False,False,2022,neurips,neurips_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,td3,ddpg,,,,
235,PCRL Priority Convention Reinforcement Learning for Microscopically Sequencable Multi-agent Problems.pdf,False,True,False,2022,neurips,neurips_2022,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,ppo,dqn,,,,,
236,Uncertainty Estimation Using Riemannian Model Dynamics for Offline Reinforcement Learning.pdf,False,True,False,2022,neurips,neurips_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
237,Influencing Long-Term Behavior in Multiagent Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
238,Human-Robotic Prosthesis as Collaborating Agents for Symmetrical Walking.pdf,False,True,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,ppo,sac,ddpg,,,
239,Distributed Influence-Augmented Local Simulators for Parallel MARL in Large Networked Systems.pdf,True,False,False,2022,neurips,neurips_2022,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
240,Meta-Reward-Net Implicitly Differentiable Reward Learning for Preference-based Reinforcement Learnin.pdf,True,False,False,2022,neurips,neurips_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
241,Model-based Safe Deep Reinforcement Learning via a Constrained Proximal Policy Optimization Algorith.pdf,True,True,False,2022,neurips,neurips_2022,6-10,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
242,Parametrically Retargetable Decision-Makers Tend To Seek Power.pdf,False,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
243,Iso-Dream Isolating and Leveraging Noncontrollable Visual Dynamics in World Models.pdf,True,False,False,2022,neurips,neurips_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,,,,,,,ppo,dreamer,,,,,
244,I2Q A Fully Decentralized Q-Learning Algorithm.pdf,False,False,False,2022,neurips,neurips_2022,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,sac,,,
245,Dynamic Inverse Reinforcement Learning for Characterizing Animal Behavior.pdf,True,False,False,2022,neurips,neurips_2022,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,other,,,,,,
246,Instance-optimal PAC Algorithms for Contextual Bandits.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
247,Near Instance-Optimal PAC Reinforcement Learning for Deterministic MDPs.pdf,True,False,False,2022,neurips,neurips_2022,6-10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
248,Policy Optimization for Markov Games Unified Framework and Faster Convergence.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,dqn,,,,,,
249,SPD Synergy Pattern Diversifying Oriented Unsupervised Multi-agent Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
250,Distinguishing Learning Rules with Brain Machine Interfaces.pdf,False,False,False,2022,neurips,neurips_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,other,,,,,,
251,Generalizing Goal-Conditioned Reinforcement Learning with Variational Causal Reasoning.pdf,True,False,False,2022,neurips,neurips_2022,6-10,(?:discount|reward)\s+function,,,,,,,pets,ppo,dqn,sac,,,
252,Improving Zero-Shot Generalization in Offline Reinforcement Learning using Generalized Similarity Fu.pdf,True,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
253,Continuous MDP Homomorphisms and Homomorphic Policy Gradient.pdf,True,True,False,2022,neurips,neurips_2022,6-10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,ddpg,sac,td3,ppo,,
254,Models of human preference for learning reward functions.pdf,False,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
255,Exploration via Planning for Information about the Optimal Trajectory.pdf,True,False,False,2022,neurips,neurips_2022,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,pets,td3,ppo,sac,,,
256,Off-Policy Evaluation for Episodic Partially Observable Markov Decision Processes under Non-Parametr.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
257,PALMER Perception - Action Loop with Memory for Long-Horizon Planning.pdf,False,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
258,A Unified Framework for Deep Symbolic Regression.pdf,True,True,False,2022,neurips,neurips_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
259,Skills Regularized Task Decomposition for Multi-task Offline Reinforcement Learning.pdf,False,True,False,2022,neurips,neurips_2022,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,,,,,,
260,Learning to Share in Networked Multi-Agent Reinforcement Learning.pdf,True,True,False,2022,neurips,neurips_2022,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,,,,
261,Pre-Trained Image Encoder for Generalizable Visual Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,sac,,,,,,
262,Factored Adaptation for Non-Stationary Reinforcement Learning.pdf,False,True,False,2022,neurips,neurips_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
263,Off-Team Learning.pdf,True,False,False,2022,neurips,neurips_2022,1-5,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
264,Learning in Congestion Games with Bandit Feedback.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
265,Policy Optimization with Linear Temporal Logic Constraints.pdf,False,False,False,2022,neurips,neurips_2022,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
266,Efficient Scheduling of Data Augmentation for Deep Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
267,Alleviating Posterior Collapse in Deep Topic Models via Policy Gradient.pdf,True,False,False,2022,neurips,neurips_2022,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,ppo,,,,,,
268,Near-Optimal Goal-Oriented Reinforcement Learning in Non-Stationary Environments.pdf,False,False,False,2022,neurips,neurips_2022,0,state-action\s+pairs,,,,,,,ppo,,,,,,
269,Off-Policy Evaluation for Action-Dependent Non-stationary Environments.pdf,True,False,False,2022,neurips,neurips_2022,over 10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
270,Towards Trustworthy Automatic Diagnosis Systems by Emulating Doctors Reasoning  with Deep Reinforcem.pdf,False,False,False,2022,neurips,neurips_2022,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
271,Learning to Follow Instructions in Text-Based Games.pdf,True,False,False,2022,neurips,neurips_2022,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
272,Off-Beat Multi-Agent Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
273,Improving Intrinsic Exploration with Language Abstractions.pdf,True,True,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
274,A Few Expert Queries Suffices for Sample-Efficient RL with Resets and Linear Value Approximation.pdf,False,False,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,,,,,ppo,,,,,,
275,Tiered Reinforcement Learning Pessimism in the Face of Uncertainty and Constant Regret.pdf,False,False,False,2022,neurips,neurips_2022,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,sac,,,,,,
276,When to Trust Your Simulator Dynamics-Aware Hybrid Offline-and-Online Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,sac,,,,,,
277,Faster Reinforcement Learning with Value Target Lower Bounding.pdf,False,False,False,2022,neurips,neurips_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
278,A Direct Approximation of AIXI Using Logical State Abstractions.pdf,False,False,False,2022,neurips,neurips_2022,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
279,Hardness in Markov Decision Processes Theory and Practice.pdf,True,True,False,2022,neurips,neurips_2022,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,,ppo,dqn,,,,,
280,DOMINO Decomposed Mutual Information Optimization for Generalized Context in Meta-Reinforcement Lear.pdf,False,False,False,2022,neurips,neurips_2022,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
281,PerfectDou Dominating DouDizhu with Perfect Information Distillation.pdf,True,False,False,2022,neurips,neurips_2022,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
282,Learning Representations via a Robust Behavioral Metric for Deep Reinforcement Learning.pdf,True,False,False,2022,neurips,neurips_2022,1-5,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
283,LECO Learnable Episodic Count for Task-Specific Intrinsic Reward.pdf,True,True,False,2022,neurips,neurips_2022,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
284,DHRL A Graph-Based Approach for Long-Horizon and Sparse Hierarchical Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
285,Reinforcement Learning with Non-Exponential Discounting.pdf,False,True,False,2022,neurips,neurips_2022,6-10,(?:discount|reward)\s+function,,,,,,,other,,,,,,
286,Efficient Meta Reinforcement Learning for Preference-based Fast Adaptation.pdf,True,False,False,2022,neurips,neurips_2022,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
287,Doubly-Asynchronous Value Iteration Making Value Iteration Asynchronous in Actions.pdf,False,False,False,2022,neurips,neurips_2022,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
288,Regret Bounds for Information-Directed Reinforcement Learning.pdf,False,True,False,2022,neurips,neurips_2022,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
289,ASPiRe Adaptive Skill Priors for  Reinforcement Learning.pdf,False,False,False,2022,neurips,neurips_2022,6-10,(?:discount|reward)\s+function,,,,,,,sac,,,,,,
0,Self-Predictive Universal AI.pdf,False,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,,,,,,sac,,,,,,
1,Regret-Optimal Model-Free Reinforcement Learning for Discounted MDPs with Short Burn-In Time.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
2,Bayesian Risk-Averse Q-Learning with Streaming Observations.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
3,Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation Minimax Optimal .pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
4,Computing Optimal Equilibria and Mechanisms via Learning in Zero-Sum Extensive-Form Games.pdf,False,True,False,2023,neurips,neurips_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
5,Posterior Sampling with Delayed Feedback for Reinforcement Learning with Linear Function Approximati.pdf,False,True,False,2023,neurips,neurips_2023,0,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
6,Distributional Policy Evaluation a Maximum Entropy approach to Representation Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
7,Winner Takes It All Training Performant RL Populations for Combinatorial Optimization.pdf,True,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
8,Synthetic Experience Replay.pdf,True,True,False,2023,neurips,neurips_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,dqn,sac,,,,
9,Combining Behaviors with the Successor Features Keyboard.pdf,True,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,a3c,ppo,dqn,,,,
10,Provably Robust Temporal Difference Learning for Heavy-Tailed Rewards.pdf,False,False,False,2023,neurips,neurips_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,ppo,sac,,,,
11,On the Importance of Exploration for Generalization in Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,dreamer,ppo,dqn,,,,
12,Policy Space Diversity for Non-Transitive Games.pdf,True,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,sac,,,
13,ELDEN Exploration via Local Dependencies.pdf,False,False,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
14,Revisiting the Minimalist Approach to Offline Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,dqn,sac,td3,ppo,,
15,Multi-Step Generalized Policy Improvement by Leveraging Approximate Models.pdf,True,False,False,2023,neurips,neurips_2023,0,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,pets,dqn,sac,ppo,dreamer,,
16,Double Gumbel Q-Learning.pdf,True,True,False,2023,neurips,neurips_2023,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,trpo,dqn,ddpg,sac,td3,ppo,
17,Optimistic Natural Policy Gradient a Simple Efficient Policy Optimization Framework  for Online RL.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
18,Design from Policies Conservative Test-Time Adaptation for Offline Policy Optimization.pdf,True,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,,,,
19,Blockwise Parallel Transformers for Large Context Models.pdf,True,True,False,2023,neurips,neurips_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
20,Flexible Attention-Based Multi-Policy Fusion for Efficient Deep Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
21,Trust Region-Based Safe Distributional Reinforcement Learning for Multiple Constraints.pdf,True,True,False,2023,neurips,neurips_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,ppo,sac,a2c,,,
22,Direct Preference Optimization Your Language Model is Secretly a Reward Model.pdf,True,True,False,2023,neurips,neurips_2023,over 10,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
23,Taylor TD-learning.pdf,True,True,False,2023,neurips,neurips_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,dqn,sac,td3,ppo,,
24,Boosting Verification of Deep Reinforcement Learning via Piece-Wise Linear Decision Neural Networks.pdf,False,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,ddpg,,,,
25,Contrastive Modules with Temporal Attention for Multi-Task Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
26,Can Pre-Trained Text-to-Image Models Generate Visual Goals for Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,td3,ddpg,,,,,
27,RePo Resilient Model-Based Reinforcement Learning by Regularizing Posterior Predictability.pdf,False,False,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,td-mpc,dreamer,ppo,sac,,,
28,Provably More Sample-Efficient Offline RL with Options.pdf,False,False,False,2023,neurips,neurips_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
29,Learning Multi-agent Behaviors from Distributed and Streaming Demonstrations.pdf,False,False,False,2023,neurips,neurips_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,dqn,sac,,,,,
30,Belief Projection-Based Reinforcement Learning for Environments with Delayed Feedback.pdf,False,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,trpo,dqn,sac,td3,ppo,,
31,RL-based Stateful Neural Adaptive Sampling and Denoising for Real-Time Path Tracing.pdf,True,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
32,Seeing is not Believing Robust Reinforcement Learning against Spurious Correlation.pdf,False,False,False,2023,neurips,neurips_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,sac,,,,,,
33,When is Agnostic Reinforcement Learning Statistically Tractable.pdf,False,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,ppo,,,,,,
34,Contrastive Retrospection honing in on critical steps for rapid learning and generalization in RL.pdf,True,False,False,2023,neurips,neurips_2023,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,a2c,,,,
35,Off-Policy Evaluation for Human Feedback.pdf,True,True,False,2023,neurips,neurips_2023,1-5,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
36,PLASTIC Improving Input and Label Plasticity for Sample Efficient Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,dreamer,ppo,dqn,sac,,,
37,StateMask Explaining Deep Reinforcement Learning through State Mask.pdf,True,False,False,2023,neurips,neurips_2023,over 10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,trpo,ppo,sac,pets,,,
38,Fine-Grained Human Feedback Gives Better Rewards for Language Model Training.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,pets,ppo,sac,,,,
39,Tempo Adaptation in Non-stationary Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,sac,,,,,,
40,Keep Various Trajectories Promoting Exploration of Ensemble Policies in Continuous Control.pdf,False,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,dqn,ddpg,sac,,,
41,Constrained Policy Optimization with Explicit Behavior Density For Offline Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,ppo,dqn,,,,
42,Efficient Symbolic Policy Learning with Differentiable Symbolic Expression.pdf,True,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,trpo,dqn,ddpg,sac,a2c,td3,ppo
43,Hybrid Policy Optimization from Imperfect Demonstrations.pdf,True,False,False,2023,neurips,neurips_2023,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
44,State2Explanation Concept-Based Explanations to Benefit Agent Learning and User Understanding.pdf,True,True,False,2023,neurips,neurips_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
45,Efficient RL with Impaired Observability Learning to Act with Delayed and Missing State Observations.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
46,Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence.pdf,False,False,False,2023,neurips,neurips_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
47,Probabilistic Inference in Reinforcement Learning Done Right.pdf,False,False,False,2023,neurips,neurips_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
48,Recovering from Out-of-sample States via Inverse Dynamics in Offline Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
49,Anytime-Competitive Reinforcement Learning with Policy Prior.pdf,False,False,False,2023,neurips,neurips_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
50,Combinatorial Optimization with Policy Adaptation using Latent Space Search.pdf,True,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
51,Goal-conditioned Offline Planning from Curious Exploration.pdf,True,True,False,2023,neurips,neurips_2023,over 10,(?:discount|reward)\s+function,,,,,,,dqn,ddpg,sac,td3,ppo,,
52,AlpacaFarm A Simulation Framework for Methods that Learn from Human Feedback.pdf,True,True,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
53,Elastic Decision Transformer.pdf,True,True,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
54,Interpretable Reward Redistribution in Reinforcement Learning A Causal Approach.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,sac,ddpg,,,
55,Deep Reinforcement Learning with Plasticity Injection.pdf,True,True,False,2023,neurips,neurips_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,dqn,,,,,
56,Optimistic Active Exploration of Dynamical Systems.pdf,True,True,False,2023,neurips,neurips_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,pets,ppo,sac,,,,
57,On Sample-Efficient Offline Reinforcement Learning Data Diversity Posterior Sampling and Beyond.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
58,Information Design in Multi-Agent Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,a2c,,,,,
59,Accountability in Offline Reinforcement Learning Explaining Decisions with a Corpus of Examples.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,dqn,sac,td3,ppo,,
60,The Curious Price of Distributional Robustness in Reinforcement Learning with a Generative Model.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,ddpg,,,,,
61,A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processe.pdf,False,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
62,A Novel Framework for Policy Mirror Descent with General Parameterization and Linear Convergence.pdf,False,False,False,2023,neurips,neurips_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,,,,
63,Would I have gotten that reward Long-term credit assignment by counterfactual contribution analysis.pdf,True,True,False,2023,neurips,neurips_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
64,Small batch deep reinforcement learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
65,RiskQ Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization.pdf,True,False,False,2023,neurips,neurips_2023,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
66,Domain Adaptive Imitation Learning with Visual Observation.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
67,MAG-GNN Reinforcement Learning Boosted Graph Neural Network.pdf,True,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
68,Decision Stacks Flexible Reinforcement Learning via Modular Generative Models.pdf,False,False,False,2023,neurips,neurips_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
69,Learning Regularized Monotone Graphon Mean-Field Games.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,other,,,,,,
70,Behavior Alignment via Reward Function Optimization.pdf,False,False,False,2023,neurips,neurips_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
71,Kernelized Reinforcement Learning with Order Optimal Regret Bounds.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,other,,,,,,
72,Extracting Reward Functions from Diffusion Models.pdf,True,False,False,2023,neurips,neurips_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
73,Safe Exploration in Reinforcement Learning A Generalized Formulation and Algorithms.pdf,True,False,False,2023,neurips,neurips_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,trpo,td3,ppo,sac,,,
74,Diverse Conventions for Human-AI Collaboration.pdf,False,True,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
75,Connected Superlevel Set in Deep Reinforcement Learning and its Application to Minimax Theorems.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
76,Learning from Active Human Involvement through Proxy Value Propagation.pdf,True,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
77,Residual Q-Learning Offline and Online Policy Customization without Value.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
78,Provably Efficient Offline Goal-Conditioned Reinforcement Learning with General Function Approximati.pdf,True,False,False,2023,neurips,neurips_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,other,,,,,,
79,Decision-Aware Actor-Critic with Function Approximation and Theoretical Guarantees.pdf,True,True,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,trpo,ppo,dqn,sac,,,
80,Bayesian Learning of Optimal Policies in Markov Decision Processes with Countably Infinite State-Spa.pdf,False,False,False,2023,neurips,neurips_2023,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
81,Understanding and Addressing the Pitfalls of Bisimulation-based Representations in Offline Reinforce.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,sac,,,,
82,Loss Dynamics of Temporal Difference Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
83,Mutual Information Regularized Offline Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,td3,dqn,sac,,,
84,Inverse Reinforcement Learning with the Average Reward Criterion.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
85,Language Model Alignment with Elastic Reset.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,trpo,ppo,sac,,,,
86,For SALE State-Action Representation Learning for Deep Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,trpo,dqn,sac,td3,ppo,,
87,TD Convergence An Optimization Perspective.pdf,False,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
88,Offline Multi-Agent Reinforcement Learning with Implicit Global-to-Local Value Regularization.pdf,True,False,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
89,Model-Free Reinforcement Learning with the Decision-Estimation Coefficient.pdf,False,False,False,2023,neurips,neurips_2023,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
90,FlowPG Action-constrained Policy Gradient with Normalizing Flows.pdf,True,True,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,ppo,dqn,ddpg,sac,,,
91,Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction.pdf,True,True,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
92,Hierarchical Multi-Agent Skill Discovery.pdf,False,False,False,2023,neurips,neurips_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
93,Reward-agnostic Fine-tuning Provable Statistical Benefits of Hybrid Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
94,Effectively Learning Initiation Sets in Hierarchical Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,sac,,,,
95,Sample Efficient Reinforcement Learning in Mixed Systems through Augmented Samples and Its Applicati.pdf,False,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,dqn,sac,,,,
96,When Demonstrations meet Generative World Models A Maximum Likelihood Framework for Offline Inverse .pdf,True,False,False,2023,neurips,neurips_2023,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
97,Beyond Uniform Sampling Offline Reinforcement Learning with Imbalanced Datasets.pdf,True,False,False,2023,neurips,neurips_2023,1-5,state-action\s+pairs,,,,,,,td3,ppo,dqn,sac,,,
98,Long-Term Fairness with Unknown Dynamics.pdf,False,False,False,2023,neurips,neurips_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,td3,ppo,sac,,,,
99,Guiding Large Language Models via Directional Stimulus Prompting.pdf,True,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
100,Accelerating Value Iteration with Anchoring.pdf,False,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,,,,,
101,Efficient Diffusion Policies For Offline Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,,,,,trpo,dqn,ddpg,td3,ppo,,
102,A State Representation for Diminishing Rewards.pdf,False,False,False,2023,neurips,neurips_2023,6-10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,a2c,sac,,,
103,VOCE Variational Optimization with Conservative Estimation for Offline Safe Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,ddpg,sac,td3,ppo,,
104,Ensemble-based Deep Reinforcement Learning for Vehicle Routing Problems under Distribution Shift.pdf,True,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,dqn,sac,,,,
105,Conditional Mutual Information for Disentangled Representations in Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
106,Coherent Soft Imitation Learning.pdf,True,True,False,2023,neurips,neurips_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
107,Policy Optimization for Continuous Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,,,,
108,Cross-Domain Policy Adaptation via Value-Guided Data Filtering.pdf,True,False,False,2023,neurips,neurips_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
109,Video Prediction Models as Rewards for Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,1-5,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,(?:discount|reward)\s+function,,,,,,dreamer,ppo,sac,,,,
110,Scalable Primal-Dual Actor-Critic Method for Safe Multi-Agent RL with General Utilities.pdf,True,False,False,2023,neurips,neurips_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
111,Learning Generalizable Agents via Saliency-guided Features Decorrelation.pdf,False,False,False,2023,neurips,neurips_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
112,Learning World Models with Identifiable Factorization.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
113,Semantic HELM A Human-Readable Memory for Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dreamer,ppo,dqn,sac,,,
114,On Dynamic Programming Decompositions of Static Risk Measures in Markov Decision Processes.pdf,False,False,False,2023,neurips,neurips_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
115,Conservative Offline Policy Adaptation in Multi-Agent Games.pdf,False,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,,,,
116,Learning to Discover Skills through Guidance.pdf,True,False,False,2023,neurips,neurips_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
117,Learning Better with Less Effective Augmentation for Sample-Efficient Visual Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
118,Natural Actor-Critic for Robust Reinforcement Learning with Function Approximation.pdf,True,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
119,Guide Your Agent with Adaptive Multimodal Rewards.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
120,Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning.pdf,False,True,False,2023,neurips,neurips_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,ppo,dqn,ddpg,,,,
121,Sequential Preference Ranking for Efficient Reinforcement Learning from Human Feedback.pdf,False,False,False,2023,neurips,neurips_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
122,MoVie Visual Model-Based Policy Adaptation for View Generalization.pdf,True,False,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,td-mpc,ppo,,,,,
123,Successor-Predecessor Intrinsic Exploration.pdf,False,True,False,2023,neurips,neurips_2023,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
124,Structured State Space Models for In-Context Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,a2c,,,,,
125,Percentile Criterion Optimization in Offline Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
126,Efficient Adversarial Attacks on Online Multi-agent Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
127,Maximize to Explore One Objective Function Fusing Estimation Planning and Exploration.pdf,True,False,False,2023,neurips,neurips_2023,1-5,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
128,The Benefits of Being Distributional Small-Loss Bounds for Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,,,,,,ppo,,,,,,
129,Inferring the Future by Imagining the Past.pdf,False,False,False,2023,neurips,neurips_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
130,PID-Inspired Inductive Biases for Deep Reinforcement Learning in Partially Observable Control Tasks.pdf,True,True,False,2023,neurips,neurips_2023,1-5,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,td3,ppo,sac,a2c,,,
131,Multi-Agent Meta-Reinforcement Learning Sharper Convergence Rates with Task Similarity.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
132,Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping.pdf,False,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
133,Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning.pdf,True,True,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,a2c,td3,ppo,dreamer,,
134,Posterior Sampling for Competitive RL Function Approximation and Partial Observation.pdf,False,False,False,2023,neurips,neurips_2023,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
135,AlberDICE Addressing Out-Of-Distribution Joint Actions in Offline Multi-Agent RL via Alternating Sta.pdf,True,True,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
136,Resetting the Optimizer in Deep RL An Empirical Study.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,sac,,,,
137,Managing Temporal Resolution in Continuous Value Estimation A Fundamental Trade-off.pdf,False,False,False,2023,neurips,neurips_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,sac,,,,
138,State Sequences Prediction via Fourier Transform for Representation Learning.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
139,Multi-Agent First Order Constrained Optimization in Policy Space.pdf,False,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
140,Regret Minimization via Saddle Point Optimization.pdf,False,True,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,dqn,,,,,,
141,Improved Bayesian Regret Bounds for Thompson Sampling in Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
142,Wasserstein Gradient Flows for Optimizing Gaussian Mixture Policies.pdf,False,False,False,2023,neurips,neurips_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
143,Replicable Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
144,Prediction and Control in Continual Reinforcement Learning.pdf,False,True,False,2023,neurips,neurips_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
145,Learning Dynamic Attribute-factored World Models for Efficient Multi-object Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
146,Doubly Robust Augmented Transfer for Meta-Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
147,Robust Multi-Agent Reinforcement Learning via Adversarial Regularization Theoretical Foundation and .pdf,True,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,ddpg,,,,
148,Online RL in Linearly qpi-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore.pdf,False,False,False,2023,neurips,neurips_2023,0,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
149,Natural Language Instruction-following with Task-related Language Development and Translation.pdf,False,False,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
150,Policy Optimization in a Noisy Neighborhood On Return Landscapes in Continuous Control.pdf,True,False,False,2023,neurips,neurips_2023,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,trpo,td3,ppo,sac,,,
151,Context Shift Reduction for Offline Meta-Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
152,SPQR Controlling Q-ensemble Independence with Spiked Random Model for Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,a2c,sac,,,
153,Reduced Policy Optimization for Continuous Control with Hard Constraints.pdf,True,False,False,2023,neurips,neurips_2023,6-10,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,ddpg,,,,
154,Cal-QL Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning.pdf,True,True,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,td3,ppo,dqn,sac,,,
155,Unsupervised Behavior Extraction via Random Intent Priors.pdf,True,False,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,ppo,dqn,,,,
156,Adversarial Counterfactual Environment Model Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
157,How to Fine-tune the Model Unified Model Shift and Model Bias Policy Optimization.pdf,True,False,False,2023,neurips,neurips_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
158,Iterative Reachability Estimation for Safe Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
159,Conservative State Value Estimation for Offline Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,sac,,,,
160,Improved Communication Efficiency in Federated Natural Policy Gradient via ADMM-based Gradient Updat.pdf,False,False,False,2023,neurips,neurips_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
161,Counterfactual Conservative Q Learning for Offline Multi-agent Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,ddpg,,,
162,Pitfall of Optimism Distributional Reinforcement Learning by Randomizing Risk Criterion.pdf,True,True,False,2023,neurips,neurips_2023,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,,,ppo,dqn,a2c,sac,,,
163,Accelerating Reinforcement Learning with Value-Conditional State Entropy Exploration.pdf,True,False,False,2023,neurips,neurips_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,dreamer,ppo,sac,a2c,,,
164,Swarm Reinforcement Learning for Adaptive Mesh Refinement.pdf,True,True,False,2023,neurips,neurips_2023,6-10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
165,BIRD Generalizable Backdoor Detection and Removal for Deep Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
166,Offline RL with Discrete Proxy Representations for Generalizability in POMDPs.pdf,False,True,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,dqn,,,,,,
167,Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning Ge.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
168,A Partially-Supervised Reinforcement Learning Framework for Visual Active Search.pdf,False,True,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
169,Budgeting Counterfactual for Offline RL.pdf,False,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,ppo,sac,,,,
170,Model-Based Reparameterization Policy Gradient Methods Theory and Practical Algorithms.pdf,True,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,sac,ddpg,a2c,td3,ppo,,
171,Survival Instinct in Offline Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,sac,,,,
172,Diffused Task-Agnostic Milestone Planner.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
173,Regularity as Intrinsic Reward for Free Play.pdf,True,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
174,Dual Self-Awareness Value Decomposition Framework without Individual Global Max for Cooperative MARL.pdf,True,False,False,2023,neurips,neurips_2023,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,sac,,,
175,Offline Minimax Soft-Q-learning Under Realizability and Partial Coverage.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
176,Weakly Coupled Deep Q-Networks.pdf,True,True,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,,,,,ppo,dqn,sac,,,,
177,De novo Drug Design using Reinforcement Learning with Multiple GPT Agents.pdf,True,False,False,2023,neurips,neurips_2023,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,sac,,,,,,
178,Thinker Learning to Plan and Act.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
179,Offline Reinforcement Learning with Differential Privacy.pdf,False,False,False,2023,neurips,neurips_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
180,Instructing Goal-Conditioned Reinforcement Learning Agents with Temporal Logic Objectives.pdf,True,True,False,2023,neurips,neurips_2023,1-5,our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm),policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
181,Optimistic Exploration in Reinforcement Learning Using Symbolic Model Estimates.pdf,True,False,False,2023,neurips,neurips_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
182,ODE-based Recurrent Model-free Reinforcement Learning for POMDPs.pdf,True,False,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
183,Discovering General Reinforcement Learning Algorithms with Adversarial Environment Design.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,a2c,,,,,
184,Corruption-Robust Offline Reinforcement Learning with General Function Approximation.pdf,False,True,False,2023,neurips,neurips_2023,6-10,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
185,Sample-Efficient and Safe Deep Reinforcement Learning via Reset Deep Ensemble Agents.pdf,False,False,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
186,Learning to Modulate pre-trained Models in RL.pdf,True,True,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
187,End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes.pdf,False,True,False,2023,neurips,neurips_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
188,Pre-training Contextualized World Models with In-the-wild Videos for Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,over 10,(?:discount|reward)\s+function,,,,,,,dreamer,ppo,sac,,,,
189,A Long N-step Surrogate Stage Reward for Deep Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,6-10,state-action\s+pairs,,,,,,,dqn,ddpg,sac,td3,ppo,,
190,Neural Multi-Objective Combinatorial Optimization with Diversity Enhancement.pdf,True,False,False,2023,neurips,neurips_2023,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
191,Importance Weighted Actor-Critic for Optimal Conservative Offline Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,other,,,,,,
192,On the Convergence and Sample Complexity Analysis of Deep Q-Networks with epsilon-Greedy Exploration.pdf,False,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
193,Proportional Response Contextual Bandits for Simple and Cumulative Regret Minimization.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
194,Adjustable Robust Reinforcement Learning for Online 3D Bin Packing.pdf,False,False,False,2023,neurips,neurips_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,ppo,sac,,,,,
195,CEIL Generalized Contextual Imitation Learning.pdf,True,True,False,2023,neurips,neurips_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,dqn,sac,td3,ppo,,
196,Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback.pdf,True,False,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
197,CaMP Causal Multi-policy Planning for Interactive Navigation in  Multi-room Scenes.pdf,True,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
198,Train Once Get a Family State-Adaptive Balances for Offline-to-Online Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
199,Reinforcement Learning with Simple Sequence Priors.pdf,True,True,False,2023,neurips,neurips_2023,6-10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
200,Learning Shared Safety Constraints from Multi-task Demonstrations.pdf,True,True,False,2023,neurips,neurips_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
201,From Pixels to UI Actions Learning to Follow Instructions via Graphical User Interfaces.pdf,True,True,False,2023,neurips,neurips_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
202,Multi-Objective Intrinsic Reward Learning for Conversational Recommender Systems.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
203,Replicability in Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
204,Counterfactual-Augmented Importance Sampling for Semi-Offline Policy Evaluation.pdf,True,False,False,2023,neurips,neurips_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
205,MIMEx Intrinsic Rewards from Masked Input Modeling.pdf,True,True,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,ddpg,,,,,
206,CQM Curriculum Reinforcement Learning with a Quantized World Model.pdf,True,False,False,2023,neurips,neurips_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
207,Self-Supervised Reinforcement Learning that Transfers using Random Features.pdf,False,False,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,trpo,pets,dqn,sac,ppo,dreamer,
208,Dynamics Generalisation in Reinforcement Learning via Adaptive Context-Aware Policies.pdf,True,False,False,2023,neurips,neurips_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
209,Offline Reinforcement Learning for Mixture-of-Expert Dialogue Management.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,a3c,dqn,sac,,,,
210,Team-PSRO for Learning Approximate TMECor in Large Team Games via Cooperative Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,using\s+(?:deep\s+)?reinforcement\s+learning\s+to,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,,,,,,
211,Truncating Trajectories in Monte Carlo Policy Evaluation an Adaptive Approach.pdf,True,False,False,2023,neurips,neurips_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
212,Generalized Weighted Path Consistency for Mastering Atari Games.pdf,True,True,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
213,Latent exploration for Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
214,Performance Bounds for Policy-Based Average Reward Reinforcement Learning Algorithms.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,,,,,,dqn,sac,,,,,
215,Look Beneath the Surface Exploiting Fundamental Symmetry for Sample-Efficient Offline RL.pdf,True,False,False,2023,neurips,neurips_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,,,,
216,Mutual-Information Regularized Multi-Agent Policy Iteration.pdf,False,True,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,dqn,ddpg,sac,ppo,,
217,Distributional Model Equivalence for Risk-Sensitive Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,sac,,,,
218,Active Vision Reinforcement Learning under Limited Visual Observability.pdf,False,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,ddpg,sac,,,
219,Supervised Pretraining Can Learn In-Context Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
220,Rewiring Neurons in Non-Stationary Environments.pdf,True,True,False,2023,neurips,neurips_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,sac,,,,,,
221,Suggesting Variable Order for Cylindrical Algebraic Decomposition via Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,ppo,dqn,a2c,sac,,,
222,Sample Complexity of Goal-Conditioned Hierarchical Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
223,Is RLHF More Difficult than Standard RL A Theoretical Perspective.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
224,STEVE-1 A Generative Model for Text-to-Behavior in Minecraft.pdf,True,False,False,2023,neurips,neurips_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
225,Efficient Potential-based Exploration in Reinforcement Learning using Inverse Dynamic Bisimulation M.pdf,True,False,False,2023,neurips,neurips_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
226,When Do Transformers Shine in RL Decoupling Memory from Credit Assignment.pdf,True,False,False,2023,neurips,neurips_2023,6-10,(?:discount|reward)\s+function,,,,,,,dqn,sac,,,,,
227,Reining Generalization in Offline Reinforcement Learning via Representation Distinction.pdf,False,False,False,2023,neurips,neurips_2023,1-5,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
228,DPOK Reinforcement Learning for Fine-tuning Text-to-Image Diffusion Models.pdf,True,True,False,2023,neurips,neurips_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
229,Efficient Model-Free Exploration in Low-Rank MDPs.pdf,False,False,False,2023,neurips,neurips_2023,1-5,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
230,Hyperbolic VAE via Latent Gaussian Distributions.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,,,,,,
231,Model-free Posterior Sampling via Learning Rate Randomization.pdf,True,False,False,2023,neurips,neurips_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
232,Learning to Influence Human Behavior with Offline Reinforcement Learning.pdf,False,True,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,dqn,,,,,,
233,Creating Multi-Level Skill Hierarchies in Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
234,Understanding Predicting and Better Resolving Q-Value Divergence in Offline-RL.pdf,True,True,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,dqn,sac,,,
235,An Alternative to Variance Gini Deviation for Risk-averse Policy Gradient.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,td3,ppo,dqn,,,,
236,Model-Free Active Exploration in Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,over 10,state-action\s+pairs,,,,,,,ppo,dqn,sac,,,,
237,Supported Value Regularization for Offline Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,td3,ppo,dqn,sac,,,
238,Adversarial Model for Offline Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,6-10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
239,Refining Diffusion Planner for Reliable Behavior Synthesis by Automatic Detection of Infeasible Plan.pdf,True,True,False,2023,neurips,neurips_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,other,,,,,,
240,textttTACO Temporal Latent Action-Driven Contrastive Loss for Visual Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,6-10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,dreamer,,,,,
241,Maximum State Entropy Exploration using Predecessor and Successor Representations.pdf,True,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,td3,ppo,dqn,sac,,,
242,Spectral Entry-wise Matrix Estimation for Low-Rank Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
243,Robust Knowledge Transfer in Tiered Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
244,Ordering-based Conditions for Global Convergence of Policy Gradient Methods.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,,,,,
245,Efficient Meta Neural Heuristic for Multi-Objective Combinatorial Optimization.pdf,True,False,False,2023,neurips,neurips_2023,0,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,sac,,,,,
246,Direct Preference-based Policy Optimization without Reward Modeling.pdf,True,False,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
247,Policy Finetuning in Reinforcement Learning via Design of Experiments using Offline Data.pdf,False,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
248,Prioritizing Samples in Reinforcement Learning with Reducible Loss.pdf,True,True,False,2023,neurips,neurips_2023,over 10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,ddpg,sac,,,
249,Future-Dependent Value-Based Off-Policy Evaluation in POMDPs.pdf,True,False,False,2023,neurips,neurips_2023,over 10,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
250,Safety Verification of Decision-Tree Policies in Continuous Time.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,,,,,,ppo,,,,,,
251,Parameterizing Non-Parametric Meta-Reinforcement Learning Tasks via Subtask Decomposition.pdf,True,True,False,2023,neurips,neurips_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
252,DIFFERDecomposing Individual Reward for Fair Experience Replay in Multi-Agent Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,(?:discount|reward)\s+function,,,,ppo,dqn,sac,,,,
253,RoboCLIP One Demonstration is Enough to Learn Robot Policies.pdf,False,False,False,2023,neurips,neurips_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
254,No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions.pdf,False,False,False,2023,neurips,neurips_2023,1-5,state-action\s+pairs,,,,,,,ppo,,,,,,
255,Inverse Preference Learning Preference-based RL without a Reward Function.pdf,True,True,False,2023,neurips,neurips_2023,1-5,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,trpo,ppo,dqn,sac,,,
256,Macro Placement by Wire-Mask-Guided Black-Box Optimization.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
257,Hierarchical Adaptive Value Estimation for Multi-modal Visual Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
258,Large Language Models Are Semi-Parametric Reinforcement Learning Agents.pdf,True,False,False,2023,neurips,neurips_2023,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,ppo,dqn,,,,,
259,HIQL Offline Goal-Conditioned RL with Latent States as Actions.pdf,True,False,False,2023,neurips,neurips_2023,6-10,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
260,Bridging RL Theory and Practice with the Effective Horizon.pdf,True,False,False,2023,neurips,neurips_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,,,,,
261,Provably Efficient Offline Reinforcement Learning in Regular Decision Processes.pdf,False,False,False,2023,neurips,neurips_2023,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
262,Recurrent Hypernetworks are Surprisingly Strong in Meta-RL.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
263,Gradient Informed Proximal Policy Optimization.pdf,True,True,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,,trpo,ppo,,,,,
264,Train Hard Fight Easy Robust Meta Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
265,Constraint-Conditioned Policy Optimization for Versatile Safe Reinforcement Learning.pdf,False,False,False,2023,neurips,neurips_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
266,Automatic Grouping for Efficient Cooperative Multi-Agent Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,(?:discount|reward)\s+function,,,,,ppo,,,,,,
267,Bi-Level Offline Policy Optimization with Limited Exploration.pdf,False,True,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,td3,ppo,dqn,sac,,,
268,Generative Modelling of Stochastic Actions with Arbitrary Constraints in Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,sac,ddpg,a2c,,,
269,Monte Carlo Tree Search with Boltzmann Exploration.pdf,False,False,False,2023,neurips,neurips_2023,over 10,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
270,Unified Off-Policy Learning to Rank a Reinforcement Learning Perspective.pdf,True,True,False,2023,neurips,neurips_2023,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,,,,,,ppo,dqn,sac,,,,
271,Breadcrumbs to the Goal Goal-Conditioned Exploration from Human-in-the-Loop Feedback.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
272,State-Action Similarity-Based Representations for Off-Policy Evaluation.pdf,True,True,False,2023,neurips,neurips_2023,over 10,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
273,Explore to Generalize in Zero-Shot RL.pdf,True,False,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,ppo,,,,,,
274,Convergence of Actor-Critic with Multi-Layer Neural Networks.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,sac,,,,
275,State Regularized Policy Optimization on Data with Dynamics Shift.pdf,False,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,other,,,,,,
276,Consistent Aggregation of Objectives with Diverse Time Preferences Requires Non-Markovian Rewards.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
277,Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games.pdf,True,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
278,Fractal Landscapes in Policy Optimization.pdf,False,False,False,2023,neurips,neurips_2023,0,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,trpo,ppo,dqn,sac,,,
279,Accelerating Exploration with Unlabeled Prior Data.pdf,True,True,False,2023,neurips,neurips_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,dqn,,,,,
280,Accelerating Monte Carlo Tree Search with Probability Tree State Abstraction.pdf,True,False,False,2023,neurips,neurips_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
281,One Risk to Rule Them All A Risk-Sensitive Perspective on Model-Based Offline Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,td3,ppo,dqn,sac,,,
282,Diffusion Model is an Effective Planner and Data Synthesizer for Multi-Task Reinforcement Learning.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
283,Active Observing in Continuous-time Control.pdf,True,True,False,2023,neurips,neurips_2023,over 10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
284,Generating Behaviorally Diverse Policies with Latent Diffusion Models.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,sac,,,,,
285,Reinforcement Learning with Fast and Forgetful Memory.pdf,True,True,False,2023,neurips,neurips_2023,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,trpo,a3c,dqn,sac,td3,ppo,
286,A Unified Algorithm Framework for Unsupervised Discovery of Skills based on Determinantal Point Proc.pdf,True,True,False,2023,neurips,neurips_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
287,Beyond Average Return in Markov Decision Processes.pdf,False,False,False,2023,neurips,neurips_2023,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
288,Reward Scale Robustness for Proximal Policy Optimization via DreamerV3 Tricks.pdf,True,True,False,2023,neurips,neurips_2023,1-5,(?:discount|reward)\s+function,,,,,,,trpo,dreamer,ppo,sac,,,
289,Provably Safe Reinforcement Learning with Step-wise Violation Constraints.pdf,False,False,False,2023,neurips,neurips_2023,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,,,,,,
290,H-InDex Visual Reinforcement Learning with Hand-Informed Representations for Dexterous Manipulation.pdf,True,True,False,2023,neurips,neurips_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),,,,,,ppo,,,,,,
291,Iteratively Learn Diverse Strategies with State Distance Information.pdf,True,False,False,2023,neurips,neurips_2023,6-10,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
292,Multi-Modal Inverse Constrained Reinforcement Learning from a Mixture of Demonstrations.pdf,True,False,False,2023,neurips,neurips_2023,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,,,,,,
293,Provably Efficient Algorithm for Nonstationary Low-Rank MDPs.pdf,False,False,False,2023,neurips,neurips_2023,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
294,Distributional Pareto-Optimal Multi-Objective Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
295,f-Policy Gradients A General Framework for Goal-Conditioned RL using f-Divergences.pdf,False,False,False,2023,neurips,neurips_2023,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
296,Diversify  Conquer Outcome-directed Curriculum RL via Out-of-Distribution Disagreement.pdf,True,False,False,2023,neurips,neurips_2023,1-5,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
297,Cross-Episodic Curriculum for Transformer Agents.pdf,False,False,False,2023,neurips,neurips_2023,over 10,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
298,Risk-Averse Model Uncertainty for Distributionally Robust Safe Reinforcement Learning.pdf,True,False,False,2023,neurips,neurips_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,dqn,sac,,,,,
299,Optimal Convergence Rate for Exact Policy Mirror Descent in Discounted Markov Decision Processes.pdf,False,False,False,2023,neurips,neurips_2023,0,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,ppo,dqn,,,,
300,Waypoint Transformer Reinforcement Learning via Supervised Learning with Intermediate Targets.pdf,True,True,False,2023,neurips,neurips_2023,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,action-value\s+function,,,,,,td3,ppo,dqn,,,,
0,Multi-turn Reinforcement Learning with Preference Human Feedback.pdf,True,True,False,2024,neurips,neurips_2024,1-5,(?:discount|reward)\s+function,,,,,,,trpo,ppo,,,,,
1,Measuring Mutual Policy Divergence for Multi-Agent Sequential Exploration.pdf,True,False,False,2024,neurips,neurips_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,trpo,ppo,sac,,,,
2,Going Beyond Heuristics by Imposing Policy Improvement as a Constraint.pdf,True,True,False,2024,neurips,neurips_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,trpo,ppo,sac,,,,
3,Dynamic Model Predictive Shielding for Provably Safe Reinforcement Learning.pdf,False,False,False,2024,neurips,neurips_2024,6-10,based\s+on\s+(?:deep\s+)?reinforcement\s+learning,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,sac,ddpg,td3,ppo,dreamer,,
4,Controlled maximal variability along with reliable performance in recurrent neural networks.pdf,False,False,False,2024,neurips,neurips_2024,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
5,KALM Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts.pdf,True,False,False,2024,neurips,neurips_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,td3,ppo,dqn,,,,
6,Federated Ensemble-Directed Offline Reinforcement Learning.pdf,True,False,False,2024,neurips,neurips_2024,1-5,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,dqn,sac,td3,ppo,,
7,Learning to Cooperate with Humans using Generative Agents.pdf,True,False,False,2024,neurips,neurips_2024,1-5,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
8,Meta-Reinforcement Learning with Universal Policy Adaptation Provable Near-Optimality under All-task.pdf,False,False,False,2024,neurips,neurips_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,trpo,ppo,sac,,,,
9,GenRL Multimodal-foundation world models for generalization in embodied agents.pdf,False,False,False,2024,neurips,neurips_2024,over 10,(?:discount|reward)\s+function,,,,,,,td3,ppo,dreamer,,,,
10,Enhancing Robustness of Graph Neural Networks on Social Media with Explainable Inverse Reinforcement.pdf,False,False,False,2024,neurips,neurips_2024,0,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,,ppo,sac,,,,,
11,C-GAIL Stabilizing Generative Adversarial Imitation Learning with Control Theory.pdf,False,True,False,2024,neurips,neurips_2024,6-10,through\s+(?:deep\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
12,FlexPlanner Flexible 3D Floorplanning via Deep Reinforcement Learning in Hybrid Action Space with Mu.pdf,True,False,False,2024,neurips,neurips_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
13,Uncertainty-based Offline Variational Bayesian Reinforcement Learning for Robustness under Diverse D.pdf,True,True,False,2024,neurips,neurips_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),action-value\s+function,,,,,,ppo,dqn,sac,,,,
14,Automated Multi-level Preference for MLLMs.pdf,True,False,False,2024,neurips,neurips_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
15,Learning Multimodal Behaviors from Scratch with Diffusion Policy Gradient.pdf,False,False,False,2024,neurips,neurips_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),state-action\s+pairs,(?:discount|reward)\s+function,,,,,trpo,dqn,sac,td3,ppo,,
16,Reinforcement Learning with Lookahead Information.pdf,False,False,False,2024,neurips,neurips_2024,0,state-action\s+pairs,,,,,,,ppo,dqn,sac,,,,
17,On the Curses of Future and History in Future-dependent Value Functions for Off-policy Evaluation.pdf,False,False,False,2024,neurips,neurips_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
18,Learning to Balance Altruism and Self-interest Based on Empathy in Mixed-Motive Games.pdf,True,False,False,2024,neurips,neurips_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,sac,a2c,,,,
19,Solving Zero-Sum Markov Games with Continuous State via Spectral Dynamic Embedding.pdf,False,False,False,2024,neurips,neurips_2024,0,policy\s+gradient\s+(?:method|algorithm|approach),value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
20,Making Offline RL Online Collaborative World Models for Offline Visual Reinforcement Learning.pdf,True,False,False,2024,neurips,neurips_2024,1-5,(?:discount|reward)\s+function,,,,,,,dreamer,,,,,,
21,Verified Safe Reinforcement Learning  for Neural Network Dynamic Models.pdf,True,False,False,2024,neurips,neurips_2024,0,trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
22,Bridging Model-Based Optimization and Generative Modeling via Conservative Fine-Tuning of Diffusion .pdf,True,True,False,2024,neurips,neurips_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,,,,,,
23,REBEL Reinforcement Learning via Regressing Relative Rewards.pdf,True,True,False,2024,neurips,neurips_2024,1-5,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,,,,,,
24,Diffusion-based Curriculum Reinforcement Learning.pdf,True,False,False,2024,neurips,neurips_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,ddpg,,,,
25,Off-Policy Selection for Initiating Human-Centric Experimental Design.pdf,False,True,False,2024,neurips,neurips_2024,0,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
26,Corruption-Robust Linear Bandits Minimax Optimality and Gap-Dependent Misspecification.pdf,False,False,False,2024,neurips,neurips_2024,0,value\s+function\s+approximation,(?:discount|reward)\s+function,,,,,,ppo,,,,,,
27,Learning Successor Features the Simple Way.pdf,True,True,False,2024,neurips,neurips_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,dqn,ddpg,,,,
28,Multi-Reward Best Policy Identification.pdf,True,False,False,2024,neurips,neurips_2024,over 10,we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning,through\s+(?:deep\s+)?reinforcement\s+learning,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
29,Policy Aggregation.pdf,True,False,False,2024,neurips,neurips_2024,0,state-action\s+pairs,(?:discount|reward)\s+function,,,,,,ppo,sac,,,,,
30,Reinforcement Learning Under Latent Dynamics Toward Statistical and Algorithmic Modularity.pdf,False,False,False,2024,neurips,neurips_2024,0,value\s+function\s+approximation,state-action\s+pairs,(?:discount|reward)\s+function,,,,,ppo,sac,,,,,
31,Excluding the Irrelevant Focusing Reinforcement Learning through Continuous Action Masking.pdf,False,True,False,2024,neurips,neurips_2024,over 10,policy\s+gradient\s+(?:method|algorithm|approach),(?:discount|reward)\s+function,,,,,,ppo,dqn,sac,,,,
32,Efficient Recurrent Off-Policy RL Requires a Context-Encoder-Specific Learning Rate.pdf,True,True,False,2024,neurips,neurips_2024,6-10,value\s+function\s+approximation,action-value\s+function,(?:discount|reward)\s+function,,,,,dqn,a2c,sac,td3,ppo,,
33,A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approx.pdf,False,False,False,2024,neurips,neurips_2024,0,through\s+(?:deep\s+)?reinforcement\s+learning,value\s+function\s+approximation,action-value\s+function,state-action\s+pairs,(?:discount|reward)\s+function,,,ppo,dqn,,,,,
34,Episodic Future Thinking Mechanism for Multi-agent Reinforcement Learning.pdf,False,False,False,2024,neurips,neurips_2024,0,(?:discount|reward)\s+function,,,,,,,dqn,ddpg,sac,ppo,dreamer,,
35,Provably Efficient Reinforcement Learning with Multinomial Logit Function Approximation.pdf,False,False,False,2024,neurips,neurips_2024,0,action-value\s+function,(?:discount|reward)\s+function,,,,,,ppo,dqn,,,,,
36,Is Mamba Compatible with Trajectory Optimization in Offline Reinforcement Learning.pdf,True,False,False,2024,neurips,neurips_2024,1-5,through\s+(?:deep\s+)?reinforcement\s+learning,,,,,,,ppo,dqn,,,,,
37,Focus On What Matters Separated Models For Visual-Based RL Generalization.pdf,True,True,False,2024,neurips,neurips_2024,1-5,(?:discount|reward)\s+function,,,,,,,ppo,dqn,sac,,,,
