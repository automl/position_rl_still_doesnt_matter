# RL Papers Analysis


## Year 2018 (97 RL papers)


### Addressing Function Approximation Error in Actor-Critic Methods.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Adversarial Attack on Graph Structured Data.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c', 'sac']


### Adversarial Risk and the Dangers of Evaluating Against Weak Attacks.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Adversarially Regularized Autoencoders.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### An Efficient Generalized Bellman Update For Cooperative Inverse Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### An Inference-Based Policy Gradient Method for Learning Options.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, state-action\s+pairs
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'sac']


### Automatic Goal Generation for Reinforcement Learning Agents.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Beyond the One-Step Greedy Approach in Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c']


### Clipped Action Policy Gradient.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Competitive Multi-agent Inverse Reinforcement Learning with Sub-optimal Demonstrations.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Composable Planning with Attributes.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Compressing Neural Networks using the Variational Information Bottleneck.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Configurable Markov Decision Processes.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Continual Reinforcement Learning with Complex Synapses.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Convergent Tree Backup and Retrace with Function Approximation.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Decoupling Gradient-Like Learning Rules from Representations.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Deep Reinforcement Learning in Continuous Action Spaces a Case Study in the Game of Simulated Curlin.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Deep Variational Reinforcement Learning for POMDPs.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'dqn', 'a2c', 'sac', 'ppo']


### DiCE The Infinitely Differentiable Monte Carlo Estimator.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Differentiable plasticity training plastic neural networks with backpropagation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 15
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'a2c']


### Discovering and Removing Exogenous State Variables and Rewards for Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Efficient Gradient-Free Variational Inference using Policy Search.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Efficient Neural Architecture Search via Parameters Sharing.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### End-to-end Active Object Tracking via Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'sac']


### Fast Bellman Updates for Robust MDPs.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'ddpg']


### Feedback-Based Tree Search for Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Focused Hierarchical RNNs for Conditional Sequence Processing.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 2
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets']


### Fourier Policy Gradients.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### GEP-PG Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 1000
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'ppo']


### Gated Path Planning Networks.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Graph Networks as Learnable Physics Engines for Inference and Control.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'ddpg']


### GraphRNN Generating Realistic Graphs with Deep Auto-regressive Models.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Hierarchical Imitation and Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### IMPALA Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a3c', 'dqn', 'a2c', 'sac', 'ppo']


### Implicit Quantile Networks for Distributional Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 2
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Importance Weighted Transfer of Samples in Reinforcement Learning.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Improving Regression Performance with Distributional Losses.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Latent Space Policies for Hierarchical Reinforcement Learning.pdf
* Matched keywords: our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm), policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'ppo']


### Learning Policy Representations in Multiagent Systems.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'ddpg']


### Learning by Playing Solving Sparse Reward Tasks from Scratch.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Learning the Reward Function for a Misspecified Model.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning to Act in Decentralized Partially Observable MDPs.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Learning to Coordinate with Coordination Graphs in Repeated Single-Stage Multi-Agent Decision Proble.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Learning to Explore via Meta-Policy Gradient.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg']


### Learning to search with MCTSnets.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Learning with Abandonment.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Least-Squares Temporal Difference Learning for the Linear Quadratic Regulator.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Lipschitz Continuity in Model-based Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 105
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Machine Theory of Mind.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Mean Field Multi-Agent Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### Minimax Concave Penalized Multi-Armed Bandit Model with High-Dimensional Covariates.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Modeling Others using Oneself in Multi-Agent Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 1000
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'dqn', 'a2c']


### More Robust Doubly Robust Off-policy Evaluation.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, action-value\s+function, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Neural Program Synthesis from Diverse Demonstration Videos.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Noisy Natural Gradient as Variational Inference.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### PIPPS Flexible Model-Based Policy Search Robust to the Curse of Chaos.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Path Consistency Learning in Tsallis Entropy Regularized MDPs.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'a3c', 'ppo']


### Path-Level Network Transformation for Efficient Architecture Search.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Policy Optimization as Wasserstein Gradient Flows.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'a2c', 'sac', 'ppo']


### Policy Optimization with Demonstrations.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'ddpg']


### Policy and Value Transfer in Lifelong Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Programmatically Interpretable Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'ddpg']


### QMIX Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### RLlib Abstractions for Distributed Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'dqn', 'ddpg']


### Recurrent Predictive State Policy Networks.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn']


### Regret Minimization for Partially Observable Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'ddpg']


### Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'ddpg']


### SBEED Convergent Reinforcement Learning with Nonlinear Function Approximation.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'ppo']


### Scalable Bilinear Pi Learning Using State and Action Features.pdf
* Matched keywords: value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Self-Consistent Trajectory Autoencoder Hierarchical Reinforcement Learning with Trajectory Embedding.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'a3c', 'ppo']


### Self-Imitation Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'a3c', 'dqn', 'a2c', 'ppo']


### Smoothed Action Value Functions for Learning Gaussian Policies.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'ddpg']


### Soft Actor-Critic Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Spotlight Optimizing Device Placement for Training Deep Neural Networks.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Stagewise Safe Bayesian Optimization with Gaussian Processes.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### State Abstractions for Lifelong Reinforcement Learning.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Stochastic Variance-Reduced Policy Gradient.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Structured Control Nets for Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Structured Evolution with Compact Architectures for Scalable Policy Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Synthesizing Programs for Images using Reinforced Adversarial Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a2c']


### TACO Learning Task Decomposition via Temporal Alignment for Control.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### The Mirage of Action-Dependent Baselines in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo']


### The Uncertainty Bellman Equation and Exploration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function
* Number of seeds: 500
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Thompson Sampling for Combinatorial Semi-Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Tighter Variational Bounds are Not Necessarily Better.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Time Limits in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 30
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets', 'ppo', 'dqn']


### Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Universal Planning Networks Learning Generalizable Representations for Visuomotor Control.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Visualizing and Understanding Atari Agents.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'a2c']


## Year 2019 (124 RL papers)


### A Baseline for Any Order Gradient Estimation in Stochastic Computation Graphs.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Composite Randomized Incremental Gradient Method.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Deep Reinforcement Learning Perspective on Internet Congestion Control.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### A Theory of Regularized Markov Decision Processes.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'sac']


### A Wrapped Normal Distribution on Hyperbolic Space for Gradient-Based Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### A fully differentiable beam search decoder.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### ARSM Augment-REINFORCE-Swap-Merge Estimator for Gradient Backpropagation Through Categorical Variabl.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Accelerated Flow for Probability Distributions.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Action Robust Reinforcement Learning and Applications in Continuous Control.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'ddpg']


### Actor-Attention-Critic for Multi-Agent Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac', 'ddpg']


### Adaptive Sensor Placement for Continuous Spaces.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Addressing the Loss-Metric Mismatch with Adaptive Loss Alignment.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn']


### An Investigation of Model-Free Planning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c']


### Batch Policy Learning under Constraints.pdf
* Matched keywords: action-value\s+function
* Number of seeds: 30
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Bayesian Counterfactual Risk Minimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Bayesian Optimization Meets Bayesian Optimal Stopping.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'ddpg']


### CURIOUS Intrinsically Motivated Modular Multi-Goal Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac']


### Calibrated Model-Based Deep Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Cautious Regret Minimization Online Optimization with Long-Term Budget Constraints.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Collaborative Evolutionary Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'dqn', 'ddpg']


### Combining parametric and nonparametric models for off-policy evaluation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Composing Entropic Policies using Divergence Correction.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Composing Value Functions in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 80
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Contextual Memory Trees.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Control Regularization for Reduced Variance Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'ddpg']


### Curiosity-Bottleneck Exploration By Distilling Task-Specific Novelty.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Dead-ends and Secure Exploration in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Deep Counterfactual Regret Minimization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### DeepMDP Learning Continuous Latent Space Models for Representation Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Diagnosing Bottlenecks in Deep Q-learning Algorithms.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Dimension-Wise Importance Sampling Weight Clipping for Sample-Efficient Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Discovering Context Effects from Raw Choice Data.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Discovering Options for Exploration by Minimizing Cover Time.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Distributional Multivariate Policy Evaluation and Exploration with the Bellman GAN.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn']


### Distributional Reinforcement Learning for Efficient Exploration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Dynamic Measurement Scheduling for Event Forecasting using Deep RL.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Dynamic Weights in Multi-Objective Deep Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### EMI Exploration with Mutual Information.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'a3c', 'ppo']


### Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Exploration Conscious Reinforcement Learning Revisited.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'a3c', 'dqn', 'ddpg']


### Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Fast Context Adaptation via Meta-Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo']


### Finding Options that Minimize Planning Time.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Fingerprint Policy Optimisation for Robust Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Finite-Time Analysis of Distributed TD0 with Linear Function Approximation on Multi-Agent Reinforcem.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Garbage In Reward Out Bootstrapping Exploration in Multi-Armed Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Generative Adversarial User Model for Reinforcement Learning Based Recommendation System.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Graphite Iterative Generative Modeling of Graphs.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Grid-Wise Control for Multi-Agent Reinforcement Learning in Video Game AI.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Guided evolutionary strategies augmenting random search with surrogate gradients.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Hessian Aided Policy Gradient.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Imitating Latent Policies from Observation.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Imitation Learning from Imperfect Demonstration.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Importance Sampling Policy Evaluation with an Estimated Behavior Policy.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 200
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Improving Neural Network Quantization without Retraining using Outlier Channel Splitting.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Information-Theoretic Considerations in Batch Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Insertion Transformer Flexible Sequence Generation via Insertion Operations.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Iterative Linearized Control Stable Algorithms and Complexity Guarantees.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Kernel-Based Reinforcement Learning in Robust Markov Decision Processes.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Action Representations for Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Learning Context-dependent Label Permutations for Multi-label Classification.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Latent Dynamics for Planning from Pixels.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c']


### Learning Linear-Quadratic Regulators Efficiently with only sqrtT Regret.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Neurosymbolic Generative Models via Program Synthesis.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Learning Novel Policies For Tasks.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Learning a Prior over Intent via Meta-Inverse Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Learning from a Learner.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Learning to Collaborate in Markov Decision Processes.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Learning to Generalize from Sparse and Underspecified Rewards.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Learning to select for a predefined ranking.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Making Deep Q-learning methods robust to time discretization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'a3c', 'dqn', 'ddpg', 'ppo']


### Maximum Entropy-Regularized Multi-Goal Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'a3c', 'sac', 'ddpg']


### Model-Based Active Exploration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### More Efficient Off-Policy Evaluation through Regularized Targeted Learning.pdf
* Matched keywords: action-value\s+function
* Number of seeds: 315
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Multi-Agent Adversarial Inverse Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Myopic Posterior Sampling for Adaptive Goal Oriented Design of Experiments.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Neural Logic Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Nonlinear Distributional Gradient Temporal-Difference Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Off-Policy Deep Reinforcement Learning without Exploration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg']


### On the Design of Estimators for Bandit Off-Policy Evaluation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### On the Feasibility of Learning Rather than Assuming Human Biases for Reward Inference.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### On the Generalization Gap in Reparameterizable Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Online Adaptive Principal Component Analysis and Its extensions.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Online Control with Adversarial Disturbances.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Online Variance Reduction with Mixtures.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Optimal Algorithms for Lipschitz Bandits with Heavy-tailed Rewards.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Optimistic Policy Optimization via Multiple Importance Sampling.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### POLITEX Regret Bounds for Policy Iteration using Expert Prediction.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Per-Decision Option Discounting.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Policy Certificates Towards Accountable Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Policy Consolidation for Continual Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 30
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Predictor-Corrector Policy Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Probabilistic Neural Symbolic Models for Interpretable Visual Question Answering.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 15
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Probability Functional Descent A Unifying Perspective on GANs Variational Inference and Reinforcemen.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'a2c']


### Provably Efficient Maximum Entropy Exploration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Provably efficient RL with Rich Observations via Latent State Decoding.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### QTRAN Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Quantifying Generalization in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Random Expert Distillation Imitation Learning via Expert Policy Support Estimation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Reinforcement Learning in Configurable Continuous Environments.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Remember and Forget for Experience Replay.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'ppo']


### Revisiting the Softmax Bellman Operator New Benefits and New Perspective.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### SOLAR Deep Structured Representations for Model-Based Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Sample-Optimal Parametric Q-Learning Using Linearly Additive Features.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Scalable Training of Inference Networks for Gaussian-Process Models.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Self-Supervised Exploration via Disagreement.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Separating value functions across time-scales.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 250
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Simple Black-box Adversarial Attacks.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Social Influence as Intrinsic Motivation for Multi-Agent Deep Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'a2c']


### Structured agents for physical construction.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Taming MAML Efficient unbiased meta-reinforcement learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### TarMAC Targeted Multi-Agent Communication.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Target-Based Temporal-Difference Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### Task-Agnostic Dynamics Priors for Deep Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### The Natural Language of Actions.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### The Value Function Polytope in Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### TibGM A Transferable and Information-Based Graphical Model Approach for Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 1000
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Val.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Trajectory-Based Off-Policy Deep Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'ddpg']


### Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'a2c']


### Transfer of Samples in Policy Search via Multiple Importance Sampling.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Understanding the Impact of Entropy on Policy Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn']


### Weakly-Supervised Temporal Localization via Occurrence Count Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets', 'ppo', 'sac']


## Year 2020 (189 RL papers)


### A Chance-Constrained Generative Framework for Sequence Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### A Finite-Time Analysis of Q-Learning with Neural Network Function Approximation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### A Game Theoretic Framework for Model Based Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### A Graph to Graphs Framework for Retrosynthesis Prediction.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Markov Decision Process Model for Socio-Economic Systems Impacted by Climate Change.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### A Natural Lottery Ticket Winner Reinforcement Learning with Ordinary Neural Circuits.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### A distributional view on multi-objective policy optimization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### AR-DAE Towards Unbiased Neural Entropy Gradient Estimation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Accelerated Stochastic Gradient-free and Projection-free Methods.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Accountable Off-Policy Evaluation With Kernel Bellman Statistics.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Active World Model Learning with Progress Curiosity.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Adaptive Droplet Routing in Digital Microfluidic Biochips Using Deep Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Adaptive Estimator Selection for Off-Policy Evaluation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Adaptive Reward-Poisoning Attacks against Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 1000
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'dqn', 'ddpg', 'sac']


### Agent57 Outperforming the Atari Human Benchmark.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### An Optimistic Perspective on Offline Reinforcement Learning.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Asynchronous Coagent Networks.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Automated Synthetic-to-Real Generalization.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### BINOCULARS for efficient nonmyopic sequential experimental design.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Bandits for BMO Functions.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Bandits with Adversarial Scaling.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Batch Reinforcement Learning with Hyperparameter Gradients.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 300
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Batch Stationary Distribution Estimation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'a2c']


### Bayesian Optimisation over Multiple Continuous and Categorical Inputs.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Bidirectional Model-based Policy Optimization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['pets', 'ppo', 'sac']


### Bootstrap Latent-Predictive Representations for Multitask Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Breaking the Curse of Many Agents Provable Mean Embedding Q-Iteration for Mean-Field Reinforcement L.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### CURL Contrastive Unsupervised Representations for Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn', 'sac']


### Can Autonomous Vehicles Identify Recover From and Adapt to Distribution Shifts.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Can Increasing Input Dimensionality Improve Deep Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'sac', 'ddpg']


### Causal Effect Estimation and Optimal Dose Suggestions in Mobile Health.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Cautious Adaptation For Reinforcement Learning in Safety-Critical Settings.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets']


### Clinician-in-the-Loop Decision Making Reinforcement Learning with Near-Optimal Set-Valued Policies.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Closed Loop Neural-Symbolic Learning via Integrating Neural Perception Grammar Parsing and Symbolic .pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### CoMic Complementary Task Learning  Mimicry for Reusable Skills.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### ConQUR Mitigating Delusional Bias in Deep Q-Learning.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Constrained Markov Decision Processes via Backward Value Functions.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'a2c']


### Context-aware Dynamics Model for Generalization in Model-Based Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Control Frequency Adaptation via Action Persistence in Batch Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Controlling Overestimation Bias with Truncated Mixture of Continuous Distributional Quantile Critics.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Countering Language Drift with Seeded Iterated Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Data Valuation using Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Decentralized Reinforcement Learning Global Decision-Making via Local Economic Transactions.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Deep Coordination Graphs.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Deep PQR Solving Inverse Reinforcement Learning using Anchor Actions.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Deep Reinforcement Learning with Robust and Smooth Policy.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'ppo']


### Description Based Text Classification with Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Discount Factor as a Regularizer in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Distributionally Robust Policy Evaluation and Learning in Offline Contextual Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Does the Markov Decision Process Fit the Data Testing for the Markov Property in Sequential Decision.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'dqn', 'a2c', 'sac', 'ppo']


### Domain Adaptive Imitation Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Double Reinforcement Learning for Efficient and Robust Off-Policy Evaluation.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Doubly robust off-policy evaluation with shrinkage.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Dual Mirror Descent for Online Allocation Problems.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 400
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Dynamic Knapsack Optimization Towards Efficient Multi-Channel Sequential Advertising.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Efficiently Solving MDPs with Stochastic Mirror Descent.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Estimating Qss with Deep Deterministic Dynamics Gradients.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'ddpg']


### Evaluating the Performance of Reinforcement Learning Algorithms.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Evolutionary Reinforcement Learning for Sample-Efficient Multiagent Coordination.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'ddpg']


### Explicit Gradient Learning for Black-Box Optimization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'ddpg']


### Explore Discover and Learn Unsupervised Discovery of State-Covering Skills.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Fast Adaptation to New Environments via Policy-Dynamics Value Functions.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Fast computation of Nash Equilibria in Imperfect Information Games.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Fiduciary Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Finite-Time Last-Iterate Convergence for Multi-Agent Learning in Games.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Flexible and Efficient Long-Range Planning Through Curious Exploration.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to, through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### From Importance Sampling to Doubly Robust Policy Gradient.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 150
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Generalization to New Actions in Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Generative Adversarial Imitation Learning with Neural Network Parameterization Global Optimality and.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo']


### Generative Teaching Networks Accelerating Neural Architecture Search by Learning to Generate Synthet.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Global Concavity and Optimization in a Class of Dynamic Discrete Choice Models.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Goal-Aware Prediction Learning to Model What Matters.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 500
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### GradientDICE Rethinking Generalized Offline Estimation of Stationary Values.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3']


### GraphOpt Learning Optimization Models of Graph Formation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Graphical Models Meet Bandits A Variational Thompson Sampling Approach.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Growing Action Spaces.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Hallucinative Topological Memory for Zero-Shot Visual Planning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Hierarchical Generation of Molecular Graphs using Structural Motifs.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Hierarchically Decoupled Imitation For Morphological Transfer.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### History-Gradient Aided Batch Size Adaptation for Variance Reduced Algorithms.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Implicit Generative Modeling for Efficient Exploration.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### Improved Optimistic Algorithms for Logistic Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Improving Molecular Design by Stochastic Iterative Target Augmentation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Inductive-bias-driven Reinforcement Learning For Efficient Schedules in Heterogeneous Clusters.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 500
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'a2c']


### Inferring DQN structure for high-dimensional continuous control.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg']


### Information Particle Filter Tree An Online Algorithm for POMDPs with Belief-Based Rewards on Continu.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Interference and Generalization in Temporal Difference Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Interpretable Off-Policy Evaluation in Reinforcement Learning by Highlighting Influential Transition.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Intrinsic Reward Driven Imitation Learning via Generative Model.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Invariant Causal Prediction for Block MDPs.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Inverse Active Sensing Modeling and Understanding Timely Decision-Making.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Kernel Methods for Cooperative Multi-Agent Contextual Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Kinematic State Abstraction and Provably Efficient Rich-Observation Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Adversarial Markov Decision Processes with Bandit Feedback and Unknown Transition.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Learning Calibratable Policies using Programmatic Style-Consistency.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Learning Compound Tasks without Task-specific Knowledge via Imitation and Self-supervised Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Learning Efficient Multi-agent Communication An Information Bottleneck Approach.pdf
* Matched keywords: action-value\s+function
* Number of seeds: 1
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'ddpg']


### Learning Fair Policies in Multi-Objective Deep Reinforcement Learning with Average and Discounted Re.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c', 'sac']


### Learning Human Objectives by Evaluating Hypothetical Behavior.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Learning Near Optimal Policies with Low Inherent Bellman Error.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Optimal Tree Models under Beam Search.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Portable Representations for High-Level Planning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Robot Skills with Temporal Variational Inference.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Learning Selection Strategies in Buchbergers Algorithm.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning to Navigate The Synthetically Accessible Chemical Space Using Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a3c', 'dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Learning to Score Behaviors for Guided Policy Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn']


### Learning with Good Feature Representations in Bandits and in RL with a Generative Model.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Leveraging Procedural Generation to Benchmark Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Likelihood-free MCMC with Amortized Approximate Ratio Estimators.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Locally Differentially Private Combinatorial Semi-Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Logarithmic Regret for Adversarial Online Control.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Logarithmic Regret for Learning Linear Quadratic Regulators Efficiently.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Lookahead-Bounded Q-learning.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Low-Variance and Zero-Variance Baselines for Extensive-Form Games.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Maximum Entropy Gain Exploration for Long Horizon Multi-goal Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'ppo']


### Min-Max Optimization without Gradients Convergence and Applications to Black-Box Evasion and Poisoni.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Minimax Weight and Q-Function Learning for Off-Policy Evaluation.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Minimax-Optimal Off-Policy Evaluation with Linear Function Approximation.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Model-Based Reinforcement Learning with Value-Targeted Regression.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Model-free Reinforcement Learning in Infinite-horizon Average-reward Markov Decision Processes.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Momentum-Based Policy Gradient Methods.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Monte-Carlo Tree Search as Regularized Policy Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 8
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Multi-Agent Determinantal Q-Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Multi-Agent Routing Value Iteration Network.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Multi-Objective Molecule Generation using Interpretable Substructures.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to, through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Multi-step Greedy Reinforcement Learning Algorithms.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn']


### Naive Exploration is Optimal for Online LQR.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Near-optimal Regret Bounds for Stochastic Shortest Path.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Neural Contextual Bandits with UCB-based Exploration.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn']


### Neural Network Control Policy Verification With Persistent Adversarial Perturbation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Off-Policy Actor-Critic with Shared Experience Replay.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### On the Expressivity of Neural Networks for Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### On the Generalization Effects of Linear Transformations in Data Augmentation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### On the Global Convergence Rates of Softmax Policy Gradient Methods.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### On the Global Optimality of Model-Agnostic Meta-Learning.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### One Policy to Control Them All Shared Modular Policies for Agent-Agnostic Control.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo']


### Online Dense Subgraph Discovery via Blurred-Graph Feedback.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Online Learned Continual Compression with Adaptive Quantization Modules.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Optimally Solving Two-Agent Decentralized POMDPs Under One-Sided Information Sharing.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 652
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Optimizing Data Usage via Differentiable Rewards.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Optimizing Long-term Social Welfare in Recommender Systems A Constrained Matching Approach.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Optimizing for the Future in Non-Stationary MDPs.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Option Discovery in the Absence of Rewards with Manifold Analysis.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Planning to Explore via Self-Supervised World Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer']


### Policy Teaching via Environment Poisoning Training-time Adversarial Attacks against Reinforcement Le.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Population-Based Black-Box Optimization for Biological Sequence Design.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Prediction-Guided Multi-Objective Reinforcement Learning for Continuous Robot Control.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Private Outsourced Bayesian Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Provable Representation Learning for Imitation Learning via Bi-level Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Provable Self-Play Algorithms for Competitive Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 2
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Provably Convergent Two-Timescale Off-Policy Actor-Critic with Function Approximation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3']


### Provably Efficient Exploration in Policy Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Provably Efficient Model-based Policy Adaptation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Q-value Path Decomposition for Deep Multiagent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 12
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### R2-B2 Recursive Reasoning-Based Bayesian Optimization for No-Regret Learning in Games.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### ROMA Multi-Agent Reinforcement Learning with Emergent Roles.pdf
* Matched keywords: action-value\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### Ready Policy One World Building Through Active Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Reducing Sampling Error in Batch Temporal Difference Learning.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 300
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Reinforcement Learning for Molecular Design Guided by Quantum Mechanics.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Reinforcement Learning for Non-Stationary Markov Decision Processes The Blessing of More Optimism.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Reinforcement Learning in Feature Space Matrix Bandit Kernels and Regret Bound.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Representations for Stable Off-Policy Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Responsive Safety in Reinforcement Learning by PID Lagrangian Methods.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Revisiting Fundamentals of Experience Replay.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Reward-Free Exploration for Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 1
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Safe Reinforcement Learning in Constrained Markov Decision Processes.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Sample Factory Egocentric 3D Control from Pixels at 100000 FPS with Asynchronous Reinforcement Learn.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'sac', 'a2c']


### Selective Dyna-Style Planning Under Limited Model Capacity.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Sequence Generation with Mixed Representations.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Sequential Transfer in Reinforcement Learning with a Generative Model.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Skew-Fit State-Covering Self-Supervised Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 9
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Statistically Efficient Off-Policy Policy Gradients.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Stochastically Dominant Distributional Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Striving for Simplicity and Performance in Off-Policy DRL Output Normalization and Non-Uniform Sampl.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Structured Policy Iteration for Linear Quadratic Regulator.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Student-Teacher Curriculum Learning via Reinforcement Learning Predicting Hospital Inpatient Admissi.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, action-value\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg']


### Sub-Goal Trees a Framework for Goal-Based Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Task-Oriented Active Perception and Planning in Environments with Partially Known Semantics.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Taylor Expansion Policy Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Thompson Sampling via Local Uncertainty.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Tightening Exploration in Upper Confidence Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Training Deep Energy-Based Models with f-Divergence Minimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Tuning-free Plug-and-Play Proximal Algorithm for Inverse Imaging Problems.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac', 'ddpg']


### Understanding the Curse of Horizon in Off-Policy Evaluation via Conditional Importance Sampling.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Variational Imitation Learning with Diverse-quality Demonstrations.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### What Can Learned Intrinsic Rewards Capture.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### What can I do here A Theory of Affordances in Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Working Memory Graphs.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'dqn', 'sac']


## Year 2021 (232 RL papers)


### A Deep Reinforcement Learning Approach to Marginalized Importance Sampling with the Successor Repres.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'dqn']


### A Language for Counterfactual Generative Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Lower Bound for the Sample Complexity of Inverse Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A New Formalism Method and Open Issues for Zero-Shot Coordination.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### A New Representation of Successor Features for Transfer across Dissimilar Environments.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Regret Minimization Approach to Iterative Learning Control.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A Sharp Analysis of Model-based Reinforcement Learning with Self-Play.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### AGENT A Benchmark for Core Psychological Reasoning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3360
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### APS Active Pretraining with Successor Features.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### ARMS Antithetic-REINFORCE-Multi-Sample Gradient for Binary Variables.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Accelerating Safe Reinforcement Learning with Constraint-mismatched Baseline Policies.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Actionable Models Unsupervised Offline Reinforcement Learning of Robotic Skills.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### AdaXpert Adapting Neural Architecture for Growing Data.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Adapting to misspecification in contextual bandits with offline regression oracles.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Adversarial Combinatorial Bandits with General Non-linear Reward Functions.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Adversarial Option-Aware Hierarchical Imitation Learning.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Adversarial Policy Learning in Two-player Competitive Games.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Adversarial Robustness Guarantees for Random Deep Neural Networks.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Approximation Theory Based Methods for RKHS Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environmen.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Average-Reward Off-Policy Policy Evaluation with Function Approximation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['sac']


### Batch Value-function Approximation with Only Realizability.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Beyond Variance Reduction Understanding the True Impact of Baselines on Policy Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Bias-Robust Bayesian Optimization via Dueling Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Bilinear Classes A Structural Framework for Provable Generalization in RL.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Bootstrapping Fitted Q-Evaluation for Off-Policy Inference.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 200
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Breaking the Deadly Triad with a Target Network.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### CRPO A New Approach for Safe Reinforcement Learning with Convergence Guarantee.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac', 'ddpg']


### Causal Curiosity RL Agents Discovering Self-supervised Experiments for Causal Representation Learnin.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Characterizing the Gap Between Actor-Critic and Policy Gradient.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'a2c', 'sac', 'ppo']


### Coach-Player Multi-agent Reinforcement Learning for Dynamic Team Composition.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Collaborative Bayesian Optimization with Fair Regret.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Combinatorial Blocking Bandits with Stochastic Delays.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Combining Pessimism with Optimism for Robust and Efficient Model-Based Deep Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'pets', 'dqn', 'sac', 'ppo']


### Confidence-Budget Matching for Sequential Budgeted Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Continuous Coordination As a Realistic Scenario for Lifelong Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Continuous-time Model-based Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets']


### Convex Regularization in Monte-Carlo Tree Search.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Cooperative Exploration for Multi-Agent Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg']


### Counterfactual Credit Assignment in Model-Free Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Cross-domain Imitation from Observations.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c', 'sac']


### DFAC Framework Factorizing the Value Function via Quantile Mixture for Multi-Agent Distributional Q-.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Decentralized Single-Timescale Actor-Critic on Zero-Sum Two-Player Stochastic Games.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Decision-Making Under Selective Labels Optimal Finite-Domain Policies and Beyond.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Decoupling Exploration and Exploitation for Meta-Reinforcement Learning without Sacrifices.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Decoupling Representation Learning from Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Decoupling Value and Policy for Generalization in Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'a2c']


### Deep Coherent Exploration for Continuous Control.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac', 'a2c']


### Deep Reinforcement Learning amidst Continual Structured Non-Stationarity.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Deeply-Debiased Off-Policy Interval Estimation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Demonstration-Conditioned Reinforcement Learning for Few-Shot Imitation.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Density Constrained Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Detecting Rewards Deterioration in Episodic Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Discovering symbolic policies with deep reinforcement learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Diversity Actor-Critic Sample-Aware Entropy Regularization for Sample-Efficient Exploration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### DouZero Mastering DouDizhu with Self-Play Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Doubly Robust Off-Policy Actor-Critic Convergence and Optimality.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Dynamic Balancing for Model Selection in Bandits and RL.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Dynamic Planning and Learning under Recovering Rewards.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### EMaQ Expected-Max Q-Learning Operator for Simple Yet Effective Offline and Online RL.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Efficient Differentiable Simulation of Articulated Bodies.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Efficient Performance Bounds for Primal-Dual Reinforcement Learning from Demonstrations.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Emergent Social Learning via Multi-agent Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Emphatic Algorithms for Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 200
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Ensemble Bootstrapping for Q-Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### Estimating α-Rank from A Few Entries with Low Rank Matrix Completion.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Exploration in Approximate Hyper-State Space for Meta Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Explore Visual Concept Formation for Image Classification.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Exponential Lower Bounds for Batch Reinforcement Learning Batch RL can be Exponentially Harder than .pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Expressive 1-Lipschitz Neural Networks for Robust Multiple Graph Learning against Adversarial Attack.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### FOP Factorizing Optimal Joint Policy of Maximum-Entropy Multi-Agent Reinforcement Learning.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac']


### Fast active learning for pure exploration in reinforcement learning.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Finding the Stochastic Shortest Path with Low Regret the Adversarial Cost and Unknown Transition Cas.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Finite-Sample Analysis of Off-Policy Natural Actor-Critic Algorithm.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### First-Order Methods for Wasserstein Distributionally Robust MDP.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### GLSearch Maximum Common Subgraph Detection via Learning to Search.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### GMAC A Distributional Perspective on Actor-Critic Framework.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### Generalizable Episodic Memory for Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn']


### Global Convergence of Policy Gradient for Linear-Quadratic Mean-Field ControlGame in Continuous Time.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Goal-Conditioned Reinforcement Learning with Imagined Subgoals.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### GraphDF A Discrete Flow Model for Molecular Graph Generation.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Grounding Language to Entities and Dynamics for Generalization in Reinforcement Learning.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Guided Exploration with Proximal Policy Optimization using a Single Demonstration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c']


### High Confidence Generalization for Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 1000
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### High-dimensional Experimental Design and Kernel Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Hyperparameter Selection for Imitation Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Imitation by Predicting Observations.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Improved Corruption Robust Algorithms for Episodic Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Improved Regret Bound and Experience Replay in Regularized Policy Iteration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Instabilities of Offline RL with Pre-Trained Neural Representation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'ddpg']


### Interactive Learning from Activity Description.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Inverse Constrained Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Inverse Decision Modeling Learning Interpretable Representations of Behavior.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Is Pessimism Provably Efficient for Offline RL.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Joining datasets via data augmentation in the label space for neural networks.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Joint Online Learning and Decision-making via Dual Mirror Descent.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Kernel-Based Reinforcement Learning A Finite-Time Analysis.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Keyframe-Focused Visual Imitation Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### LIME Learning Inductive Bias for Primitives of Mathematical Reasoning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### LTL2Action Generalizing LTL Instructions for Multi-Task RL.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Large-Scale Multi-Agent Deep FBSDEs.pdf
* Matched keywords: action-value\s+function
* Number of seeds: 64
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Fair Policies in Decentralized Cooperative Multi-Agent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Routines for Effective Off-Policy Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'dqn', 'ddpg', 'sac']


### Learning While Playing in Mean-Field Games Convergence and Optimality.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Learning and Planning in Average-Reward Markov Decision Processes.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 30
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Learning and Planning in Complex Action Spaces.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac', 'ddpg']


### Learning in Nonzero-Sum Stochastic Games with Potentials.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg']


### Learning to Weight Imperfect Demonstrations.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Leveraging Non-uniformity in First-order Non-convex Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Locally Persistent Exploration in Continuous Control Tasks with Sparse Rewards.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac']


### Logarithmic Regret for Reinforcement Learning with Linear Function Approximation.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### MURAL Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Marginalized Stochastic Natural Gradients for Black-Box Variational Inference.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Megaverse Simulating Embodied Agents at One Million Experiences per Second.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### MetaCURE Meta Reinforcement Learning with Empowerment-Driven Exploration.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Model-Based Reinforcement Learning via Latent-Space Collocation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Model-Free Reinforcement Learning from Clipped Pseudo-Regret to Sample Complexity.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Model-Free and Model-Based Policy Evaluation when Causality is Uncertain.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Model-based Reinforcement Learning for Continuous Control with Posterior Sampling.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets', 'dqn', 'sac']


### Modeling Hierarchical Structures with Continuous Recursive Neural Networks.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Modelling Behavioural Diversity for Learning in Open-Ended Games.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Modularity in Reinforcement Learning via Algorithmic Independence in Credit Assignment.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Monotonic Robust Policy Optimization with Model Discrepancy.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Muesli Combining Improvements in Policy Optimization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'sac', 'ppo', 'dreamer']


### Multi-Task Reinforcement Learning with Context-based Representations.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Multi-layered Network Exploration via Random Walks From Offline Optimization to Online Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Near Optimal Reward-Free Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Near-Optimal Model-Free Reinforcement Learning in Non-Stationary Episodic MDPs.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Near-Optimal Representation Learning for Linear Bandits and Linear RL.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Neural Architecture Search without Training.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to
* Number of seeds: 500
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Neuro-algorithmic Policies Enable Fast Combinatorial Generalization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Of Moments and Matching A Game-Theoretic Framework for Closing the Imitation Gap.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Off-Belief Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Offline Contextual Bandits with Overparameterized Models.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Offline Meta-Reinforcement Learning with Advantage Weighting.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Offline Reinforcement Learning with Fisher Divergence Critic Regularization.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Offline Reinforcement Learning with Pseudometric Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td3', 'ppo']


### On Proximal Policy Optimizations Heavy-tailed Gradients.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'a2c']


### On Reinforcement Learning with Adversarial Corruption and Its Application to Block MDP.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### On Reward-Free RL with Kernel and Neural Function Approximations Single-Agent MDP and Markov Game.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### On-Policy Deep Reinforcement Learning for the Average-Reward Criterion.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Online Learning for Load Balancing of Unknown Monotone Resource Allocation Games.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Online Learning in Unknown Markov Games.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Online Limited Memory Neural-Linear Bandits with Likelihood Matching.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Online Policy Gradient for Model Free Learning of Linear Quadratic Regulators with sqrtT Regret.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Online Submodular Resource Allocation with Applications to Rebalancing Shared Mobility Systems.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### OptiDICE Offline Policy Optimization via Stationary Distribution Correction Estimation.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 500
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Optimal regret algorithm for Pseudo-1d Bandit Convex Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### PC-MLP Model-based Reinforcement Learning with Policy Cover Guided Exploration.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo']


### PEBBLE Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervi.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac', 'a2c']


### PID Accelerated Value Iteration Algorithm.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### PODS Policy Optimization via Differentiable Simulation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Parallel Droplet Control in MEDA Biochips using Multi-Agent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Path Planning using Neural A Search.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Phasic Policy Gradient.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Policy Caches with Successor Features.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10000
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Policy Gradient Bayesian Robust Optimization for Imitation Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Policy Information Capacity Information-Theoretic Measure for Task Complexity in Deep Reinforcement .pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Posterior Value Functions Hindsight Baselines for Policy Gradient Methods.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 300
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Preferential Temporal Difference Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Principled Exploration via Optimistic Bootstrapping and Backward Induction.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Provably Correct Optimization and Exploration with Non-linear Policies.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Provably Efficient Fictitious Play Policy Optimization for Zero-Sum Markov Games with Structured Tra.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 2
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Provably Efficient Learning of Transferable Rewards.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 200
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Provably Efficient Reinforcement Learning for Discounted MDPs with Feature Mapping.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### PsiPhi-Learning Reinforcement Learning with Demonstrations using Successor Features and Inverse Temp.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### REPAINT Knowledge Transfer in Deep Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### RRL Resnet as representation for Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Randomized Entity-wise Factorization for Multi-Agent Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 24
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Randomized Exploration in Reinforcement Learning with General Value Function Approximation.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Recomposing the Reinforcement Learning Building Blocks with Hypernetworks.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'dqn', 'sac']


### Regularized Online Allocation Problems Fairness and Beyond.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Reinforcement Learning Under Moral Uncertainty.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Reinforcement Learning for Cost-Aware Markov Decision Processes.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Reinforcement Learning of Implicit and Explicit Control Flow Instructions.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Reinforcement Learning with Prototypical Representations.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Revisiting Pengs Qλ for Modern Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Revisiting Rainbow Promoting more insightful and inclusive deep reinforcement learning research.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn']


### Reward Identification in Inverse Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Risk Bounds and Rademacher Complexity in Batch Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Risk-Sensitive Reinforcement Learning with Function Approximation A Debiasing Approach.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Robust Asymmetric Learning in POMDPs.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Robust Policy Gradient against Strong Data Corruption.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Robust Reinforcement Learning using Least Squares Policy Iteration with Provable Performance Guarant.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg']


### SAINT-ACC Safety-Aware Intelligent Adaptive Cruise Control for Autonomous Vehicles Using Deep Reinfo.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### SECANT Self-Expert Cloning for Zero-Shot Generalization of Visual Policies.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### SUNRISE A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'pets', 'dqn', 'sac', 'td3', 'dreamer']


### Safe Reinforcement Learning Using Advantage-Based Intervention.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Safe Reinforcement Learning with Linear Function Approximation.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Sample Efficient Reinforcement Learning In Continuous State Spaces A Perspective Beyond Linearity.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting Pot.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 21
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'dqn']


### Scaling Multi-Agent Reinforcement Learning with Selective Parameter Sharing.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'a2c']


### Self-Improved Retrosynthetic Planning.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Self-Paced Context Evaluation for Contextual Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Skill Discovery for Exploration and Planning using Deep Skill Graphs.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Solving Challenging Dexterous Manipulation Tasks With Trajectory Optimisation and Reinforcement Lear.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'dqn', 'ddpg']


### Sparse Feature Selection Makes Batch Reinforcement Learning More Sample Efficient.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Sparsity-Agnostic Lasso Bandit.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Spectral Normalisation for Deep Reinforcement Learning An Optimisation Perspective.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### State Entropy Maximization with Random Encoders for Efficient Exploration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dreamer', 'a2c']


### State Relevance for Off-Policy Evaluation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 200
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Stochastic Iterative Graph Matching.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Structured World Belief for Reinforcement Learning in POMDP.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Targeted Data Acquisition for Evolving Negotiation Agents.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Task-Optimal Exploration in Linear Dynamical Systems.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Taylor Expansion of Discount Factors.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### TeachMyAgent a Benchmark for Automatic Curriculum Learning in Deep RL.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 32
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### TempoRL Learning When to Act.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg']


### Temporal Predictive Coding For Model-Based Planning In Latent Space.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'sac']


### Tesseract Tensorised Actors for Multi-Agent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### The Emergence of Individuality.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### The Logical Options Framework.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### The Power of Log-Sum-Exp Sequential Density Ratio Matrix Estimation for Speed-Accuracy Optimization.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Tightening the Dependence on Horizon in the Sample Complexity of Q-Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Top-k eXtreme Contextual Bandits with Arm Hierarchy.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Towards Better Laplacian Representation in Reinforcement Learning with Generalized Graph Drawing.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Towards Distraction-Robust Active Visual Tracking.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Towards Open Ad Hoc Teamwork Using Graph-based Policy Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'dqn']


### Towards Tight Bounds on the Sample Complexity of Average-reward MDPs.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Trajectory Diversity for Zero-Shot Coordination.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### UCB Momentum Q-learning Correcting the bias without forgetting.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### UneVEn Universal Value Exploration for Multi-Agent Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Unsupervised Learning of Visual 3D Keypoints for Control.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Unsupervised Skill Discovery with Bottleneck Option Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Value Alignment Verification.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Variational Empowerment as Representation Learning for Goal-Conditioned Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### World Model as a Graph Learning Latent Landmarks for Planning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg']


### Zeroth-Order Non-Convex Learning via Hierarchical Dual Averaging.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Zoo-Tuning Adaptive Transfer from A Zoo of Models.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


## Year 2022 (230 RL papers)


### A Framework for Learning to Request Rich and Contextually Useful Information from Humans.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'a2c']


### A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Minimax Learning Approach to Off-Policy Evaluation in Confounded Partially Observable Markov Decis.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### A Natural Actor-Critic Framework for Zero-Sum Markov Games.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### A Parametric Class of Approximate Gradient Updates for Policy Optimization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### A Reduction from Linear Contextual Bandits Lower Bounds to Estimations Lower Bounds.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Regret Minimization Approach to Multi-Agent Control.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### A Self-Play Posterior Sampling Algorithm for Zero-Sum Markov Games.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### A Simple Reward-free Approach to Constrained Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A Simple Unified Framework for High Dimensional Bandit Problems.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Single-Loop Gradient Descent and Perturbed Ascent Algorithm for Nonconvex Functional Constrained O.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A State-Distribution Matching Approach to Non-Episodic Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### A Temporal-Difference Approach to Policy Gradient Estimation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Action-Sufficient State Representation Learning for Control with Structural Constraints.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn', 'ddpg']


### Actor-Critic based Improper Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 200
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Adapting to Mixing Time in Stochastic Optimization with Markovian Data.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Adaptive Model Design for Markov Decision Process.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Addressing Optimism Bias in Sequence Modeling for Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Adversarially Trained Actor Critic for Offline Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'sac']


### Align-RUDDER Learning From Few Demonstrations by Reward Redistribution.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### An Analytical Update Rule for General Policy Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Analysis of Stochastic Processes through Replay Buffers.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### AnyMorph Learning Transferable Polices By Inferring Agent Morphology.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo']


### Asking for Knowledge AFK Training RL Agents to Query External Knowledge Using Language.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Augment with Care Contrastive Learning for Combinatorial Problems.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Balancing Sample Efficiency and Suboptimality in Inverse Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Bayesian Nonparametrics for Offline Skill Discovery.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Bayesian Optimization under Stochastic Delayed Feedback.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Biased Gradient Estimate with Drastic Variance Reduction for Meta Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Biological Sequence Design with GFlowNets.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Bisimulation Makes Analogies in Goal-Conditioned Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn']


### Blocks Assemble Learning to Assemble with Large-Scale Structured Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 2
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Branching Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Breaking the sqrtT Barrier Instance-Independent Logarithmic Regret in Stochastic Contextual Linear B.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Cascaded Gaps Towards Logarithmic Regret for Risk-Sensitive Reinforcement Learning.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### Causal Dynamics Learning for Task-Independent State Abstraction.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Choosing Answers in Epsilon-Best-Answer Identification for Linear Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5000
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Cliff Diving Exploring Reward Surfaces in Reinforcement Learning Environments.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'a2c']


### Communicating via Markov Decision Processes.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'a2c']


### Congested Bandits Optimal Routing via Short-term Resets.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Constrained Offline Policy Optimization.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Constrained Variational Policy Optimization for Safe Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Contextual Bandits with Large Action Spaces Made Practical.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 32
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Contextual Bandits with Smooth Regret Efficient Learning in Continuous Action Spaces.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Contextual Information-Directed Sampling.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Continuous Control with Action Quantization from Demonstrations.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Contrastive UCB Provably Efficient Contrastive Self-Supervised Learning in Online Reinforcement Lear.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Controlling Conditional Language Models without Catastrophic Forgetting.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Convergence of Policy Gradient for Entropy Regularized MDPs with Neural Network Approximation in the.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Cooperative Online Learning in Stochastic and Adversarial MDPs.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### CtrlFormer Learning Transferable State Representation for Visual Control via Transformer.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn', 'sac']


### Curriculum Reinforcement Learning via Constrained Optimal Transport.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 32
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### DNS Determinantal Point Process Based Neural Network Sampler for Ensemble Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn']


### DRIBO Robust Deep Reinforcement Learning via Multi-View Information Bottleneck.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn', 'sac']


### Decentralized Online Convex Optimization in Networked Systems.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Deconfounded Value Decomposition for Multi-Agent Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Deep Hierarchy in Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Delayed Reinforcement Learning by Imitation.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Denoised MDPs Learning World Models Better Than the World Itself.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'sac']


### Difference Advantage Estimation for Multi-Agent Policy Gradients.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### Direct Behavior Specification via Constrained Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 343
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'sac']


### Discovering Generalizable Spatial Goal Representations via Graph-based Active Reward Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Disentangling Sources of Risk for Distributional Multi-Agent Reinforcement Learning.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Distributional Hamilton-Jacobi-Bellman Equations for Continuous-Time Reinforcement Learning.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Distributionally Robust Q-Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 2000
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Divergence-Regularized Multi-Agent Actor-Critic.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Do Differentiable Simulators Give Better Policy Gradients.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### EAT-C Environment-Adversarial sub-Task Curriculum for Efficient Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['sac']


### Efficient Distributionally Robust Bayesian Optimization with Worst-case Sensitivity.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Efficient Learning for AlphaZero via Path Consistency.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Efficient Model-based Multi-agent Reinforcement Learning via Optimistic Equilibrium Computation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Efficient Reinforcement Learning in Block MDPs A Model-free Representation Learning approach.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### EqR Equivariant Representations for Data-Efficient Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn']


### Estimating and Penalizing Induced Preference Shifts in Recommender Systems.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets', 'ppo']


### Evolving Curricula with Regret-Based Environment Design.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Extracting Latent State Representations with Linear Dynamics from Rich Observations.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Fast Aquatic Swimmer Optimization with Differentiable Projective Dynamics and Neural Network Hydrody.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Fast Population-Based Reinforcement Learning on a Single Machine.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 80
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Feature and Parameter Selection in Stochastic Linear Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Federated Reinforcement Learning Linear Speedup Under Markovian Sampling.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'dqn', 'a2c', 'sac', 'ppo']


### First-Order Regret in Reinforcement Learning with Linear Function Approximation A Robust Estimation .pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### From Dirichlet to Rubin Optimistic Exploration in RL without Bonuses.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Generalized Data Distribution Iteration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn']


### Generalizing Gaussian Smoothing for Random Search.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 1000
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Generative Cooperative Networks for Natural Language Generation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Generative Flow Networks for Discrete Probabilistic Modeling.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Goal Misgeneralization in Deep Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Greedy based Value Representation for Optimal Coordination in Multi-agent Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Greedy when Sure and Conservative when Uncertain about the Opponents.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn']


### Guarantees for Epsilon-Greedy Reinforcement Learning with Function Approximation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### How to Leverage Unlabeled Data in Offline Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### How to Stay Curious while avoiding Noisy TVs using Aleatoric Uncertainty Estimation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Human-in-the-loop Provably Efficient Preference-based Reinforcement Learning with General Function A.pdf
* Matched keywords: value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Imitation Learning by Estimating Expertise of Demonstrators.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 1000
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo']


### Improve Single-Point Zeroth-Order Optimization Using High-Pass and Low-Pass Filters.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Improved No-Regret Algorithms for Stochastic Shortest Path with Linear MDP.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Improved Regret for Differentially Private Exploration in Linear MDP.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Improving Policy Optimization with Generalist-Specialist Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Independent Policy Gradient for Large-Scale Markov Potential Games Sharper Rates Function Approximat.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### Individual Reward Assisted Multi-Agent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Influence-Augmented Local Simulators a Scalable Solution for Fast Deep RL in Large Networked Systems.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Interactive Inverse Reinforcement Learning for Cooperative Games.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Interactively Learning Preference Constraints in Linear Bandits.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Inverse Contextual Bandits Learning How Behavior Evolves over Time.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Koopman Q-learning Offline Reinforcement Learning via Symmetries of Dynamics.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### LIMO Latent Inceptionism for Targeted Molecule Generation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Lagrangian Method for Q-Function Learning with Applications to Machine Translation.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Langevin Monte Carlo for Contextual Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Large Batch Experience Replay.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'dqn', 'sac']


### Large-Scale Graph Neural Architecture Search.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### LeNSE Learning To Navigate Subgraph Embeddings for Large-Scale Combinatorial Optimisation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Learning Bellman Complete Representations for Offline Policy Evaluation.pdf
* Matched keywords: value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'sac']


### Learning Dynamics and Generalization in Deep Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Learning Infinite-horizon Average-reward Markov Decision Process with Constraints.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Learning Iterative Reasoning through Energy Minimization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Learning Markov Games with Adversarial Opponents Efficient Algorithms and Fundamental Limits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Learning Mixtures of Linear Dynamical Systems.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Learning Pseudometric-based Action Representations for Offline Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Learning Stochastic Shortest Path with Linear Function Approximation.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 40
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Learning Symmetric Embeddings for Equivariant World Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Learning from Demonstration Provably Efficient Adversarial Policy Imitation with Linear Function App.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Learning from a Learning User for Optimal Recommendations.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Learning-based Optimisation of Particle Accelerators Under Partial Observability Without Real-World .pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Leveraging Approximate Symbolic Models for Reinforcement Learning via Skill Diversity.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Lyapunov Density Models Constraining Distribution Shift in Learning-Based Control.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### MASER Multi-Agent Reinforcement Learning with Subgoals Generated from Experience Replay Buffer.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Making Linear MDPs Practical via Contrastive Representation Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Meta-Learning Hypothesis Spaces for Sequential Decision-making.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Mirror Learning A Unifying Framework of Policy Optimisation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'a3c', 'ppo', 'dqn']


### ModLaNets Learning Generalisable Dynamics via Modularity and Physical Inductive Bias.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Model Selection in Batch Policy Optimization.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Model-Free Opponent Shaping.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Model-Value Inconsistency as a Signal for Epistemic Uncertainty.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dreamer', 'dqn', 'sac']


### Model-based Meta Reinforcement Learning using Graph Structured Surrogate Models and Amortized Policy.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Modeling Strong and Human-Like Gameplay with KL-Regularized Search.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Near-Optimal Algorithms for Autonomous Exploration and Multi-Goal Stochastic Shortest Path.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Near-Optimal Learning of Extensive-Form Games with Imperfect Information.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Nearly Minimax Optimal Reinforcement Learning with Linear Function Approximation.pdf
* Matched keywords: value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Nearly Optimal Policy Optimization with Stable at Any Time Guarantee.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### OFA Unifying Architectures Tasks and Modalities Through a Simple Sequence-to-Sequence Learning Frame.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Off-Policy Evaluation for Large Action Spaces via Embeddings.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Off-Policy Fitted Q-Evaluation with Differentiable Function Approximators Z-Estimation and Inference.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Off-Policy Reinforcement Learning with Delayed Rewards.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Offline Meta-Reinforcement Learning with Online Self-Supervision.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Offline RL Policies Should Be Trained to be Adaptive.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### On Improving Model-Free Algorithms for Decentralized Multi-Agent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### On Last-Iterate Convergence Beyond Zero-Sum Games.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### On Well-posedness and Minimax Optimal Rates of Nonparametric Q-function Estimation in Off-policy Eva.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### On the Hidden Biases of Policy Mirror Ascent in Continuous Action Spaces.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg']


### On the Impossibility of Learning to Cooperate with Adaptive Partner Strategies in Repeated Games.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### On the Role of Discount Factor in Offline Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo']


### On the Sample Complexity of Learning Infinite-horizon Discounted Linear Kernel MDPs.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 2
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c']


### Online Decision Transformer.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Online Learning with Knapsacks the Best of Both Worlds.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Optimal Estimation of Policy Gradient via Double Fitted Iteration.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Optimistic Linear Support and Successor Features as a Basis for Optimal Policy Transfer.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Optimizing Sequential Experimental Design with Deep Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Optimizing Tensor Network Contraction Using Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### PAGE-PG A Simple and Loopless Variance-Reduced Policy Gradient Method with Probabilistic Gradient Es.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'a2c']


### POEM Out-of-Distribution Detection with Posterior Sampling.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Parametric Visual Program Induction with Function Modularization.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Pessimism meets VCG Learning Dynamic Mechanism Design via Offline Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Pessimistic Minimax Value Iteration Provably Efficient Equilibrium Learning from Offline Datasets.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Pessimistic Q-Learning for Offline Reinforcement Learning Towards Optimal Sample Complexity.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Phasic Self-Imitative Reduction for Sparse-Reward Goal-Conditioned Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Plan Better Amid Conservatism Offline Multi-Agent Reinforcement Learning with Actor Rectification.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'ddpg']


### Plan Your Target and Learn Your Skills Transferable State-Only Imitation Learning via Decoupled Poli.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Planning with Diffusion for Flexible Behavior Synthesis.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 15
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets', 'dreamer', 'ppo', 'dqn']


### Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent RL.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 8
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'a2c', 'ppo']


### Policy Gradient Method For Robust Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Private Streaming SCO in ell_p geometry with Applications in High Dimensional Online Decision Making.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Prompting Decision Transformer for Few-Shot Policy Generalization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Provable Reinforcement Learning with a Short-Term Memory.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Provably Efficient Offline Reinforcement Learning for Partially Observable Markov Decision Processes.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Proving Theorems using Incremental Learning and Hindsight Experience Replay.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### REvolveR Continuous Evolutionary Models for Robot-to-robot Policy Transfer.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Reachability Constrained Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Recurrent Model-Free RL Can Be a Strong Baseline for Many POMDPs.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 40
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'sac', 'a2c']


### Reducing Variance in Temporal-Difference Value Estimation via Ensemble of Deep Networks.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Regret Bounds for Stochastic Shortest Path Problems with Linear Function Approximation.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Regularizing a Model-based Policy Stationary Distribution to Stabilize Offline Reinforcement Learnin.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'sac']


### Reinforcement Learning from Partial Observation Linear Function Approximation with Provable Sample E.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Reinforcement Learning with Action-Free Pre-Training from Videos.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 48
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dreamer']


### Retrieval-Augmented Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets', 'dqn']


### Revisiting Some Common Practices in Cooperative Multi-Agent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Reward-Free RL is No Harder Than Reward-Aware RL in Linear Markov Decision Processes.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### RieszNet and ForestRiesz Automatic Debiased Machine Learning with Neural Nets and Random Forests.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Risk-Averse No-Regret Learning in Online Convex Games.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Robust Deep Reinforcement Learning through Bootstrapped Opportunistic Curriculum.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 9
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Robust Imitation Learning against Variations in Environment Dynamics.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac', 'a2c']


### Robust Policy Learning over Multiple Uncertainty Sets.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Robust Task Representations for Offline Meta-Reinforcement Learning via Contrastive Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Rotting Infinitely Many-Armed Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Sample and Communication-Efficient Decentralized Actor-Critic Algorithms with Finite-Time Analysis.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Sample-Efficient Reinforcement Learning with loglogT Switching Cost.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Saute RL Almost Surely Safe Reinforcement Learning Using State Augmentation.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac', 'pets']


### Scalable Deep Reinforcement Learning Algorithms for Mean Field Games.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Self-Organized Polynomial-Time Coordination Graphs.pdf
* Matched keywords: action-value\s+function
* Number of seeds: 1000
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Showing Your Offline Reinforcement Learning Work Online Evaluation Budget Matters.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo']


### Shuffle Private Linear Contextual Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Simplex Neural Population Learning Any-Mixture Bayes-Optimality in Symmetric Zero-sum Games.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Stabilizing Off-Policy Deep Reinforcement Learning from Pixels.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Stabilizing Q-learning with Linear Architectures for Provable Efficient Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Stochastic Rising Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Supervised Off-Policy Ranking.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### Symmetric Machine Theory of Mind.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 9
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ddpg']


### Temporal Difference Learning for Model Predictive Control.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td-mpc', 'ppo', 'dreamer']


### The Geometry of Robust Value Functions.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### The Importance of Non-Markovianity in Maximum State Entropy Exploration.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### The Neural Race Reduction Dynamics of Abstraction in Gated Networks.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### The Power of Exploiter Provable Multi-Agent RL in Large State Spaces.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### The Primacy Bias in Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### The State of Sparse Training in Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'a2c', 'sac', 'td3', 'ppo']


### Thresholded Lasso Bandit.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Topology-Aware Network Pruning using Multi-stage Graph Embedding and Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'ddpg']


### Toward Compositional Generalization in Object-Oriented World Modeling.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Towards Evaluating Adaptivity of Model-Based Reinforcement Learning Methods.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dreamer']


### Towards Uniformly Superhuman Autonomy via Subdominance Minimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Training Characteristic Functions with Reinforcement Learning XAI-methods play Connect Four.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Transformers are Meta-Reinforcement Learners.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Translating Robot Skills Learning Unsupervised Skill Correspondences Across Robots.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Understanding Policy Gradient Algorithms A Sensitivity-Based Approach.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Unified Scaling Laws for Routed Language Models.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Utility Theory for Sequential Decision Making.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Versatile Offline Imitation from Observations and Examples via Regularized State-Occupancy Matching.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Welfare Maximization in Competitive Equilibrium Reinforcement Learning for Markov Exchange Economy.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Why Should I Trust You Bellman The Bellman Error is a Poor Replacement for Value Error.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'sac', 'td3', 'ppo']


### Zero-Shot Reward Specification via Grounded Natural Language.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


## Year 2023 (345 RL papers)


### A Connection between One-Step RL and Critic Regularization in Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### A Coupled Flow Approach to Imitation Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 25
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Framework for Adapting Offline Algorithms to Solve Combinatorial Multi-Armed Bandit Problems with .pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A Model-Based Method for Minimizing CVaR and Beyond.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A Near-Optimal Algorithm for Safe Reinforcement Learning Under Instantaneous Hard Constraints.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### A Reinforcement Learning Framework for Dynamic Mediation Analysis.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 200
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A Robust Test for the Stationarity Assumption in Sequential Decision Making.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### A Study of Global and Episodic Bonuses for Exploration in Contextual MDPs.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### A theory of continuous generative flow networks.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Abstract-to-Executable Trajectory Translation for One-Shot Task Generalization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Abstracting Imperfect Information Away from Two-Player Zero-Sum Games.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Accelerated Stochastic Optimization Methods under Quasar-convexity.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Active Policy Improvement from Multiple Black-box Oracles.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Actor-Critic Alignment for Offline-to-Online Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### AdaptDiffuser Diffusion Models as Adaptive Self-evolving Planners.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Adapting to game trees in zero-sum imperfect information games.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Adaptive Barrier Smoothing for First-Order Policy Gradient with Contact Dynamics.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Adaptive Coordination in Social Embodied Rearrangement.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Adversarial Cheap Talk.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Adversarial Learning of Distributional Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Aligning Language Models with Preferences through f-divergence Minimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### An Adaptive Entropy-Regularization Framework for Multi-Agent Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 9
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c', 'sac']


### An Information-Theoretic Analysis of Nonstationary Bandit Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### An Instrumental Variable Approach to Confounded Off-Policy Evaluation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Anti-Exploration by Random Network Distillation.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Arithmetic Sampling Parallel Diverse Decoding for Large Language Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Atari-5 Distilling the Arcade Learning Environment down to Five Games.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a3c', 'dqn']


### Attention-Based Recurrence for Multi-Agent Reinforcement Learning under Stochastic Partial Observabi.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'a2c']


### Autoregressive Diffusion Model for Graph Generation.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Bandit Multi-linear DR-Submodular Maximization and Its Applications on Adversarial Submodular Bandit.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Bandits with Knapsacks Advice on Time-Varying Demands.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Bayesian Design Principles for Frequentist Sequential Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Bayesian Reparameterization of Reward-Conditioned Reinforcement Learning with Energy-based Models.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Behavior Contrastive Learning for Unsupervised Skill Discovery.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 1200
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'sac']


### Best Arm Identification in Multi-Agent Multi-Armed Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Best of Both Worlds Policy Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Better Training of GFlowNets with Local Credit and Incomplete Trajectories.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Beyond Exponentially Fast Mixing in Average-Reward Reinforcement Learning via Multi-Level Monte Carl.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['sac']


### Beyond Reward Offline Preference-guided Policy Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Biases in Evaluation of Molecular Optimization Methods and Bias Reduction Strategies.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Bigger Better Faster Human-level Atari with human-level efficiency.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Boosting Offline Reinforcement Learning with Action Preference Query.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'sac']


### Bootstrapped Representations in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### CLUTR Curriculum Learning via Unsupervised Task Representation Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### CO-BED Information-Theoretic Contextual Optimization via Bayesian Experimental Design.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 32
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Cell-Free Latent Go-Explore.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### ChiPFormer Transferable Chip Placement via Offline Decision Transformer.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### CircuitNet A Generic Neural Network to Realize Universal Circuit Motif Modeling.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Combinatorial Neural Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Complementary Attention for Multi-Agent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg']


### Computationally Efficient PAC RL in POMDPs with Latent Determinism and Conditional Embeddings.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### ConCerNet A Contrastive Learning Based Framework for Automated Conservation Law Discovery and Trustw.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Consistency Models.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Constrained Decision Transformer for Offline Safe Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Context-Aware Bayesian Network Actor-Critic Methods for Cooperative Multi-Agent Reinforcement Learni.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Contextual Combinatorial Bandits with Probabilistically Triggered Arms.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Contextual Conservative Interleaving Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Contextual Reliability When Different Features Matter in Different Contexts.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Continual Task Allocation in Meta-Policy Network via Sparse Prompting.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### ContraBAR Contrastive Bayes-Adaptive Deep RL.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Contrastive Energy Prediction for Exact Energy-Guided Diffusion Sampling in Offline Reinforcement Le.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Controllability-Aware Unsupervised Skill Discovery.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Controlling Type Confounding in Ad Hoc Teamwork with Instance-wise Teammate Feedback Rectification.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Convergence of Proximal Point and Extragradient-Based Methods Beyond Monotonicity the Case of Negati.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Cooperative Multi-Agent Reinforcement Learning Asynchronous Communication and Linear Function Approx.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Cooperative Open-ended Learning Framework for Zero-Shot Coordination.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Correcting discount-factor mismatch in on-policy policy gradient methods.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn']


### Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear Contextual Bandits and Markov .pdf
* Matched keywords: value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Curiosity in Hindsight Intrinsic Exploration in Stochastic Environments.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Curious Replay for Model-based Adaptation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 7
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'sac']


### Deep Anomaly Detection under Labeling Budget Constraints.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Deep Graph Representation Learning and Optimization for Influence Maximization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Deep Laplacian-based Options for Temporally-Extended Exploration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Deep Temporal Sets with Evidential Reinforced Attentions for Unique Behavioral Pattern Discovery.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Delay-Adapted Policy Optimization and Improved Regret for Adversarial MDP with Delayed Bandit Feedba.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Demonstration-free Autonomous Reinforcement Learning via Implicit and Bidirectional Curriculum.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Detecting Adversarial Directions in Deep Reinforcement Learning to Make Robust Decisions.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Diagnosis Feedback Adaptation A Human-in-the-Loop Framework for Test-Time Policy Adaptation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets', 'ppo', 'sac']


### Differentially Private Episodic Reinforcement Learning with Heavy-tailed Rewards.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Diffusion Models for Black-Box Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Discovering Object-Centric Generalized Value Functions From Pixels.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Distance Weighted Supervised Learning for Offline Interaction Data.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'td3', 'ppo', 'dqn']


### Distilling Internet-Scale Vision-Language Models into Embodied Agents.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Distributional Offline Policy Evaluation with Predictive Error Guarantees.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Do Embodied Agents Dream of Pixelated Sheep Embodied Decision Making using Language Guided World Mod.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dreamer']


### Do the Rewards Justify the Means Measuring Trade-Offs Between Rewards and Ethical Behavior in the Ma.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### DoMo-AC Doubly Multi-step Off-policy Actor-Critic Algorithm.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Does Sparsity Help in Learning Misspecified Linear Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### ED-Batch Efficient Automatic Batching of Dynamic Neural Networks via Learned Finite State Machines.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 1000
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Efficient Exploration via Epistemic-Risk-Seeking Policy Optimization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Efficient Online Reinforcement Learning with Offline Data.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'pets', 'dqn', 'sac', 'ppo']


### Efficient RL via Disentangled Environment and Agent Representations.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Efficient Rate Optimal Regret for Adversarial Contextual MDPs Using Online Function Approximation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Emergence of Adaptive Circadian Rhythms in Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Emergent Agentic Transformer from Chain of Hindsight Experience.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'td3', 'ppo']


### Enabling First-Order Gradient-Based Learning for Equilibrium Computation in Markets.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Enforcing Hard Constraints with Soft Barriers Safe Reinforcement Learning in Unknown Stochastic Envi.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Enhancing Activity Prediction Models in Drug Discovery with the Ability to Understand Human Language.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Eventual Discounting Temporal Logic Counterfactual Experience Replay.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Explainability as statistical inference.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Explaining Reinforcement Learning with Shapley Values.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Exploring Chemical Space with Score-based Out-of-distribution Generation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Exploring the Benefits of Training Expert Language Models over Instruction Tuning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Exponential Smoothing for Off-Policy Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Facial Expression Recognition with Adaptive Frame Rate based on Multiple Testing Correction.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Fair and Accurate Decision Making through Group-Aware Learning.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Fair yet Asymptotically Equal Collaborative Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Fascinating Supervisory Signals and Where to Find Them Deep Anomaly Detection with Scale Learning.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Fast Rates for Maximum Entropy Exploration.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 48
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### FedHPO-Bench A Benchmark Suite for Federated Hyperparameter Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Flipping Coins to Estimate Pseudocounts for Exploration in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 12
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### For Pre-Trained Vision Models in Motor Control Not All Policy Learning Methods are Created Equal.pdf
* Matched keywords: our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm), policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg']


### Future-conditioned Unsupervised Pretraining for Decision Transformer.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### GFlowNet-EM for Learning Compositional Latent Variable Models.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### GFlowOut Dropout with Generative Flow Networks.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Generating Language Corrections for Teaching Physical Control Tasks.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Generative Pretraining for Black-Box Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Global Optimization with Parametric Function Approximation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Go Beyond Imagination Maximizing Episodic Reachability with World Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dreamer']


### Graph Reinforcement Learning for Network Control via Bi-Level Optimization.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'a2c']


### Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Guiding Pretraining in Reinforcement Learning with Large Language Models.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Hardness of Independent Learning and Sparse Equilibrium Computation in Markov Games.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 1
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### HarsanyiNet Computing Accurate Shapley Values in a Single Forward Propagation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Hierarchical Diffusion for Offline Decision Making.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Hierarchical Imitation Learning with Vector Quantized Models.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Hierarchical Programmatic Reinforcement Learning via Learning to Compose Programs.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Hierarchies of Reward Machines.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Hindsight Learning for MDPs with Exogenous Inputs.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Horizon-Free and Variance-Dependent Reinforcement Learning for Latent Markov Decision Processes.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Horizon-free Learning for Markov Decision Processes and Games Stochastically Bounded Rewards and Imp.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Hyperparameters in Reinforcement Learning and How To Tune Them.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 2187
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### ILLUME Rationalizing Vision-Language Models through Human Interactions.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Identifiability and Generalizability in Constrained Inverse Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Improved Policy Evaluation for Randomized Trials of Algorithmic Resource Allocation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Improved Regret for Efficient Online Reinforcement Learning with Linear Function Approximation.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Improving Bi-level Optimization Based Methods with Inspiration from Humans Classroom Study Technique.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Incentivizing Exploration with Linear Contexts and Combinatorial Actions.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Information-Theoretic State Space Model for Multi-View Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Interactive Object Placement with Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'sac', 'a2c']


### Internally Rewarded Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Internet Explorer Targeted Representation Learning on the Open Web.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['pets', 'ppo', 'sac']


### Invariance in Policy Optimisation and Partial Identifiability in Reward Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Inverse Reinforcement Learning without Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'dqn', 'sac']


### Investigating the Role of Model-Based Learning in Exploration and Transfer.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn']


### Jump-Start Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### K-SHAP Policy Clustering Algorithm for Anonymous Multi-Agent State-Action Pairs.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### LESSON Learning to Integrate Exploration Strategies for Reinforcement Learning via an Option Framewo.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### LIV Language-Image Representations and Rewards for Robotic Control.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Langevin Thompson Sampling with Logarithmic Communication Bandits and Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Language Instructed Reinforcement Learning for Human-AI Coordination.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Layered State Discovery for Incremental Autonomous Exploration.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Lazy Agents A New Perspective on Solving Sparse Reward Problem in Multi-agent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'ddpg']


### Learning Belief Representations for Partially Observable Deep RL.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Learning Compiler Pass Orders using Coreset and Normalized Value Prediction.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Learning Control by Iterative Inversion.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'a2c']


### Learning GFlowNets From Partial Episodes For Improved Convergence And Stability.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c', 'sac']


### Learning Globally Smooth Functions on Manifolds.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Learning Mixtures of Markov Chains and MDPs.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Temporally AbstractWorld Models without Online Experimentation.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Learning for Edge-Weighted Online Bipartite Matching with Robustness Guarantees.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Learning in POMDPs is Sample-Efficient with Hindsight Observability.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning to Bid in Repeated First-Price Auctions with Budgets.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Learning to Incentivize Information Acquisition Proper Scoring Rules Meet Principal-Agent Model.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning to Initiate and Reason in Event-Driven Cascading Processes.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Learning to Maximize Mutual Information for Dynamic Feature Selection.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Leveraging Offline Data in Online Reinforcement Learning.pdf
* Matched keywords: action-value\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### LipsNet A Smooth and Robust Neural Network with Adaptive Lipschitz Constant for High Accuracy Optima.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'ddpg']


### Live in the Moment Learning Dynamics Model Adapted to Evolving Policy.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Local Optimization Achieves Global Optimality in Multi-Agent Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn']


### Low-Switching Policy Gradient with Exploration via Online Sensitivity Sampling.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Lower Bounds for Learning in Revealing POMDPs.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### MAHALO Unifying Offline Reinforcement Learning and Imitation Learning from Observations.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### MANSA Learning Fast and Slow in Multi-Agent Systems.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Mastering the Unsupervised Reinforcement Learning Benchmark from Pixels.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac', 'td-mpc', 'ppo', 'dreamer']


### Meta Learning of Interface Conditions for Multi-Domain Physics-Informed Neural Networks.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Meta-SAGE Scale Meta-Learning Scheduled Adaptation with Guided Exploration for Mitigating Scale Shif.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Meta-learning Parameterized Skills.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### MetaDiffuser Diffusion Model as Conditional Planner for Offline Meta-RL.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### MetricGAN-OKD Multi-Metric Optimization of MetricGAN via Online Knowledge Distillation for Speech En.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Model-Bellman Inconsistency for Model-based Offline Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Model-Free Robust Average-Reward Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Model-based Offline Reinforcement Learning with Count-based Conservatism.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'a2c', 'sac', 'td3', 'ppo']


### Model-based Reinforcement Learning with Scalable Composite Policy Gradient Estimators.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dreamer']


### Multi-Agent Learning from Learners.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Multi-Environment Pretraining Enables Transfer to Action Limited Datasets.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Multi-Objective GFlowNets.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'a2c']


### Multi-User Reinforcement Learning with Low Rank Rewards.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Multi-channel Autobidding with Budget and ROI Constraints.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Multi-task Hierarchical Adversarial Inverse Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Multi-task Representation Learning for Pure Exploration in Linear Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### MyoDex A Generalizable Prior for Dexterous Manipulation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### NNSplitter An Active Defense Solution for DNN Model via Automated Weight Obfuscation.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Near-Optimal Φ-Regret Learning in Extensive-Form Games.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Near-optimal Conservative Exploration in Reinforcement Learning under Episode-wise Constraints.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Nearly Minimax Optimal Regret for Learning Linear Mixture Stochastic Shortest Path.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Nearly Minimax Optimal Reinforcement Learning for Linear Markov Decision Processes.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Nearly Optimal Competitive Ratio for Online Allocation Problems with Two-sided Resource Constraints .pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Non-stationary Reinforcement Learning under General Function Approximation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### NtextAtext2Q Neural Attention Additive Model for Interpretable Multi-Agent Q-Learning.pdf
* Matched keywords: action-value\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### Off-Policy Average Reward Actor-Critic with Deterministic Policy Search.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Offline Learning in Markov Games with General Function Approximation.pdf
* Matched keywords: value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Offline Meta Reinforcement Learning with In-Distribution Online Adaptation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Offline Reinforcement Learning with Closed-Form Policy Improvement Operators.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'sac', 'td3', 'ppo']


### On Many-Actions Policy Gradient.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 15
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn', 'sac']


### On Penalty-based Bilevel Gradient Descent Method.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 1000
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### On the Convergence of SARSA with Linear Function Approximation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### On the Effectiveness of Offline RL for Dialogue Response Generation.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### On the Global Convergence of Fitted Q-Iteration with Two-layer Neural Network Parametrization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### On the Global Convergence of Risk-Averse Policy Gradient Methods with Expected Conditional Risk Meas.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### On the Importance of Feature Decorrelation for Unsupervised Representation Learning in Reinforcement.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### On the Interplay Between Misspecification and Sub-optimality Gap in Linear Contextual Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 8
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### On the Occupancy Measure of Non-Markovian Policies in Continuous MDPs.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### On the Power of Pre-training for Generalization in RL Provable Benefits and Hardness.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### On the Statistical Benefits of Temporal Difference Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### One-shot Imitation in a Non-Stationary Environment via Multi-Modal Skill.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Online Learning in Stackelberg Games with an Omniscient Follower.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'ddpg']


### Online Nonstochastic Control with Adversarial and Static Constraints.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Online Prototype Alignment for Few-shot Policy Transfer.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Online Restless Bandits with Unobserved States.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg']


### Optimal Horizon-Free Reward-Free Exploration for Linear Mixture MDPs.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heterosced.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Optimal Rates and Efficient Algorithms for Online Bayesian Persuasion.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Optimistic Planning by Regularized Dynamic Programming.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Optimizing DDPM Sampling with Shortcut Fine-Tuning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Oracles  Followers Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### PPG Reloaded An Empirical Study on What Matters in Phasic Policy Gradient.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Parallel Q-Learning Scaling Off-policy Reinforcement Learning under Massively Parallel Simulation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a3c', 'dqn', 'ddpg', 'a2c', 'sac', 'ppo']


### Partially Observable Multi-agent RL with Quasi-Efficiency The Blessing of Information Sharing.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Performative Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Policy Contrastive Imitation Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg']


### Policy Gradient in Robust MDPs with Global Convergence Guarantee.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Policy Regularization with Dataset Constraint for Offline Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn']


### Posterior Sampling for Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn']


### Predictable MDP Abstraction for Unsupervised Model-Based RL.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'sac']


### Prefer to Classify Improving Text Classifiers via Auxiliary Preference Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Pretraining Language Models with Human Preferences.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Principled Offline RL in the Presence of Rich Exogenous Information.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### PromptBoosting Black-Box Text Classification with Ten Forward Passes.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Provable Reset-free Reinforcement Learning by No-Regret Reduction.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Provably Efficient Offline Reinforcement Learning with Perturbed Data Sources.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Provably Efficient Representation Learning with Tractable Planning in Low-Rank POMDP.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 7
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Provably and Practically Efficient Neural Contextual Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Q-learning Decision Transformer Leveraging Dynamic Programming for Conditional Sequence Modelling in.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### QAS-Bench Rethinking Quantum Architecture Search and A Benchmark.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Quantile Credit Assignment.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn']


### Quantum Policy Gradient Algorithm with Optimized Action Decoding.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function
* Number of seeds: 2
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### QuantumDARTS Differentiable Quantum Architecture Search for Variational Quantum Algorithms.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### RACE Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evol.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'ddpg']


### RLang A Declarative Language for Describing Partial World Knowledge to Reinforcement Learning Agents.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### ReLOAD Reinforcement Learning with Optimistic Ascent-Descent for Last-Iterate Convergence in Constra.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'ddpg']


### Reachability-Aware Laplacian Representation in Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### Regret Bounds for Markov Decision Processes with Recursive Optimized Certainty Equivalents.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Regret Minimization and Convergence to Equilibria in General-sum Markov Games.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Regularization and Variance-Weighted Regression Achieves Minimax Optimality in Linear MDPs Theory an.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Reinforcement Learning Can Be More Efficient with Multiple Rewards.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Reinforcement Learning from Passive Data via Latent Intentions.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Reinforcement Learning in Low-rank MDPs with Density Features.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Reinforcement Learning with General Utilities Simpler Variance Reduction and Large State-Action Spac.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Reinforcement Learning with History Dependent Dynamic Contexts.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Reparameterized Policy Learning for Multimodal Trajectory Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'sac']


### Representation Learning with Multi-Step Inverse Kinematics An Efficient and Optimal Approach to Rich.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Representation-Driven Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Representations and Exploration for Deep Reinforcement Learning using Singular Value Decomposition.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Revisiting Bellman Errors for Offline Model Selection.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Revisiting Domain Randomization via Relaxed State-Adversarial Policy Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Revisiting Weighted Aggregation in Federated Learning with Neural Networks.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Revisiting the Linear-Programming Framework for Offline RL with General Function Approximation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Reward-Mixing MDPs with Few Latent Contexts are Learnable.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Robust Budget Pacing with a Single Sample.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Robust Satisficing MDPs.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Robust Situational Reinforcement Learning in Face of Context Disturbances.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### Robust Subtask Learning for Compositional Generalization.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### SNeRL Semantic-aware Neural Radiance Fields for Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'sac']


### STEERING  Stein Information Directed Exploration for Model-Based Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Safe Offline Reinforcement Learning with Real-Time Budget Constraints.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets', 'ppo', 'dqn', 'sac']


### Scalable Multi-Agent Reinforcement Learning through Intelligent Information Aggregation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Scalable Safe Policy Improvement via Monte Carlo Tree Search.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10000
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### SeMAIL Eliminating Distractors in Visual Imitation via Separated Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dreamer']


### Semi Bandit dynamics in Congestion Games Convergence to Nash Equilibrium and No-Regret Guarantees.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Semi-Offline Reinforcement Learning for Optimized Text Generation.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'dqn', 'sac']


### Sequential Counterfactual Risk Minimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Set-membership Belief State-based Reinforcement Learning for POMDPs.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Settling the Reward Hypothesis.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Sharp Variance-Dependent Bounds in Reinforcement Learning Best of Both Worlds in Stochastic and Dete.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Short-lived High-volume Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Simple Embodied Language Learning as a Byproduct of Meta-Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Simplified Temporal Consistency Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['pets', 'dqn', 'ddpg', 'sac', 'td-mpc', 'ppo', 'dreamer']


### Smooth Non-stationary Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Social learning spontaneously emerges by searching optimal heuristics with deep reinforcement learni.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Spatial-Temporal Graph Learning with Adversarial Contrastive Adaptation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### SpotEM Efficient Video Search for Episodic Memory.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Stein Variational Goal Generation for adaptive Exploration in Multi-Goal Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 12
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'ddpg']


### Stochastic Gradient Succeeds for Bandits.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Stochastic Policy Gradient Methods Improved Sample Complexity for Fisher-non-degenerate Policies.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### StriderNet A Graph Reinforcement Learning Approach to Optimize Atomic Structures on Rough Energy Lan.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Subequivariant Graph Reinforcement Learning in 3D Environments.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Superhuman Fairness.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Supported Trust Region Optimization for Offline Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'td3', 'ppo', 'dqn']


### Symmetry-Aware Robot Design with Structured Subgroups.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### TGRL An Algorithm for Teacher Guided Reinforcement Learning.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to, through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Target-based Surrogates for Stochastic Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### The Benefits of Model-Based Generalization in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn', 'sac']


### The Blessing of Heterogeneity in Federated Q-Learning Linear Speedup and Beyond.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### The Dormant Neuron Phenomenon in Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### The Ideal Continual Learner An Agent That Never Forgets.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### The Optimal Approximation Factors in Misspecified Off-Policy Value Function Estimation.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### The Statistical Benefits of Quantile Temporal-Difference Learning for Value Estimation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### The Unintended Consequences of Discount Regularization Improving Regularization in Certainty Equival.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 256
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### The Wisdom of Hindsight Makes Language Models Better Instruction Followers.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Toward Efficient Gradient-Based Value Estimation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'dqn', 'ddpg']


### Towards Omni-generalizable Neural Methods for Vehicle Routing Problems.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Towards Robust and Safe Reinforcement Learning with Benign Off-policy Data.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Towards Understanding and Improving GFlowNet Training.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Towards a better understanding of representation dynamics under TD-learning.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Training-Free Neural Active Learning with Initialization-Robustness Guarantees.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Transformer-based Stagewise Decomposition for Large-Scale Multistage Stochastic Optimization.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Truncating Trajectories in Monte Carlo Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Tuning Computer Vision Models With Task Rewards.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### UPSCALE Unconstrained Channel Pruning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Understanding Plasticity in Neural Networks.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Understanding Self-Predictive Learning for Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Understanding the Complexity Gains of Single-Task RL with a Curriculum.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Universal Morphology Control via Contextual Modulation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Unsupervised Skill Discovery for Learning Shared Structures across Changing Environments.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Variance Control for Distributional Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Variational Curriculum Reinforcement Learning for Unsupervised Discovery of Skills.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['pets', 'ppo', 'dqn', 'sac']


### Warm-Start Actor-Critic From Approximation Error to Sub-optimality Gap.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Weighted Sampling without Replacement for Deep Top-k Classification.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### What can online reinforcement learning with function approximation benefit from general coverage con.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### What is Essential for Unseen Goal Generalization of Offline Goal-conditioned RL.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### When is Realizability Sufficient for Off-Policy Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Which Tricks are Important for Learning to Rank.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Who Needs to Know Minimal Knowledge for Optimal Coordination.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'a2c']


### Why Target Networks Stabilise Temporal Difference Methods.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


## Year 2024 (429 RL papers)


### A Bayesian Approach to Online Planning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['sac']


### A Contextual Combinatorial Bandit Approach to Negotiation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### A Dense Reward View on Aligning Text-to-Image Diffusion with Preference.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### A Distributional Analogue to the Successor Representation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A General Framework for Sequential Decision-Making under Adaptivity Constraints.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A General Online Algorithm for Optimizing Complex Performance Metrics.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A Hierarchical Adaptive Multi-Task Reinforcement Learning Framework for Multiplier Circuit Design.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### A Language Models Guide Through Latent Space.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Minimaximalist Approach to Reinforcement Learning from Human Feedback.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### A Neural-Guided Dynamic Symbolic Network for Exploring Mathematical Expressions from Data.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A Primal-Dual Algorithm for Offline Constrained Reinforcement Learning with Linear MDPs.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Single-Loop Robust Policy Gradient Method for Robust Markov Decision Processes.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### A Statistical Framework for Data-dependent Retrieval-Augmented Models.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A Unified Adaptive Testing System Enabled by Hierarchical Structure Search.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A Unified Linear Programming Framework for Offline Reward Learning from Human Demonstrations and Fee.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### ACE Off-Policy Actor-Critic with Causality-Aware Entropy Regularization.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'td3', 'ppo']


### ACPO A Policy Optimization Algorithm for Average MDPs with Constraints.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### AD3 Implicit Action is the Key for World Models to Distinguish the Diverse Visual Distractors.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dreamer']


### AI Alignment with Changing and Influenceable Reward Functions.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### ATraDiff Accelerating Online Reinforcement Learning with Imaginary Trajectories.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Absolute Policy Optimization Enhancing Lower Probability Bound of Performance with High Confidence.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac', 'a2c']


### Accelerated Policy Gradient On the Convergence Rates of the Nesterov Momentum for Reinforcement Lear.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'a2c']


### Accelerated Policy Gradient for s-rectangular Robust MDPs with Large State Spaces.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Accelerating Look-ahead in Bayesian Optimization Multilevel Monte Carlo is All you Need.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Acquiring Diverse Skills using Curriculum Reinforcement Learning with Mixture of Experts.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 24
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Activation-Descent Regularization for Input Optimization of ReLU Networks.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'sac', 'ddpg']


### Active Preference Learning for Large Language Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 9
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Adapting Static Fairness to Sequential Decision-Making Bias Mitigation Strategies towards Equal Long.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Adaptive Advantage-Guided Policy Regularization for Offline Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'sac', 'td3', 'ppo']


### Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich Differentiable Simulation.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Adaptive Sampling of k-Space in Magnetic Resonance for Rapid Pathology Prediction.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Adaptive-Gradient Policy Optimization Enhancing Policy Learning in Non-Smooth Differentiable Simulat.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'sac']


### Adaptively Learning to Select-Rank in Online Platforms.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 300
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Advancing DRL Agents in Commercial Fighting Games Training Integration and Agent-Human Alignment.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Adversarial Attacks on Combinatorial Multi-Armed Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Agent Instructs Large Language Models to be General Zero-Shot Reasoners.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'sac']


### Agnostic Interactive Imitation Learning New Theory and Practical Algorithms.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Align Your Steps Optimizing Sampling Schedules in Diffusion Models.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### AlphaZero-Like Tree-Search can Guide Large Language Model Decoding and Training.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### An Improved Finite-time Analysis of Temporal Difference Learning with Deep Neural Networks.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### An Information Theoretic Approach to Interaction-Grounded Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 16
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### ArCHer Training Language Model Agents via Hierarchical Multi-Turn RL.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Augmenting Decision with Hypothesis in Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'ddpg']


### Averaging n-step Returns Reduces Variance in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### BAGEL Bootstrapping Agents by Guiding Exploration with Language.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### BRAIn Bayesian Reward-conditioned Amortized Inference for natural language generation from feedback.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Bayesian Design Principles for Offline-to-Online Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'dqn']


### Bayesian Exploration Networks.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Bayesian Regret Minimization in Offline Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Behavior Generation with Latent Actions.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### BeigeMaps Behavioral Eigenmaps for Reinforcement Learning from Images.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Best Arm Identification for Stochastic Rising Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Boosting Reinforcement Learning with Strongly Delayed Feedback Through Auxiliary Short Delays.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Breadth-First Exploration on Adaptive Grid for Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Bridging Environments and Language with Rendering Functions and Vision-Language Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Bring Your Own Non-Robust Algorithm to Solve Robust MDPs by Estimating The Worst Kernel.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 40
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Building Socially-Equitable Public Models.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### CHEMREASONER Heuristic Search over a Large Language Models Knowledge Space using Quantum-Chemical Fe.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Causal Action Influence Aware Counterfactual Data Augmentation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn']


### Chain-of-Thought Predictive Control.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Closing the Gap Achieving Global Convergence Last Iterate of Actor-Critic under Markovian Sampling w.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Coactive Learning for Large Language Models using Implicit User Feedback.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Code as Reward Empowering Reinforcement Learning with VLMs.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Combinatorial Multivariant Multi-Armed Bandits with Applications to Episodic Reinforcement Learning .pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Combining Experimental and Historical Data for Policy Evaluation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Compact Optimality Verification for Optimization Proxies.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Confidence Aware Inverse Constrained Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Configurable Mirror Descent Towards a Unification of Decision Making.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Confronting Reward Overoptimization for Diffusion Models A Perspective of Inductive and Primacy Bias.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Constrained Ensemble Exploration for Unsupervised Skill Discovery.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 1320
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn', 'sac']


### Constrained Reinforcement Learning Under Model Mismatch.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Contrastive Representation for Data Filtering in Cross-Domain Offline Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Controlled Decoding from Language Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'ddpg']


### Coprocessor Actor Critic A Model-Based Reinforcement Learning Approach For Adaptive Brain Stimulatio.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Cross-Domain Policy Adaptation by Capturing Representation Mismatch.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### DIDI Diffusion-Guided Diversity for Offline Behavioral Generation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### DISCRET Synthesizing Faithful Explanations For Treatment Effect Estimation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### DRED Zero-Shot Transfer in Reinforcement Learning via Data-Regularised Environment Design.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a3c', 'ppo']


### Dealing With Unbounded Gradients in Stochastic Saddle-point Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Debiased Offline Representation Learning for Fast Online Adaptation in Non-stationary Dynamics.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### DecisionNCE Embodied Multimodal Representations via Implicit Preference Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Decoding-time Realignment of Language Models.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Deep Demonstration Tracing Learning Generalizable Imitator Policy for Runtime Imitation from a Singl.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### DeepPolar Inventing Nonlinear Large-Kernel Polar Codes via Deep Learning.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Degeneration-free Policy Optimization RL Fine-Tuning for Language Models without Degeneration.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Dense Reward for Free in Reinforcement Learning from Human Feedback.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Detecting Influence Structures in Multi-Agent Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### DiffStitch Boosting Offline Reinforcement Learning with Diffusion-based Trajectory Stitching.pdf
* Matched keywords: state-action\s+pairs
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Diffusion Model-Augmented Behavioral Cloning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'a2c']


### Discovering Multiple Solutions from a Single Task in Offline Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'dqn']


### DistiLLM Towards Streamlined Distillation for Large Language Models.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Distilling Morphology-Conditioned Hypernetworks for Efficient Universal Morphology Control.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Distributional Bellman Operators over Mean Embeddings.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Do Transformer World Models Give Better Policy Gradients.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Dr Strategy Model-Based Generalist Agents with Strategic Dreaming.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dreamer']


### Drug Discovery with Dynamic Goal-aware Fragments.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### DynSyn Dynamical Synergistic Representation for Efficient Learning and Control in Overactuated Embod.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### ELTA An Enhancer against Long-Tail for Aesthetics-oriented Models.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'sac', 'ddpg']


### Efficient Denoising Diffusion via Probabilistic Masking.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Efficient Exploration for LLMs.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Efficient Exploration in Average-Reward Constrained Reinforcement Learning Achieving Near-Optimal Re.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Efficient Policy Evaluation with Offline Data Informed Behavior Policy Design.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 900
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Efficient Value Iteration for s-rectangular Robust Markov Decision Processes.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Efficient World Models with Context-Aware Tokenization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dreamer']


### EfficientZero V2 Mastering Discrete and Continuous Control with Limited Data.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td-mpc', 'dreamer', 'ppo', 'sac']


### Eluder-based Regret for Stochastic Contextual MDPs.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Embarrassingly Parallel GFlowNets.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Embodied CoT Distillation From LLM To Off-the-shelf Agents.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Emergence of In-Context Reinforcement Learning from Noise Distillation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['sac']


### End-to-End Neuro-Symbolic Reinforcement Learning with Textual Explanations.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo']


### Energy-Guided Diffusion Sampling for Offline-to-Online Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Enhancing Value Function Estimation through First-Order State-Action Dynamics in Offline Reinforceme.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Entropy-Reinforced Planning with Large Language Models for Drug Discovery.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Environment Design for Inverse Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### EvIL Evolution Strategies for Generalisable Imitation Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### EvoRainbow Combining Improvements in Evolutionary Reinforcement Learning for Policy Search.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Expert Proximity as Surrogate Rewards for Single Demonstration Imitation Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Exploration and Anti-Exploration with Distributional Random Network Distillation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Exploration-Driven Policy Optimization in RLHF Theoretical Insights on Efficient Data Utilization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### FESSNC Fast Exponentially Stable and Safe Neural Controller.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Factored-Reward Bandits with Intermediate Observations.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Failures Are Fated But Can Be Faded Characterizing and Mitigating Unwanted Behaviors in Large-Scale .pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Fair Off-Policy Learning from Observational Data.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Fast Peer Adaptation with Context-aware Exploration.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 54
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Fast and Sample Efficient Multi-Task Representation Learning in Stochastic Contextual Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Feasibility Consistent Representation Learning for Safe Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'dreamer', 'ppo', 'sac']


### Feasible Reachable Policy Iteration.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Federated Combinatorial Multi-Agent Multi-Armed Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Federated Offline Reinforcement Learning Collaborative Single-Policy Coverage Suffices.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c']


### Feedback Efficient Online Fine-Tuning of Diffusion Models.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Feedback Loops With Language Models Drive In-Context Reward Hacking.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Feel-Good Thompson Sampling for Contextual Dueling Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### FightLadder A Benchmark for Competitive Multi-Agent Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Fine-Grained Causal Dynamics Learning with Quantization for Improving Robustness in Reinforcement Le.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Fine-tuning Reinforcement Learning Models is Secretly a Forgetting Mitigation Problem.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Finite-Time Convergence and Sample Complexity of Actor-Critic Multi-Objective Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, state-action\s+pairs
* Number of seeds: 500
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Foundation Policies with Hilbert Representations.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3']


### Fourier Controller Networks for Real-Time Decision-Making in Embodied Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### From Inverse Optimization to Feasibility to ERM.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### From Self-Attention to Markov Models Unveiling the Dynamics of Generative Transformers.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### From Words to Actions Unveiling the Theoretical Underpinnings of LLM-Driven Autonomous Systems.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### FuRL Visual-Language Models as Fuzzy Rewards for Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['sac']


### Fundamental Limitations of Alignment in Large Language Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### GFlowNet Training by Policy Gradients.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn']


### Generalization to New Sequential Decision Making Tasks with In-Context Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn', 'sac']


### Generalized Preference Optimization A Unified Approach to Offline Alignment.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Generalized Smooth Variational Inequalities Methods with Adaptive Stepsizes.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Generative Marginalization Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Geometric Active Exploration in Markov Decision Processes the Benefit of Abstraction.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 15
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Global Reinforcement Learning  Beyond Linear and Convex Rewards via Submodular Semi-gradient Methods.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Graph-Triggered Rising Bandits.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Graphon Mean Field Games with a Representative Player Analysis and Learning Algorithm.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### HGAP Boosting Permutation Invariant and Permutation Equivariant in Multi-Agent Reinforcement Learnin.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg']


### HGCN2SP Hierarchical Graph Convolutional Network for Two-Stage Stochastic Programming.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Hard Tasks First Multi-Task Reinforcement Learning Through Task Scheduling.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### HarmoDT Harmony Multi-Task Decision Transformer for Offline Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### HarmonyDream Task Harmonization Inside World Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td-mpc', 'ppo', 'dreamer']


### High-dimensional Linear Bandits with Knapsacks.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Highway Value Iteration Networks.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### How Does Goal Relabeling Improve Sample Efficiency.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### How do Large Language Models Navigate Conflicts between Honesty and Helpfulness.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### How to Explore with Belief State Entropy Maximization in POMDPs.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 16
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### How to Leverage Diverse Demonstrations in Offline Imitation Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Human Alignment of Large Language Models through Online Preference Optimisation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Hybrid Inverse Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'sac']


### Hybrid Reinforcement Learning from Offline Observation Alone.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Imitation Learning from Purified Demonstrations.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Imitation Learning in Discounted Linear MDPs without exploration assumptions.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Implicit Bias of Policy Gradient in Linear Quadratic Control Extrapolation to Unseen Initial States.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Improving Generalization in Offline Reinforcement Learning via Adversarial Data Splitting.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'sac', 'td3', 'ppo']


### Improving Instruction Following in Language Models through Proxy-Based Uncertainty Estimation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Improving Prototypical Visual Explanations with Reward Reweighing Reselection and Retraining.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Improving Sample Efficiency of Model-Free Algorithms for Zero-Sum Markov Games.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Improving Token-Based World Models with Parallel Observation Prediction.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'sac']


### In value-based deep reinforcement learning a pruned network is a good network.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### In-Context Decision Transformer Reinforcement Learning via Hierarchical Chain-of-Thought.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Incentivized Learning in Principal-Agent Bandit Games.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Individual Contributions as Intrinsic Exploration Scaffolds for Multi-agent Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### Inferring the Long-Term Causal Effects of Long-Term Treatments from Short-Term Experiments.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Information-Directed Pessimism for Offline Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Intersectional Unfairness Discovery.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Investigating Pre-Training Objectives for Generalization in Vision-Based Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Is DPO Superior to PPO for LLM Alignment A Comprehensive Study.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Is Inverse Reinforcement Learning Harder than Standard Reinforcement Learning A Theoretical Perspect.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Iterative Data Smoothing Mitigating Reward Overfitting and Overoptimization in RLHF.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Iterative Preference Learning from Human Feedback Bridging Theory and Practice for RLHF under KL-con.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Iterative Regularized Policy Optimization with Imperfect Demonstrations.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Knowledge-aware Reinforced Language Models for Protein Directed Evolution.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### LAGMA LAtent Goal-guided Multi-Agent Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### LLM-Empowered State Representation for Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Langevin Policy for Safe Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, action-value\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'td3', 'ppo', 'dqn']


### Language Models with Conformal Factuality Guarantees.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Language-guided Skill Learning with Temporal Variational Inference.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td-mpc', 'ppo', 'sac']


### Latent Logic Tree Extraction for Event Sequence Explanation from LLMs.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Causal Dynamics Models in Object-Oriented Environments.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Constraints from Offline Demonstrations via Superior Distribution Correction Estimation.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Learning Coverage Paths in Unknown Environments with Deep Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### Learning Iterative Reasoning through Energy Diffusion.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Latent Dynamic Robust Representations for World Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td-mpc', 'dreamer', 'ppo', 'sac']


### Learning Optimal Deterministic Policies with Stochastic Policy Gradients.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Reward for Robot Skills Using Large Language Models via Self-Alignment.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning Solution-Aware Transformers for Efficiently Solving Quadratic Assignment Problem.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Learning Temporal Distances Contrastive Successor Features Can Provide a Metric Structure for Decisi.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Learning Useful Representations of Recurrent Neural Network Weight Matrices.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 15
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning a Diffusion Model Policy from Rewards via Q-Score Matching.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Learning from Integral Losses in Physics Informed Neural Networks.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Learning the Target Network in Function Space.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, state-action\s+pairs
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Learning to Explore in POMDPs with Informational Rewards.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Learning to Play Atari in a World of Tokens.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer']


### Learning to Reach Goals via Diffusion.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Learning to Scale Logits for Temperature-Conditional GFlowNets.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c', 'sac']


### Learning to Stabilize Online Reinforcement Learning in Unbounded State Spaces.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Limited Preference Aided Imitation Learning from Imperfect Demonstrations.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Linear Alignment A Closed-form Solution for Aligning Human Preferences without Tuning and Feedback.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Linguistic Calibration of Long-Form Generations.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Listwise Reward Estimation for Offline Preference-based Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Local Feature Selection without Label or Feature Leakage for Interpretable Machine Learning Predicti.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Locally Interdependent Multi-Agent MDP Theoretical Framework for Decentralized Agents with Dynamic D.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Major-Minor Mean Field Multi-Agent Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 500
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'a2c']


### Mastering Zero-Shot Interactions in Cooperative and Competitive Simultaneous Games.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Matroid Semi-Bandits in Sublinear Time.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### MaxMin-RLHF Alignment with Diverse Human Preferences.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Mean Field Langevin Actor-Critic Faster Convergence and Global Optimality beyond Lazy Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Meta-Reinforcement Learning Robust to Distributional Shift Via Performing Lifelong In-Context Learni.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Mimicking Better by Matching the Approximate Action Distribution.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Mixtures of Experts Unlock Parameter Scaling for Deep RL.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Model Alignment as Prospect Theoretic Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Model-Based RL for Mean-Field Games is not Statistically Harder than Single-Agent RL.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Model-Free Robust φ-Divergence Reinforcement Learning Using Both Offline and Online Data.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Model-based Reinforcement Learning for Confounded POMDPs.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Model-based Reinforcement Learning for Parameterized Action Spaces.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'td3', 'ppo']


### Mollification Effects of Policy Gradient Methods.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Momentum for the Win Collaborative Federated Reinforcement Learning across Heterogeneous Environment.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### More Benefits of Being Distributional Second-Order Bounds for Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Multi-Agent Reinforcement Learning Meets Leaf Sequencing in Radiotherapy.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Multi-Agent Reinforcement Learning with Hierarchical Coordination for Emergency Responder Stationing.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'ddpg']


### Multi-View Clustering by Inter-cluster Connectivity Guided Reward.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### MusicRL Aligning Music Generation to Human Preferences.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets', 'ppo', 'sac']


### NExT Teaching Large Language Models to Reason about Code Execution.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Nash Learning from Human Feedback.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Near-Optimal Regret in Linear MDPs with Aggregate Bandit Feedback.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Near-Optimal Reinforcement Learning with Self-Play under Adaptivity Constraints.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Nesting Particle Filters for Experimental Design in Dynamical Systems.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 25
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Neural-Kernel Conditional Mean Embeddings.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn']


### No-Regret Reinforcement Learning in Smooth MDPs.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Non-Asymptotic Analysis for Single-Loop Natural Actor-Critic with Compatible Function Approximation.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### ODIN Disentangled Reward Mitigates Hacking in RLHF.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### OLLIE Imitation Learning from Offline Pretraining to Online Finetuning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### OMPO A Unified Framework for RL under Policy and Dynamics Shifts.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'td3', 'ppo', 'sac']


### Offline Actor-Critic Reinforcement Learning Scales to Large Models.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 400
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Offline Inverse RL New Solution Concepts and Provably Efficient Algorithms.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Offline Transition Modeling via Contrastive Energy Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Offline-Boosted Actor-Critic Adaptively Blending Optimal Historical Behaviors in Deep Off-Policy RL.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac', 'td3', 'td-mpc', 'ppo']


### On PI Controllers for Updating Lagrange Multipliers in Constrained Optimization.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### On The Statistical Complexity of Offline Decision-Making.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### On the Complexity of Finite-Sum Smooth Optimization under the PolyakŁojasiewicz Condition.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### On the Hardness of Probabilistic Neurosymbolic Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### On the Second-Order Convergence of Biased Policy Gradient Algorithms.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### On the Unexpected Effectiveness of Reinforcement Learning for Sequential Recommendation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'a2c']


### Online Learning under Budget and ROI Constraints via Weak Adaptivity.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Online bipartite matching with imperfect advice.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Open Ad Hoc Teamwork with Cooperative Game Theory.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c', 'sac']


### OptiMUS Scalable Optimization Modeling with MILP Solvers and Large Language Models.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Optimistic Multi-Agent Policy Gradient.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'a2c', 'ppo']


### Overestimation Overfitting and Plasticity in Actor-Critic the Bitter Lesson of Reinforcement Learnin.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 640
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### PEARL Zero-shot Cross-task Preference Alignment and Robust Reward Learning for Robotic Manipulation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### PIPER Primitive-Informed Preference-based Hierarchical Reinforcement Learning via Hindsight Relabeli.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Pausing Policy Learning in Non-stationary Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### PcLast Discovering Plannable Continuous Latent States.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Pessimism Meets Risk Risk-Sensitive Offline Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### PlanDQ Hierarchical Plan Orchestration via D-Conductor and Q-Performer.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### Planning Fast and Slow Online Reinforcement Learning with Action-Free Offline Data via Multiscale Pl.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Policy-conditioned Environment Models are More Generalizable.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Position Automatic Environment Shaping is the Next Frontier in RL.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Position Benchmarking is Limited in Reinforcement Learning Research.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs
* Number of seeds: 103
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Position Data-driven Discovery with Large Generative Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Position Foundation Agents as the Paradigm Shift for Decision Making.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Position Intent-aligned AI Systems Must Optimize for Agency Preservation.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Position Open-Endedness is Essential for Artificial Superhuman Intelligence.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Position Opportunities Exist for Machine Learning in Magnetic Fusion Energy.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Position Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Position Scaling Simulation is Neither Necessary Nor Sufficient for In-the-Wild Robot Manipulation.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Position Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Position Social Environment Design Should be Further Developed for AI-based Policy-Making.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Position TrustLLM Trustworthiness in Large Language Models.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Position Video as the New Language for Real-World Decision Making.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Pragmatic Feature Preferences Learning Reward-Relevant Preferences from Human Input.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Preference Fine-Tuning of LLMs Should Leverage Suboptimal On-Policy Data.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Preference Optimization for Molecule Synthesis with Conditional Residual Energy-based Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Pricing with Contextual Elasticity and Heteroscedastic Valuation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Principled Penalty-based Methods for Bilevel Reinforcement Learning and RLHF.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['a3c', 'ppo', 'a2c']


### Principled Preferential Bayesian Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Probabilistic Constrained Reinforcement Learning with Formal Interpretability.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Probabilistic Subgoal Representations for Hierarchical Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'sac']


### Projecting Molecules into Synthesizable Chemical Spaces.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Prompt-based Visual Alignment for Zero-shot Policy Transfer.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Protein Conformation Generation via Force-Guided SE3 Diffusion Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Provable Interactive Learning with Hindsight Instruction Feedback.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Provable Representation with Efficient Planning for Partially Observable Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'sac']


### Provable Risk-Sensitive Distributional Reinforcement Learning with General Function Approximation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, state-action\s+pairs
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Provably Efficient Exploration in Quantum Reinforcement Learning with Logarithmic Worst-Case Regret.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Provably Efficient Long-Horizon Exploration in Monte Carlo Tree Search through State Occupancy Regul.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Provably Efficient Partially Observable Risk-sensitive Reinforcement Learning with Hindsight Observa.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Provably Efficient Reinforcement Learning for Adversarial Restless Multi-Armed Bandits with Unknown .pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Provably Robust DPO Aligning Language Models with Noisy Feedback.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Q-Probe A Lightweight Approach to Reward Maximization for Language Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Q-Star Meets Scalable Posterior Sampling Bridging Theory and Practice via HyperAgent.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, state-action\s+pairs
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Q-value Regularized Transformer for Offline Reinforcement Learning.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### QORA Zero-Shot Transfer via Interpretable Object-Relational Model Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Quality Diversity through Human Feedback Towards Open-Ended Diversity-Driven Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Quality-Diversity Actor-Critic Learning High-Performing and Diverse Behaviors via Value and Successo.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn', 'sac']


### Quality-Diversity with Limited Resources.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### RICE Breaking Through the Training Bottlenecks of Reinforcement Learning with Explanation.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 500
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### RIME Robust Preference-based Reinforcement Learning with Noisy Preferences.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### RL-CFR Improving Action Abstraction for Imperfect Information Extensive-Form Games with Reinforcemen.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### RL-VLM-F Reinforcement Learning from Vision Language Foundation Model Feedback.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### RLAIF vs RLHF Scaling Reinforcement Learning from Human Feedback with AI Feedback.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### RLVF Learning from Verbal Feedback without Overgeneralization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a3c', 'ppo']


### RVI-SAC Average Reward Off-Policy Deep Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn', 'ddpg', 'sac', 'ppo']


### Random Latent Exploration for Deep Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Ranking-based Client Imitation Selection for Efficient Federated Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Rate-Optimal Policy Optimization for Linear Markov Decision Processes.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### ReDiffuser Reliable Decision-Making Using a Diffuser with Confidence Estimation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### ReLU to the Rescue Improve Your On-Policy Actor-Critic with Positive Advantages.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a3c', 'dqn', 'sac', 'td3', 'ppo']


### ReMax A Simple Effective and Efficient Reinforcement Learning Method for Aligning Large Language Mod.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Reason for Future Act for Now A Principled Architecture for Autonomous LLM Agents.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Refining Minimax Regret for Unsupervised Environment Design.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Reflective Policy Optimization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Regularized Q-learning through Robust Averaging.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Reinforcement Learning and Regret Bounds for Admission Control.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Reinforcement Learning from Reachability Specifications PAC Guarantees with Expected Conditional Dis.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Reinformer Max-Return Sequence Modeling for Offline RL.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn']


### Remembering to Be Fair Non-Markovian Fairness in Sequential Decision Making.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Reprompting Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Resisting Stochastic Risks in Diffusion Planners with the Trajectory Aggregation Tree.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['sac']


### Rethinking Decision Transformer via Hierarchical Reinforcement Learning.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn']


### Rethinking Transformers in Solving POMDPs.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac', 'td3', 'ppo', 'dreamer']


### Revisiting Inexact Fixed-Point Iterations for Min-Max Problems Stochasticity and Structured Nonconve.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Revisiting Scalable Hessian Diagonal Approximations for Applications in Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'a2c']


### Reward Model Learning vs Direct Policy Optimization A Comparative Analysis of Learning from Human Pr.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Reward Shaping for Reinforcement Learning with An Assistant Reward Agent.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Reward-Free Kernel-Based Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Rich-Observation Reinforcement Learning with Continuous Latent Dynamics.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo']


### Risk Estimation in a Markov Cost Process Lower and Upper Bounds.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Risk-Sensitive Policy Optimization via Predictive CVaR Policy Gradient.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Risk-Sensitive Reward-Free Reinforcement Learning with CVaR.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### RoboGen Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Robust Inverse Constrained Reinforcement Learning under Model Misspecification.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Robust Optimization in Protein Fitness Landscapes Using Reinforcement Learning in Latent Space.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Roping in Uncertainty Robustness and Regularization in Markov Games.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Run-Time Task Composition with Safety Semantics.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td3', 'ppo']


### SAM-E Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### SAPG Split and Aggregate Policy Gradients.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn']


### SF-DQN Provable Knowledge Transfer using Successor Feature for Deep Reinforcement Learning.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### SHINE Shielding Backdoors in Deep Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### SaVeR Optimal Data Collection Strategy for Safe Policy Evaluation in Tabular MDP.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Safe Exploration in Dose Finding Clinical Trials with Heterogeneous Participants.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Safe Reinforcement Learning using Finite-Horizon Gradient-based Estimation.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Sample Average Approximation for Conditional Stochastic Optimization with Dependent Data.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Sample-Efficient Multiagent Reinforcement Learning with Reset Replay.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac']


### Sample-Efficient Robust Multi-Agent Reinforcement Learning in the Face of Environmental Uncertainty.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Scalable Online Exploration via Coverability.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Scalable Safe Policy Improvement for Factored Multi-Agent MDPs.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### SceneCraft An LLM Agent for Synthesizing 3D Scenes as Blender Code.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dreamer']


### SeMOPO Learning High-quality Model and Policy from Low-quality Offline Visual Datasets.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'ppo', 'dqn']


### See More Details Efficient Image Super-Resolution by Experts Mining.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Seizing Serendipity Exploiting the Value of Past Success in Off-Policy Actor-Critic.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Self-Composing Policies for Scalable Continual Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Self-Infilling Code Generation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['pets', 'sac']


### Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Sequence Compression Speeds Up Credit Assignment in Reinforcement Learning.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Sequential Asynchronous Action Coordination in Multi-Agent Systems A Stackelberg Decision Transforme.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### SiT Symmetry-invariant Transformers for Generalisation in Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn']


### Simple Ingredients for Offline Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn', 'sac']


### Single-Trajectory Distributionally Robust Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Skill Set Optimization Reinforcing Language Model Behavior via Transferable Skills.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Slow and Steady Wins the Race Maintaining Plasticity with Hare and Tortoise Networks.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td-mpc', 'ppo', 'sac', 'a2c']


### Smooth Tchebycheff Scalarization for Multi-Objective Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Solving Hierarchical Information-Sharing Dec-POMDPs An Extensive-Form Game Approach.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c', 'sac']


### Stability and Multigroup Fairness in Ranking with Uncertain Predictions.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Stabilizing Policy Gradients for Stochastic Differential Equations via Consistency with Perturbation.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg']


### Stealthy Imitation Reward-guided Environment-free Policy Stealing.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Stochastic Bandits with ReLU Neural Networks.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Stochastic Q-learning for Large Discrete Action Spaces.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Stop Regressing Training Value Functions via Classification for Scalable Deep RL.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Subequivariant Reinforcement Learning in 3D Multi-Entity Physical Environments.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Successor Features for Efficient Multi-Subject Controlled Text Generation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Switchable Decision Dynamic Neural Generation Networks.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Switching the Loss Reduces the Cost in Batch Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Symmetric Replay Training Enhancing Sample Efficiency in Deep Reinforcement Learning for Combinatori.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac', 'a2c']


### Tackling Non-Stationarity in Reinforcement Learning via Causal-Origin Representation.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Tackling Prevalent Conditions in Unsupervised Combinatorial Optimization Cardinality Minimum Coverin.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Target Networks and Over-parameterization Stabilize Off-policy Bootstrapping with Function Approxima.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe Reinforcement Learnin.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Test-Time Regret Minimization in Meta Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'dqn']


### The Max-Min Formulation of Multi-Objective Reinforcement Learning From Theory to a Model-Free Algori.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### To the Max Reinventing Reward in Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'td3', 'ppo', 'sac']


### Token-level Direct Preference Optimization.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### Towards Efficient Exact Optimization of Language Model Alignment.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 15
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'a2c']


### Towards General Algorithm Discovery for Combinatorial Optimization Learning Symbolic Branching Polic.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Towards Global Optimality for Practical Average Reward Reinforcement Learning without Mixing Time Or.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Towards Optimal Adversarial Robust Q-learning with Bellman Infinity-error.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'dqn', 'sac']


### Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Training Greedy Policy for Proposal Batch Selection in Expensive Multi-Objective Combinatorial Optim.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, based\s+on\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Transforming and Combining Rewards for Aligning Large Language Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Truly No-Regret Learning in Constrained MDPs.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Trust the Model Where It Trusts Itself - Model-Based Actor-Critic with Uncertainty-Aware Rollout Ada.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Trustworthy Alignment of Retrieval-Augmented Large Language Models via Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Two-sided Competing Matching Recommendation Markets With Quota and Complementary Preferences Constra.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Uncertainty-Aware Reward-Free Exploration with General Function Approximation.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### Understanding Stochastic Natural Gradient Variational Inference.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Understanding and Diagnosing Deep Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Understanding the Learning Dynamics of Alignment with Human Feedback.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Unlock the Cognitive Generalization of Deep Reinforcement Learning via Granular Ball Representation.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 15
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'sac', 'td3', 'ppo']


### Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'sac']


### Use Your INSTINCT INSTruction optimization for LLMs usIng Neural bandits Coupled with Transformers.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Value-Evolutionary-Based Reinforcement Learning.pdf
* Matched keywords: value\s+function\s+approximation
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['td3', 'ppo', 'dqn']


### WARM On the Benefits of Weight Averaged Reward Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### When Do Skills Help Reinforcement Learning A Theoretical Analysis of Temporal Abstractions.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs
* Number of seeds: 32
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Why Do Animals Need Shaping A Theory of Task Composition and Curriculum Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Zero-Shot Reinforcement Learning via Function Encoders.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn']


### Zero-Sum Positional Differential Games as a Framework for Robust Reinforcement Learning Deep Q-Learn.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'dqn', 'ddpg', 'sac']


### rm E3-Equivariant Actor-Critic Methods for Cooperative Multi-Agent Reinforcement Learning.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'ddpg']
