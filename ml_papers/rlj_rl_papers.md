# RL Papers Analysis


## Year 2024 (113 RL papers)


### A Batch Sequential Halving Algorithm without Performance Degradation.pdf
* Matched keywords: 
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['Not specified']


### A Natural Extension To Online Algorithms For Hybrid RL With Limited Coverage.pdf
* Matched keywords: value\s+function\s+approximation, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### A Provably Efficient Option-Based Algorithm for both High-Level and Low-Level Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### A Recipe for Unbounded Data Augmentation in Visual Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### A Simple Mixture Policy Parameterization for Improving Sample Efficiency of CVaR Optimization.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### A Super-human Vision-based Reinforcement Learning Agent for Autonomous Racing in Gran Turismo.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac', 'a3c', 'a2c']


### A Tighter Convergence Proof of Reverse Experience Replay.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo']


### Agent-Centric Human Demonstrations Train World Models.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dreamer', 'td-mpc', 'ppo']


### An Idiosyncrasy of Time-discretization in Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### An Open-Loop Baseline for Reinforcement Learning Locomotion Tasks.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ddpg', 'ppo', 'sac']


### An Optimal Tightness Bound for the Simulation Lemma.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['other']


### Aquatic Navigation A Challenging Benchmark for Deep Reinforcement Learning.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal Policy Optimization.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a3c', 'ddpg', 'ppo']


### Bad Habits Policy Confounding and Out-of-Trajectory Generalization in RL.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Bandits with Multimodal Structure.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Best Response Shaping.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### BetaZero Belief-State Planning for Long-Horizon POMDPs using Learned Approximations.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Bidirectional-Reachable Hierarchical Reinforcement Learning with Mutually Responsive Policies.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Boosting Soft Q-Learning by Bounding.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'ppo', 'sac']


### Bounding-Box Inference for Error-Aware Model-Based Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'dreamer', 'ppo', 'sac']


### Can Differentiable Decision Trees Enable Interpretable Reward Learning from Human Feedback.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Causal Contextual Bandits with Adaptive Context.pdf
* Matched keywords: 
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['Not specified']


### Co-Learning Empirical Games  World Models.pdf
* Matched keywords: 
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['Not specified']


### Combining Automated Optimisation of Hyperparameters and Reward Shape.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Combining Reconstruction and Contrastive Methods for Multimodal Representations in RL.pdf
* Matched keywords: 
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['Not specified']


### Constant Stepsize Q-learning Distributional Convergence Bias and Extrapolation.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo']


### Contextualized Hybrid Ensemble Q-learning Learning Fast with Control Priors.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'sac']


### Cost Aware Best Arm Identification.pdf
* Matched keywords: 
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['Not specified']


### Cross-environment Hyperparameter Tuning for Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 840
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ddpg', 'ppo', 'sac']


### Cyclicity-Regularized Coordination Graphs.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo']


### D5RL Diverse Datasets for Data-Driven Deep Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'td3', 'ppo']


### Demystifying the Recency Heuristic in Temporal-Difference Learning.pdf
* Matched keywords: action-value\s+function, state-action\s+pairs
* Number of seeds: 400
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Dissecting Deep RL with High Update Ratios Combatting Value Divergence.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'sac', 'ddpg', 'td-mpc', 'ppo']


### Distributionally Robust Constrained Reinforcement Learning under Strong Duality.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Dreaming of Many Worlds Learning Contextual World Models aids Zero-Shot Generalization.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dreamer', 'a2c', 'sac']


### Enabling Intelligent Interactions between an Agent and an LLM A Reinforcement Learning Approach.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Exploring Uncertainty in Distributional Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Graph Neural Thompson Sampling.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Guided Data Augmentation for Offline Reinforcement Learning and Imitation Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'td3', 'ppo']


### Harnessing Discrete Representations for Continual Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'dreamer', 'ppo']


### Human-compatible driving agents through data-regularized self-play reinforcement learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### ICU-Sepsis A Benchmark MDP Built from Real Medical Data.pdf
* Matched keywords: using\s+(?:deep\s+)?reinforcement\s+learning\s+to, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 8
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Imitation Learning from Observation through Optimal Transport.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'td3', 'sac']


### Improving Thompson Sampling via Information Relaxation for Budgeted Multi-armed Bandits.pdf
* Matched keywords: 
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['Not specified']


### Inception Efficiently Computable Misinformation Attacks on Markov Games.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Informed POMDP Leveraging Additional Information in Model-Based RL.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'sac', 'dreamer', 'ddpg', 'ppo']


### Inverse Reinforcement Learning with Multiple Planning Horizons.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['other']


### Investigating the Interplay of Prioritized Replay and Generalization.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### JoinGym An Efficient Join Order Selection Environment.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Learning Abstract World Models for Value-preserving Planning with Options.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'td3', 'sac', 'dreamer', 'td-mpc', 'ppo']


### Learning Action-based Representations Using Invariance.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Learning Discrete World Models for Heuristic Search.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn']


### Learning to Navigate in Mazes with Novel Layouts using Abstract Top-down Maps.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Learning to Optimize for Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a2c', 'ppo']


### Light-weight Probing of Unsupervised Representations for Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'dreamer', 'ppo']


### Mitigating the Curse of Horizon in Monte-Carlo Returns.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Mixture of Experts in a Mixture of RL settings.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### More Efficient Randomized Exploration for Reinforcement Learning via Approximate Sampling.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, value\s+function\s+approximation, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo']


### Multi-view Disentanglement for Reinforcement Learning with Multiple Cameras.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['sac']


### MultiHyRL Robust Hybrid RL for Obstacle Avoidance against Adversarial Attacks on the Observation Spa.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Multistep Inverse Is Not All You Need.pdf
* Matched keywords: 
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['Not specified']


### Non-adaptive Online Finetuning for Offline Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### OCAtari Object-Centric Atari 2600 Reinforcement Learning Environments.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo']


### Offline Diversity Maximization under Imitation Constraints.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo']


### Offline Reinforcement Learning from Datasets with Structured Non-Stationarity.pdf
* Matched keywords: action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'sac']


### On Welfare-Centric Fair Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### On the consistency of hyper-parameter selection in value-based deep reinforcement learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'trpo', 'ppo', 'sac']


### Online Planning in POMDPs with State-Requests.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 4000
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo']


### Optimizing Rewards while meeting omega-regular Constraints.pdf
* Matched keywords: our\s+(?:reinforcement\s+learning|RL)\s+(?:approach|method|algorithm), trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### PASTA Pretrained Action-State Transformer Agents.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'td3', 'trpo', 'sac', 'ppo']


### PID Accelerated Temporal Difference Algorithms.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 80
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Physics-Informed Model and Hybrid Planning for Efficient Dyna-Style Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['td3', 'sac', 'pets', 'dreamer', 'td-mpc']


### Planning to Go Out-of-Distribution in Offline-to-Online Reinforcement Learning.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['sac']


### Policy Architectures for Compositional Generalization in Control.pdf
* Matched keywords: action-value\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ddpg', 'ppo', 'sac']


### Policy Gradient Algorithms with Monte Carlo Tree Learning for Non-Markov Decision Processes.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'trpo', 'ppo', 'sac']


### Policy Gradient with Active Importance Sampling.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Policy-Guided Diffusion.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 4
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'td3', 'sac', 'pets', 'ppo']


### Posterior Sampling for Continuing Environments.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo']


### Quantifying Interaction Level Between Agents Helps Cost-efficient Generalization in Multi-agent Rein.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### RL for Consistency Models Reward Guided Text-to-Image Generation with Fast Inference.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### ROER Regularized Optimal Experience Replay.pdf
* Matched keywords: based\s+on\s+(?:deep\s+)?reinforcement\s+learning, through\s+(?:deep\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 20
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'trpo', 'ppo', 'sac']


### ROIL Robust Offline Imitation Learning without Trajectories.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Reinforcement Learning from Delayed Observations via World Models.pdf
* Matched keywords: 
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['Not specified']


### Reinforcement Learning from Human Feedback without Reward Inference Model-Free Algorithm and Instanc.pdf
* Matched keywords: state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo']


### Representation Alignment from Human Feedback for Cross-Embodiment Reward Learning from Mixed-Quality.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Resource Usage Evaluation of Discrete Model-Free Deep Reinforcement Learning Algorithms.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach)
* Number of seeds: Not specified
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['a2c', 'dqn', 'ppo', 'sac']


### Revisiting Sparse Rewards for Goal-Reaching Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Reward Centering.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, action-value\s+function, state-action\s+pairs
* Number of seeds: 50
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'trpo', 'ppo', 'sac']


### Robotic Manipulation Datasets for Offline Compositional Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Sample Complexity of Offline Distributionally Robust Linear Markov Decision Processes.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Semi-Supervised One Shot Imitation Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo', 'sac']


### Sequential Decision-Making for Inline Text Autocomplete.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'trpo', 'ppo', 'sac']


### Shield Decomposition for Safe Reinforcement Learning in General Partially Observable Multi-Agent Env.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 100
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### SplAgger Split Aggregation for Meta-Reinforcement Learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 3
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['ppo']


### Stabilizing Extreme Q-learning by Maclaurin Expansion.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 6
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'trpo', 'ppo', 'sac']


### States as goal-directed concepts an epistemic approach to state-representation learning.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 1000
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Surprise-Adaptive Intrinsic Motivation for Unsupervised Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### SwiftTD A Fast and Robust Algorithm for Temporal Difference Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning
* Number of seeds: 15
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### The Cliff of Overcommitment with Policy Gradient Step Sizes.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['trpo', 'ppo', 'sac']


### The Limits of Pure Exploration in POMDPs When the Observation Entropy is Enough.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 16
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### The Role of Inherent Bellman Error in Offline Reinforcement Learning with Linear Function Approximat.pdf
* Matched keywords: value\s+function\s+approximation, state-action\s+pairs, (?:discount|reward)\s+function
* Number of seeds: 1
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Three Dogmas of Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Tiered Reward Designing Rewards for Specification and Fast Learning of Desired Behavior.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: 300
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['dqn', 'ppo']


### Towards General Negotiation Strategies with End-to-End Reinforcement Learning.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Towards Principled Practical Policy Gradient for Bandits and Tabular MDPs.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'ppo']


### Trust-based Consensus in Multi-Agent Reinforcement Learning Systems.pdf
* Matched keywords: we\s+(?:propose|present|introduce|develop)\s+(?:\w+\s+)*?reinforcement\s+learning, action-value\s+function, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### Unifying Model-Based and Model-Free Reinforcement Learning with Equivalent Policy Sets.pdf
* Matched keywords: policy\s+gradient\s+(?:method|algorithm|approach), (?:discount|reward)\s+function
* Number of seeds: 5
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['trpo', 'td3', 'sac', 'dreamer', 'ddpg', 'ppo']


### Value Internalization Learning and Generalizing from Social Reward.pdf
* Matched keywords: (?:discount|reward)\s+function
* Number of seeds: 10
* Code available: Yes
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Verification-Guided Shielding for Deep Reinforcement Learning.pdf
* Matched keywords: trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning, (?:discount|reward)\s+function
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['ppo']


### Weight Clipping for Deep Continual and Reinforcement Learning.pdf
* Matched keywords: through\s+(?:deep\s+)?reinforcement\s+learning, trained\s+(?:with\s+|using\s+)?(?:deep\s+|model-based\s+|model-free\s+)?reinforcement\s+learning
* Number of seeds: 5
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'ppo', 'sac']


### When does Self-Prediction help Understanding Auxiliary Tasks in Reinforcement Learning.pdf
* Matched keywords: value\s+function\s+approximation, (?:discount|reward)\s+function
* Number of seeds: 30
* Code available: Yes
* Hyperparameters detailed: Yes
* Environment version specified: No
* Algorithm: ['dqn', 'td3', 'ppo']


### Zero-shot cross-modal transfer of Reinforcement Learning policies through a Global Workspace.pdf
* Matched keywords: 
* Number of seeds: Not specified
* Code available: No
* Hyperparameters detailed: No
* Environment version specified: No
* Algorithm: ['Not specified']
